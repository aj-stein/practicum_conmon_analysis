# Metadata

title:What can't or shouldn't be automated and why?

author: [github.com/emu-gov](https://github.com/emu-gov)

url: [https://github.com/FedRAMP/applying-existing-frameworks-cwg/discussions/9](https://github.com/FedRAMP/applying-existing-frameworks-cwg/discussions/9)

created: 2025-04-07T19:49:44Z

id: D_kwDOOMfSVs4AfMLX



# Post

FedRAMP 20x seeks to automate as much as possible, but technical, ethical, or assurance challenges may necessitate human intervention. 

What items in your opinion *can't* or *shouldn't* be attested by machine and why?

# Comments




## Comment 1

author: [github.com/Christcpd](https://github.com/Christcpd)

url: [https://github.com/FedRAMP/applying-existing-frameworks-cwg/discussions/9#discussioncomment-12756775](https://github.com/FedRAMP/applying-existing-frameworks-cwg/discussions/9#discussioncomment-12756775)

created: 2025-04-07T22:03:19Z

id: DC_kwDOOMfSVs4Awqcn

User and System audits.
Inventory reviews.
Policy Reviews.
Event (Incident) Response (SOAR is dead)

All require human judgement.  

Although, Agentic AI could be deployed.  "Time based action to review existing policy document against new developments and model training, make appropriate updates, and submit for approval."  

Again, Agentic AI: "Review user access, compare to users of similar job title from HR system, and output recommendations."

Using AI, it is possible to get the compliance aspect to about 5% of effort.  BUT, that takes third parties to create that level of automation.


### Replies



#### Reply 1

author: [github.com/CJ-J-J](https://github.com/CJ-J-J)

url: [https://github.com/FedRAMP/applying-existing-frameworks-cwg/discussions/9#discussioncomment-12770249](https://github.com/FedRAMP/applying-existing-frameworks-cwg/discussions/9#discussioncomment-12770249)

created: 2025-04-08T21:14:50Z

id: DC_kwDOOMfSVs4AwtvJ

AI automation of user audits is a really interesting idea that I could see saving internal teams a lot of time potentially. It is something traditionally done by human judgement, but in practice how many times have we asked for justification of a user's access only to be told by their manager "I don't know what they use that for but I'm sure they need it!" which arguably is less helpful than automation (in my opinion).



#### Reply 2

author: [github.com/gorkhalee](https://github.com/gorkhalee)

url: [https://github.com/FedRAMP/applying-existing-frameworks-cwg/discussions/9#discussioncomment-12779305](https://github.com/FedRAMP/applying-existing-frameworks-cwg/discussions/9#discussioncomment-12779305)

created: 2025-04-09T14:24:50Z

id: DC_kwDOOMfSVs4Awv8p

I think this is one where it's difficult for me to see AI doing it because it is traditionally a human judgement thing, and also so many things in an audit require context.

In a perfect world where someone requests/approves access for themselves, and they're granted it, how does automation judge if that's appropriate? Engineer x got root access, it was documented in a ticket with the note "Engineer x needs root access to fix 'specific issue'"

Automation can tell if a justification is there, it can tell if there's an expiration or parameters around the elevation, but there's question around it like:
1. Did they really NEED root access for this?
2. If you look at the number of people with root access, maybe that's a little worrying if there's a lot of them 
3. They maybe needed access, but the justification documented in the ticket is really bad (eg. I don't know what they use that for but I'm sure they need it!")

It seems difficult, at least for this example and examples of this nature, for me to imagine a non-human considering the context around it and coming to sound judgement.





#### Reply 3

author: [github.com/CJ-J-J](https://github.com/CJ-J-J)

url: [https://github.com/FedRAMP/applying-existing-frameworks-cwg/discussions/9#discussioncomment-12779597](https://github.com/FedRAMP/applying-existing-frameworks-cwg/discussions/9#discussioncomment-12779597)

created: 2025-04-09T14:47:13Z

id: DC_kwDOOMfSVs4AwwBN

Those are all great points. Can you see a world where automation/AI at least cuts down on a lot of the manual labor by auditors? There will almost certainly be weird/fringe cases that require human understanding of context, but if it could reduce the amount of hours spent reviewing things I can see that as a net benefit. Curious to hear all opinions though, keep them coming!



#### Reply 4

author: [github.com/gorkhalee](https://github.com/gorkhalee)

url: [https://github.com/FedRAMP/applying-existing-frameworks-cwg/discussions/9#discussioncomment-12780127](https://github.com/FedRAMP/applying-existing-frameworks-cwg/discussions/9#discussioncomment-12780127)

created: 2025-04-09T15:27:14Z

id: DC_kwDOOMfSVs4AwwJf

Cut down on work absolutely, I think if the overall goal was "Do FedRAMP as is, but automate what you can" I would have a much easier time thinking through it. My mindset has automation's main purpose ingesting and verifying things that are quantifiable/things with parameters.

eg:
Check IdP for password length
Check account expiration time thresholds 
Check that vuln scanners are set to autoupdate prior to scans
Check this policy to make sure retention requirements are set to xyz

So anything that is a binary "yes/no", or a button you can click, seems appropriate for automation. 

I'm also not the MOST savvy person when it comes to what AI/automation is capable of though, so would welcome other opinions!



## Comment 2

author: [github.com/gorkhalee](https://github.com/gorkhalee)

url: [https://github.com/FedRAMP/applying-existing-frameworks-cwg/discussions/9#discussioncomment-12764081](https://github.com/FedRAMP/applying-existing-frameworks-cwg/discussions/9#discussioncomment-12764081)

created: 2025-04-08T12:24:55Z

id: DC_kwDOOMfSVs4AwsOx

Just the way my mind works, I am thinking through the existing FedRAMP Mod controls (if they were all automated.

These are some of the things that come to mind in terms of what presents difficulties to automated assessments:
- Physical controls (MA/MP/PE/PS) - obvious reasons
- Controls that interact with humans (termination processes, sanctions, PS type controls) -- a lot these have some level of subtext that aren't strictly binary (eg. we have reworked our organization to only allow this subset of engineers to work on the FR system), and I find these controls tend to have more to the story than what is documented in procedures.
- IR controls tend to be more human oriented (do these people know what process to follow in the event of an Incident), so more difficult to automate. You can have runbooks, but do employees know the process, is the process fleshed out and comprehensive? 
- POAMs require some level of human review, especially for Deviation Requests. 
- Across control families, interviews tend to be more helpful for asking questions about processes, as not every process (IR, CM, SA [third party acquisition etc.]) necessarily aligns with the way it is documented. Most CSPs I've worked with have discrepancies between the documented processes and how an employee actually does things.



### Replies



## Comment 3

author: [github.com/ChanceofClouds](https://github.com/ChanceofClouds)

url: [https://github.com/FedRAMP/applying-existing-frameworks-cwg/discussions/9#discussioncomment-12766661](https://github.com/FedRAMP/applying-existing-frameworks-cwg/discussions/9#discussioncomment-12766661)

created: 2025-04-08T15:41:53Z

id: DC_kwDOOMfSVs4Aws3F

Any form of exercise/training would need to be validated by a person to determine if the exercise/training was sufficient.
In theory the access form reviews and change ticket reviews to determine if the needed parties reviewed and approved them could be done by AI but I assume that would be too difficult to implement since everyone has different titles.
All PE controls will need a human being reviewing unless CSPs want to give a tool access to their surveillance and building maintenance tools.
I think all documentation review could be assisted by AI but will still probably require some form of human. Unless you have it where the AI tool is going to compare entries in the SSP to the policy/procedure to see if different tools/processes are mentioned.
Will probably need a human to review output but AI would be able to most likely be used to determine AU related evidence like are all the inventoried hosts being checked and are there queries to meet certain controls for monitoring/alerting.
Potentially all controls which are not applicable or there is no evidence of something ("We don't have any mobile devices or have had no incidents") so the human assessor has to think about what could be used to show that the CSP is doing something. I think automation will struggle with that.
SR family is more subjective so would probably need a human being to review.

Sorry, I flip flopped between can and can't. 

### Replies



## Comment 4

author: [github.com/JosephScarzone](https://github.com/JosephScarzone)

url: [https://github.com/FedRAMP/applying-existing-frameworks-cwg/discussions/9#discussioncomment-12781987](https://github.com/FedRAMP/applying-existing-frameworks-cwg/discussions/9#discussioncomment-12781987)

created: 2025-04-09T18:03:25Z

id: DC_kwDOOMfSVs4Awwmj

Really depends on your definition of "automation"? In the context of a KSI approach, I envision that there will be KSIs that are truly automated results from the CSP, and results shared to an online tool (CSP Security Posture Dashboard) via APIs. I also see that the CSP can have manual metrics calculated within their environments, but the results are shared via an API to an online dashboard. Based on the KSIs defined for what I recommend a Control Domain presentation of KSI results, a CSP should be able to label via dashboard-prompted selections how that KSI is measured, whether manual or automated. All results though, whether CSP manual measures or automated ones, are communicated via a structured API, auto-populating fields on the Dashboard. 

In the context of the purpose of this CWG, not only should CSPs be allowed to describe KSI implementation via smart labels, we should also be able to indicate if a KSI is independently validated through another existing control framework, i.e. ISO assessments, HITRUST assessment, etc., and the results of those independent tests shared, i.e. being able to indicate as an example - Pass/Fail, Good/Bad, etc., and when that independent validation occurred. All through an API though that is structured to consistently share KSI results. The real question is - "Are we willing to accept and trust independent validations from auditors/assessors of another control framework?" 

These determinations should be driven by CSPs to define through selections in the online tool the nature of how the results of a KSI are presented, whether it's a manual or automated result, and whether it's covered by an independent validation by some auditor/assessor from another control framework (similar to the concept of how FedRAMP uses the "Inheritance" concept, in essence). 

The minimum set of KSIs established by FedRAMP will basically drive what can and cannot be automated, and the solution of presenting those results should expect to have both CSP manual and automated measures to share via an API. 

### Replies

