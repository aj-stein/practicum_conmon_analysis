# Metadata

title:What technical challenges do you foresee in providing real-time, verifiable security evidence?

author: [github.com/kyhu65867](https://github.com/kyhu65867)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8)

created: 2025-04-02T14:42:13Z

id: D_kwDOOMDw3M4AfH3u



# Post

Given the goal of moving from screenshot-based evidence to continuous configuration-based assessment, what technical challenges do you foresee in providing real-time, verifiable security evidence?

# Comments




## Comment 1

author: [github.com/Christcpd](https://github.com/Christcpd)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12702464](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12702464)

created: 2025-04-02T15:21:34Z

id: DC_kwDOOMDw3M4AwdMA

This is really going to fall to the third-party vendor market to implement.  Compliance Management Tools or Governance, Risk, and Compliance vendors to be specific.  An organization would have difficulty doing anything themselves without recreating the wheel by creating their own tool.

### Replies



#### Reply 1

author: [github.com/jsantore-cgc](https://github.com/jsantore-cgc)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12703858](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12703858)

created: 2025-04-02T17:05:31Z

id: DC_kwDOOMDw3M4Awdhy

There's a big potential gotcha here.  How do we know we can trust the tool to report accurately?  

Think of it as a chain of custody thing.  Without naming names, I had a discussion with a big vendor in this space, and when asked to understand how their monitoring agents worked (and more specifically, what they checked for), they were not comfortable sharing.  It is *not* sufficient to just say 'ok, my monitoring agent says that control X is good' without understanding what the agent is checking, or having any way to verify.  

Let me give you a concrete hypothetical example.  Let's say you have agent or dashboard that gives you compliance status on SC-45(1) (time.nist.gov).  Just saying it's good isn't sufficient without knowing how that agent checks. 



#### Reply 2

author: [github.com/aj-stein-gsa](https://github.com/aj-stein-gsa)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12704195](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12704195)

created: 2025-04-02T17:26:36Z

id: DC_kwDOOMDw3M4AwdnD

> Let me give you a concrete hypothetical example. Let's say you have agent or dashboard that gives you compliance status on SC-45(1) (time.nist.gov). Just saying it's good isn't sufficient without knowing how that agent checks.

Interesting enough, there is vast world around this kind of authenticity claims, and many people are working towards building blocks around [timestamp servers](https://datatracker.ietf.org/doc/rfc3161/) and [digitally signing packed binary objects with those servers](https://datatracker.ietf.org/doc/draft-ietf-cose-tsa-tst-header-parameter/) around these concepts. This is just _one approach_  I know of (for example, [Adobe already is deep into RFC3161 usage](https://mailarchive.ietf.org/arch/msg/cose/Vw2Ne4jh6Hki4nCVlkUn0zpmjjQ/)).

On a personal level, I am curious how the community leverage some of these ideas and compose them into useful approaches to endorsing and attesting information. I look forward to more from you and others!



#### Reply 3

author: [github.com/kamamanh](https://github.com/kamamanh)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12704205](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12704205)

created: 2025-04-02T17:27:32Z

id: DC_kwDOOMDw3M4AwdnN

Three concerns with this being a third-party vendor thing entirely, beyond what was mentioned above:

1) Cost. Not all CSPs are currently using third party GRC tools due to the cost that comes with those tools.   Any additional required tool will be as well received as the Red Team requirement was.

2) Complexity of control evidence. Using the SC-45(1) example above... the how a tool checks matters because the implementation details may be different between different components within the same CSO.  If a tool only checks one particular file, or for one particular specific line, then it could fail components that are compliant. This would then lead to either additional custom checks (if the tool supports), or a mountain of deviation paperwork. 

3) Who is going to drive adoption in the agencies for this? Is the expectation that they will simply accept whatever FedRAMP decides to adopt? 



#### Reply 4

author: [github.com/aparkar-panw](https://github.com/aparkar-panw)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12704325](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12704325)

created: 2025-04-02T17:35:28Z

id: DC_kwDOOMDw3M4AwdpF

Also, there are cost implications on developing tools to objectively capture evidence of said controls. This reminds me very much of CIS/STIG creation. The first step would be to establish what the standard, which we may have, but the method to check the standard could vary (ex. RHEL vs Windows ubuntu vs and appliance). The best way to start might be to determine what controls are the most important and automate those and keep evolving. 



#### Reply 5

author: [github.com/JosephScarzone](https://github.com/JosephScarzone)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12718447](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12718447)

created: 2025-04-03T20:11:59Z

id: DC_kwDOOMDw3M4AwhFv

To my point on another thread, the standard should not set the "how" but the "what". This will allow CSPs to be creative, ingenious and innovative to figure out how best to report on a KSI in an automated, continuous fashion. I foresee that once this happens, it will naturally spark all sorts of creativity, process tweaks, defining automation mechanisms via code, etc, to meet a KSI. 

Taking a Control Domain approach, with KSIs defined per Control Domain, we should allow the CSP the ability to describe how they met the KSI via automation/code, all within the CSP Security Posture Dashboard, making it a very powerful, one-stop shop to help FedRAMP and Agencies to make a reasonable authorization decision. It should be a living entity, constantly updated based on a defined frequency to give Agencies and FedRAMP all they should need to make a decision. 

Eventually, and I think what our goal is, all KSI's will be automated/continuously monitored based on all the methods each CSP had to implement/organize to make the Dashboard the key resource for determining authorization approvals. :-)



#### Reply 6

author: [github.com/sunstonesecure-robert](https://github.com/sunstonesecure-robert)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12804351](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12804351)

created: 2025-04-11T13:47:02Z

id: DC_kwDOOMDw3M4Aw2D_

> There's a big potential gotcha here. How do we know we can trust the tool to report accurately?
ZKPs
chained hashes (eg git, blockchains)
crypto watermarking

nothing is bulletproof but then what is bulletproof about a screenshot? 
Trust but verify.




#### Reply 7

author: [github.com/sunstonesecure-robert](https://github.com/sunstonesecure-robert)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12804504](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12804504)

created: 2025-04-11T13:59:03Z

id: DC_kwDOOMDw3M4Aw2GY

> 1. Cost. Not all CSPs are currently using third party GRC tools due to the cost that comes with those tools.  

open source solutions exist. all the major clouds have some form of GRC capability. but overall I read this as "not all CSPs are currently managing risk" and yes, unfortunately, that's accurate. But to your point of GRC == better evidence, I agree with your sentiment.  GRCs at best water down the evidence, at worst, just turn actual data into text no one reads. Better to push the CSPs to expose APIs and telemetry directly (like the could platforms) so every part of a CSO can be assessed. Put that in your procurement contracts.

> 2. Complexity of control evidence. Using the SC-45(1) example above... 

Review 800-53A as a source. I details (at a high level) what you should evaluate.  No - it's not 1 file.  In our toolkit it's ~3K API calls and CLI calls for a moderate. That's not hard for modern compute resources to process.  Takes about 30 mins on a small EC2 instance.

> 3. Who is going to drive adoption in the agencies for this? Is the expectation that they will simply accept whatever FedRAMP decides to adopt?

No. Either they will see the benefits and vote with their feet. Or, they will ignore and ask for the same artifacts we already produce.  But - who cares?  If automation can transform OSCAL <-> word and an LLM can convert anything to JSON/yaml -> Excel, then give the agencies what they want.  When the *data* is the source of truth the conversion of data format X to format Y is trivial. When Word docs and Excel files are the source of truth - you get confusion and delay.





#### Reply 8

author: [github.com/sunstonesecure-robert](https://github.com/sunstonesecure-robert)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12804562](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12804562)

created: 2025-04-11T14:03:39Z

id: DC_kwDOOMDw3M4Aw2HS

>  standard should not set the "how" but the "what". 

YES!

> with KSIs defined per Control Domain...

As long as those map to the actual threat model, yes completely agree but let's not define metrics that measure artificial things that do not defend against insider or outside threats and failure modes.



#### Reply 9

author: [github.com/kamamanh](https://github.com/kamamanh)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12842865](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12842865)

created: 2025-04-15T14:12:13Z

id: DC_kwDOOMDw3M4Aw_dx

> But - who cares?

The cost of these additional requirements matters to CSPs.  If I spend $100k to automate artifacts, only to have to spit out in Excel anyway, I've just burned through money that could have been used in a more positively impactful way in my environment. In the new era of budget slashing, agencies aren't going to want to absorb the costs of me automating a thing they don't care about having automated or building an API that they won't use.  The buy in from agencies is critical, if we can't show clear ROI internally. (The CSPs that can show that ROI are already doing this work.)

The closer this automation is to the core business that the CSP is offering, the easier it will be to implement (skills, resources availability, leadership willingness, etc) and the more likely the adoption and promotion. I think that's one of the bigger divides that we need to recognize, more so than small/large size of the business.  The more divorced these compliance automations and APIs are from the core CSO product, the more they are scrutinized as costs. CSPs have brought up FedRAMP cost as a primary issue for years. 



#### Reply 10

author: [github.com/ProdSecCSP](https://github.com/ProdSecCSP)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12843024](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12843024)

created: 2025-04-15T14:24:21Z

id: DC_kwDOOMDw3M4Aw_gQ

Couldn't agree more. None of this matters if the cost isn't eliminated or significantly reduced.  

CSP's for years **" It takes too long and it cost too much"** 



#### Reply 11

author: [github.com/sunstonesecure-robert](https://github.com/sunstonesecure-robert)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12845611](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12845611)

created: 2025-04-15T18:24:23Z

id: DC_kwDOOMDw3M4AxAIr

> If I spend $100k to automate artifacts, only to have to spit out in Excel anyway, I've just burned through money that could have been used in a more positively impactful way in my environment. 

Come to the CNCF Compliance WG. There's lots of free tooling to do this.  Spend the $100k *training devs* on using the automation to produce BOTH OSCAL *and* Excel in 1 shot. And...hopefully...the 3PAO audits go from $150K+ to something automated where it can be $10K, $5K, or even less (if you flip the script as noted elsewhere).

> The more divorced these compliance automations and APIs are from the core CSO product, the more they are scrutinized as costs.

I 100% agree - nothing should be far from dev. call it shift-left or whatever. But the product teams can, should, and MUST use the automations as part of their daily habits.  Anything to the right is wrong :)

> CSPs have brought up FedRAMP cost as a primary issue for years.

I agree the 3PAO costs are high as they are mostly labor intensive human interviews about documentation and diagrams (sadly that are obsolete 5 mins after they are created). If this effort here can remove that cost, that frees up ~$150K *annually* to invest in (free, open source) automation + training + DevSecOps and make both your commercial stuff and your federal stuff more resilient against insider and external attack.

> None of this matters if the cost isn't eliminated or significantly reduced.

As a taxpayer with data in Fed systems... I think security matters more than the cost and convenience to a CSP. I *also* want to see more faster better innovation in Gov systems for sure.  But this can be BOTH - with automation.  There's an artificial mental barrier that treats these as either/ORs - but they don't have to be.

Apart from the cost of the 3PAO, and fixing existing bad dev and operational practices that should be fixed anyway, a FedRAMP Moderate can cost ~$10K already. I'd love for this effort to drive that to zero!  Naturally, there's no cheap shortcut to having good code and operations, but if that's all good - documenting it and the work for Comon is not that expensive (with open source automation).  Come to the CNCF Compliance WG and tell us your challenges and we can assist.





#### Reply 12

author: [github.com/dan-fedramp](https://github.com/dan-fedramp)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12858528](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12858528)

created: 2025-04-16T18:27:59Z

id: DC_kwDOOMDw3M4AxDSg

The imbalance between assessment costs and operating costs exists within agencies as well.  If you have a system that costs $100k annually to assess and only $10k annually to procure there has to be a better way. 



#### Reply 13

author: [github.com/ProdSecCSP](https://github.com/ProdSecCSP)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12858750](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12858750)

created: 2025-04-16T18:46:44Z

id: DC_kwDOOMDw3M4AxDV-

" I think security matters more than the cost and convenience to a CSP"

Why are you automatically assuming that reducing 3PAO cost would decrease security? 



#### Reply 14

author: [github.com/kamamanh](https://github.com/kamamanh)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12860390](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12860390)

created: 2025-04-16T22:53:55Z

id: DC_kwDOOMDw3M4AxDvm

> > The more divorced these compliance automations and APIs are from the core CSO product, the more they are scrutinized as costs.

> I 100% agree - nothing should be far from dev. call it shift-left or whatever. But the product teams can, should, and MUST use the automations as part of their daily habits. Anything to the right is wrong :)

I think my point was missed on this. It wasn't about shift-left, it was about automation of compliance things being an easier cost to absorb and justify for those companies who are selling compliance automation (or assessments, or security tools) as their core product than it is for companies whose core product is in a very different area of tech.  

I haven't heard any 3PAOs chiming in to say that costs would decrease when APIs come into play.  

What I am trying to do is point out the reality that a lot of CSPs live in where there is never enough budget (money, time, people) to do all the security and compliance and automation things you could possibly want. The cost FedRAMP requires continues to increase - by this I mean all of the costs associated with being on the FedRAMP marketplace (3PAO assessments, FIPS, STIGs, remediation SLAs, Red Team exercises, responding to ad hoc memos, FedRAMP 3rd party licenses, etc).  Even opensource things come with costs - you need personnel who understand it (costs for experience, training time, etc), you have to update/patch/scan/etc, as the things you hook into change you have to refactor (and possibly switch back to dusty old manually processes while covering the gap), and in the federal world you sometimes have to convince agencies and assessors that opensource is a valid and viable option (this, too, takes resource time).  We need something help prioritize the resources towards automating assessment (the topic of this CWG) and away from the other things we are doing to maintain security and compliance (and functionality). Or to help make the business case to the people who hold the purse strings that they should give more money. 

I'm not saying this to put brakes on the topic. I'm saying it so that there is consideration as this CWG moves forward that CSPs will need justifying the cost of making the transition.  


Is the CNCF Compliance WG the tag-security one? I'm happy for more resources to look at.  



#### Reply 15

author: [github.com/ProdSecCSP](https://github.com/ProdSecCSP)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12862127](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12862127)

created: 2025-04-17T03:43:13Z

id: DC_kwDOOMDw3M4AxEKv

@kamamanh 

I wholeheartedly agree. CSPs, especially smaller firms like the one I represent, can't implement automation while also covering the costs for 3PAO services, including annual assessments, pentests, and significant change requests. A majority of the evidence collection is often stale, sometimes up to 12 months old, before any authorization official reviews it for approval. Additionally, 90% of the security package documentation is boilerplate, with 3PAOs often copying and pasting and merely removing templated language. **For FedRAMP20x to be successful, costs must significantly reduce not only for initial authorization but also for ongoing continuous monitoring and change request work.**

If we are moving towards a model focused on KSI, automation, and near real-time metrics, this involves a major uplift for CSPs. **I believe most providers would be open to bearing these costs if it proves to be more beneficial for long-term growth and reporting, but any idea of continued significant cost for third party assessments would undermine what FedRAMP20x is set out to achieve.**

**Some costs that come to mind include:**

**1. Licensing Fees:** Many automation and security tools require purchasing licenses, which can be based on the number of users, devices, or the volume of data processed.
**2. Subscription Costs:** Some tools operate on a subscription model, requiring ongoing monthly or annual payments.
**3. Implementation Costs:** There may be costs associated with the initial setup and configuration of the tools, including hiring consultants or professional services.
**4. Maintenance and Support:** Ongoing maintenance and support fees are often required to ensure the tools remain up-to-date and effective.
**5. Training:** Training employees to effectively use the new tools can incur costs, whether through formal training programs, workshops, or online courses.
**6. Integration Costs:** Integrating new tools with existing systems and workflows can involve additional expenses, especially if custom development is needed.
**7. Upgrades and Scalability:** As the organization grows, additional costs may be incurred to upgrade or scale the tools to handle increased demand.
**8. Indirect Costs:** There may be indirect costs such as the time and resources spent by internal teams to manage and monitor the tools.



#### Reply 16

author: [github.com/sunstonesecure-robert](https://github.com/sunstonesecure-robert)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12880160](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12880160)

created: 2025-04-18T16:54:29Z

id: DC_kwDOOMDw3M4AxIkg

> Why are you automatically assuming that reducing 3PAO cost would decrease security?

I didn't intend that - so maybe something was lost in translation from my addled brain to fingers :)  

I assume/know from data (but  NOT a large enough N to say is a statistically correct conclusion for ALL cases, ie correlation != causation)....

- 3PAO audits *do* add security - but at high cost per unit added security.
- If 3PAO costs come down, then either the CSP can reinvest that to more automated security, better training and more staff - all things that help defend continuously
- 3PAOs can use automation too! screenshots are no better than evidence from cloud APIs or other automated sources *IF* the 3PAOs are convinced of the correctness and validity of the source - this would be a HUGE value add to everyone if the 3PAO audit audited the sources of evidence (once - per source - reusable across all audits) and attested to their veracity. 
- the value of the 3PAO audit degrades rapidly over time. Within 1 month, the state of the CSP is vastly different than during the interviews and evidence collection

re: another comment:

> I haven't heard any 3PAOs chiming in to say that costs would decrease when APIs come into play.

That shouldn't come from the 3PAOs. That should come from agency AOs, FedRAMP and/or NIST.  NIST has IRs on using automated testing.  Why should anyone apart from the stakeholders who own the risk get to decide whether evidence A is better than evidence B?  If an agency feels that a single point in time review by a 3PAO of a document is better than continuous automated attacks against a system showing no successful IoC...that's up to the AO to evaluate.  (I hope it's not MY data in that case, but I'm not the AO).



#### Reply 17

author: [github.com/jsantore-cgc](https://github.com/jsantore-cgc)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12880548](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12880548)

created: 2025-04-18T17:50:16Z

id: DC_kwDOOMDw3M4AxIqk

Ok, as a former 3PAO (I used to run the FedRAMP capability at Kratos), a few high level things about 3PAO costs:

- The SRTM portion of an assessment is labor intensive any way you slice it.  There are something like 1400 test case rows in a big ol' spreadsheet, which even if you automate/script still requires a lot of rote writing and evidence mapping.  Streamline that and it would make a HUGE difference in price, and speed.  
- Pen Test/Red Team is always going to relatively pricy, as pen testers command a premium salary-wise, and it's still a pretty labor intensive activity
- The R311 strict cert requirements actually hurt from this perspective, as ALL assessors on a project were required to have at least a junior level cert.  This was a barrier to hiring junior/associate level staff and have them apprentice and learn the ropes.  So your labor costs we de facto higher.  (Note: I believe this is in the process of being addressed with the junior cert requirement going away, although it's been in the works for 2 years or so now.  We won't actually get into the whole BCR requirement, as this is a family forum :-)
-  Because the charter of how assessments happen is 'examine, interview, test' and all three components need to be addressed, I wonder how automated assessing/KSIs might affect the value of the interviews (and debatably even the doc)  I also know some other 3PAO colleagues who don't find the interview portion of value whatsoever, and it should all be about the docs and the testing.  This is way off topic and not in scope for this, but I wonder if the assessment methodology in 800-53A should get a revamp as well.  





#### Reply 18

author: [github.com/sunstonesecure-robert](https://github.com/sunstonesecure-robert)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12881350](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12881350)

created: 2025-04-18T20:04:46Z

id: DC_kwDOOMDw3M4AxI3G

> ... 1400 test case rows in a big ol' spreadsheet, which even if you automate/script still requires a lot of rote writing and evidence mapping.  Streamline that and it would make a HUGE difference in price, and speed.

so if we removed the rote writing and evidence mapping and say generated those mappings with clear traceability and the auditor could review that - maybe even re-test all 1400 with tools at the push of a button as many times as you like to see the results are consistent - that would be better, yes?

> * Pen Test/Red Team is always going to relatively pricy, as pen testers command a premium salary-wise, and it's still a pretty labor intensive activity

If I conceded the cost point (for the moment) - even so - the value of a red test is still higher than a document "examine" or even a single point-in-time "test" of whether I had a manual review 6 months ago. IMHO.  But again up to the AO. But...read below re: interviews....

>  We won't actually get into the whole BCR requirement....

agree the accreditation requirements add cost to all for (IMHO) negligible value. let the quality of the work speak for itself but make all the work-product transparent to the agency - ZIP up all the attack traces, the transcripts of the interviews, etc.  Let the agencies use their shiny new LLMs to review all that data and make their own determination instead

>  I also know some other 3PAO colleagues who don't find the interview portion of value whatsoever, and it should all be about the docs and the testing.  

I actually highly value the interviews as it really forces CSPs to understand their own systems - as long as the interviews are open ended and technical. Not the ones where we just answer yes/no or read the TCW verbatim. Those can go.  But the ones where you ask: 

"Describe in detail how you implement and verify true end‑to‑end encryption for your React web app running in that EKS pod?"
or
"Walk me through, step by step, how Bob your theoretically disgruntled AWS cloud engineer with legitimate admin console and API access could cause damage and how you would respond?"

You know who came up with those questions: [ChatGPT](https://chatgpt.com/share/6802af04-f330-8003-91eb-655c364ee21c).  

Let's let auditors use automation/AI + their vast experience and technical training to add enormous security value.  I welcome it!  I have had the BEST time in FedRAMP learning from very experienced auditors. I honestly look forward to the interviews.  More importantly, I think agencies and CSPs level up their defensive security because of them - when they are done well.  (Those 3PAOs I have worked with and do this well know who you are!!!)






#### Reply 19

author: [github.com/jsantore-cgc](https://github.com/jsantore-cgc)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12881721](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12881721)

created: 2025-04-18T21:15:06Z

id: DC_kwDOOMDw3M4AxI85

> so if we removed the rote writing and evidence mapping and say generated those mappings with clear traceability and the auditor could review that - maybe even re-test all 1400 with tools at the push of a button as many times as you like to see the results are consistent - that would be better, yes?

This would be awesome.

> I actually highly value the interviews as it really forces CSPs to understand their own systems - as long as the interviews are open ended and technical. Not the ones where we just answer yes/no or read the TCW verbatim. Those can go.

I agree, and I didn't do that and tried teaching my assessors not to do that.  Again, that's a discussion for another time, possibly over a beverage somewhere.  As a former UNIX admin, I always found there was always a big gap with what people *really* did, versus what the *documentation said*.  So I treated interviews/demonstrations as the primary source of truth as to what was in place, and check against the SSP, rather than vice versa.    





## Comment 2

author: [github.com/shah](https://github.com/shah)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12704101](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12704101)

created: 2025-04-02T17:17:39Z

id: DC_kwDOOMDw3M4Awdll

The biggest challenge I see is what "policies as code" DSL will be chosen by FedRAMP as its policy definition language. If we can use tools such as OPA or similar DSLs that establish the controls and requirements as "policies as code" then the machine-attestable evidence gathering challenges become manageable. Without _policies as code_ the challenges will be difficult to overcome.

#4 is a great start!

### Replies



#### Reply 1

author: [github.com/aj-stein-gsa](https://github.com/aj-stein-gsa)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12704235](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12704235)

created: 2025-04-02T17:30:00Z

id: DC_kwDOOMDw3M4Awdnr

> The biggest challenge I see is what "policies as code" DSL will be chosen by FedRAMP as its policy definition language.

I would love to hear more if you have deeper thoughts on this: did you pick policies in the plural because you expect multiple or you meant you presume there will only be one, OPA or otherwise?




#### Reply 2

author: [github.com/dan-fedramp](https://github.com/dan-fedramp)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12717242](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12717242)

created: 2025-04-03T17:44:56Z

id: DC_kwDOOMDw3M4Awgy6

I remember looking at OPA as part of a zero trust solution at OMB. Can you expand some on how you see this being used? How would an agency or FedRAMP see the gathered evidence?



#### Reply 3

author: [github.com/sunstonesecure-robert](https://github.com/sunstonesecure-robert)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12804663](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12804663)

created: 2025-04-11T14:12:09Z

id: DC_kwDOOMDw3M4Aw2I3

> I remember looking at OPA as part of a zero trust solution at OMB. Can you expand some on how you see this being used? How would an agency or FedRAMP see the gathered evidence?

full transparency: OPA contributor here and CNCF chair so biased.... OPA at its core just converts JSON to other JSON and Rego is just datalog. So if you are writing rules for data conversion or data validation OPA/Rego is great!  If you are doing logic, Rego/OPA is not the right tool.

- we use OPA to generate OSCAL from evidence (that's how you can "see" the gathered evidence)
- we use OPA to check the evidence gathered is complete 
- we use OPA for evidence drift detection
- we use OPA for evidence checks and guard rails
- we use OPA for evidence enrichment from multiple sources

So raw JSON data from APIs and CLIs -> OPA -> OSCAL

[I gave a NIST workshop talk on implementing an Agency assurance framework with OPA + OSCAL noted there.
](https://csrc.nist.gov/csrc/media/Presentations/2022/oscal-mini-workshop-7-CNCF/images-media/OSCAL%20Mini%20Workshop%2011-2022-NEW.pdf) - happy to take questions in the right venue (here or CNCF WG)





#### Reply 4

author: [github.com/aj-stein-gsa](https://github.com/aj-stein-gsa)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12843421](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12843421)

created: 2025-04-15T14:57:56Z

id: DC_kwDOOMDw3M4Aw_md

The slides seem to reference OSCAL and OPA, but do you have public code the demonstrates the integration at the level of detail below the slide summary? I'd be interested, but that's the kind of thing I'd be looking for.  I saw the reference to to repositories with the separate pieces, but not integrated altogether.

(As an aside the lack of that level of detail is why stopped going to the workshops back in the day; and I'm not saying that's this presentation particular the organizer encourages it. And that's OK, but I think we're very interested in the nitty-gritty details in in the FedRAMP community work groups.)



## Comment 3

author: [github.com/ADD12](https://github.com/ADD12)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12704253](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12704253)

created: 2025-04-02T17:30:49Z

id: DC_kwDOOMDw3M4Awdn9

We have real time sensor data that needs to be used to compute in near real-time on local AI systems in our fog networks after we process and react data can be moved to a cloud for archiving or later simulation processing, so all auth must use a DTN protocol as real rime internet is too slow for our local AI to react.. Should we get our remote AI tokenized system certified with Fed Ramp to accept remote non-live data?

### Replies



#### Reply 1

author: [github.com/Cybonto](https://github.com/Cybonto)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12795195](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12795195)

created: 2025-04-10T18:22:33Z

id: DC_kwDOOMDw3M4Awz07

@ADD12 : I understand your situation, but I would need more clarification on your question. Are you:
- Asking about compliance requirements or the need for addressing a potential security gap, or both?
- Asking about whether secured remote AI tokenized system should be a KSI?

I also wonder if you and others could discuss more about the costs vs benefits, and challenges of securing remote AI systems.



#### Reply 2

author: [github.com/ADD12](https://github.com/ADD12)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12797548](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12797548)

created: 2025-04-11T00:12:41Z

id: DC_kwDOOMDw3M4Aw0Zs

Hi, thanks yes. I need to know what compliance is required when back hauling data to a Cloud will be compliant with FEDramp. We will be using video with computer vision from Data buoys and need to process locally first and only backhaul actual data our AI system has decided to use.
Data would move from our devices to a carrier and then to the cloud. Was concerned with Man in the middle attacks if we only use ssl.
Data cost via Satellite or cell link are both too expensive to send raw video to a CSP. https://www.sofarocean.com/products/spotter



#### Reply 3

author: [github.com/AnievesPANW](https://github.com/AnievesPANW)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12844901](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12844901)

created: 2025-04-15T17:12:38Z

id: DC_kwDOOMDw3M4Aw_9l

Just my .2 here. If you are shipping data out to a carrier, and then to the cloud, it sounds like every piece of that data flow would need to be considered part of your boundary and "get certified" as you stated in your post. If we look at this as you are taking FedRAMP production data, sending it somewhere, and then hauling it back in for use, that "somewhere" would need to be in an ATO'd environment or become part of yours.

Someone please correct me if I'm wrong. 



#### Reply 4

author: [github.com/sunstonesecure-robert](https://github.com/sunstonesecure-robert)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12845460](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12845460)

created: 2025-04-15T18:09:26Z

id: DC_kwDOOMDw3M4AxAGU

2 things to unpack - under the omnibus rule that the AO has to approve everything anyway, so the AO's opinion is all that matters at the end of the day - if they don't believe your story, all bets are off :)

> concerned with Man in the middle attacks if we only use ssl.

if you use *correct* TLS 1.3 and NSA approved ciphers then you only need to worry about NSA eavesdropping.  Apart from that - if they don't believe TLS is sufficient, then banking, payments, healthcare all should stop using computers.

That said, if there's defense in depth requirements - a good thing to be sure - then encrypt the payloads before sending via TLS. Google Confidential Computing enclaves aka TEEs. 

> every piece of that data flow

AOs can approve an agency specific deviation/OR.  If they accept that you 1) authenticate end-to-end and the non-FedRAMP carrier/middleman does not require proxied certs, and 2) if you do encrypt the payload in a CC/TEE manner where the carrier (or cloud) would not have the ability to decrypt even if they tapped the line, the CPU, north/south bridge bus, and sucked in all the encrypted traffic not in secure on-chip memory (assuming you believe no backdoors in FIPS crypto...and no absolute zero lab with lasers - Google it) I don't see why an AO would otherwise object.  Sure you can layer on SA and SR controls about the ownership and security posture of the carrier. But if data is encrypted, it's encrypted.  If we don't believe encryption protects data, then multiple encryption doesn't do much good in a Big-Oh sense.  If we believe FIPS CMVP crypto is susceptible to practical (or near practical quantum) ciphertext attacks and side channel attacks, then we had best assume breach and plan accordingly.

Tell the story to the sponsor/AO. If they understand the risk and you have a good story about how you protect against the threat/attack model, I don't see why they wouldn't approve.  



#### Reply 5

author: [github.com/dan-fedramp](https://github.com/dan-fedramp)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12858688](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12858688)

created: 2025-04-16T18:40:57Z

id: DC_kwDOOMDw3M4AxDVA

> Tell the story to the sponsor/AO. If they understand the risk and you have a good story about how you protect against the threat/attack model, I don't see why they wouldn't approve.

This.  

On a somewhat related note... I often use the analogy of a computer at the bottom of the ocean being 100% secure from a Confidentiality and Integrity perspective but failing to meet Accessibility. I find it amusing that you are talking about (I think) compute devices on buoys and someone being concerned about an attacker gaining physical access to the device and discovering  how foggy it is at the location. Data they could also collect by, you know, looking around at that point.  

Obviously the integrity of the data is much more important but there are many ways to protect against data manipulation. To restate what everyone else has said here, this is a great example of a system with unique security challenges and a unique risk profile. It should be evaluated by knowledgeable subject matter experts in context. This will likely provide a much better outcome than strict evaluation against a standard that is designed for "most" systems.



#### Reply 6

author: [github.com/ADD12](https://github.com/ADD12)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12879330](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12879330)

created: 2025-04-18T15:15:57Z

id: DC_kwDOOMDw3M4AxIXi

Our Data Buoys must do compute locally first, so we have our Fog network secured. Depending on the location, Data could transmit back to a Cloud across multiple carriers. We have some with satellite connections and some will be cellular or Lora radio. We can encrypt using TLS 1.3 but have seen Defcon17 of Moxie Marlinspike defeating SSL with Man in the Middle attacks so think most SSL can be broken. With multiple paths across many different carriers. Q: if we run an actual traceroute I can see multiple hops where data is transported back to a Secured Cloud, will FedRAMP require we secure the whole path to a cloud? or maintain a fixed path?




#### Reply 7

author: [github.com/dan-fedramp](https://github.com/dan-fedramp)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12899949](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12899949)

created: 2025-04-21T15:31:53Z

id: DC_kwDOOMDw3M4AxNZt

Could you implement some defense in depth solutions like monitoring for abnormalities in the data transmission? Do you have a solution to monitor for and alert if the compute device on the buoy is tampered with?

This kind of novel solution highlights the value of KSIs. Many traditional NIST controls will not apply to a system like this but there are also many new security threats that must be addressed. The KSI model will require the CSP to explain and demonstrate how they are protecting the system rather than demonstrating compliance with a specific set of requirements.



#### Reply 8

author: [github.com/ADD12](https://github.com/ADD12)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12914902](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12914902)

created: 2025-04-22T21:05:32Z

id: DC_kwDOOMDw3M4AxRDW

For our Spotter buoy live data It's streamed usually with a satellite or cell service, and we have a traditional SSL to an API to pull data back down into a website to display conditions. The computer vision part of the data is two large to move by satellite raw, and it needs to be processed locally. We use a IOTA Tangle to Auth the device sending the data before it's processed. 
From GIThub:
    Fog Computing Mesh Network:
        A decentralized network where each device (sensor or video node) processes data locally before sending it to a central system.
        Devices in the network communicate and verify each other's data.

    IOTA Tangle:
        A distributed ledger technology (DLT) that uses a directed acyclic graph (DAG) instead of a traditional blockchain.
        Provides consensus and immutability for the data written to the ledger.
        Designed for Internet of Things (IoT) applications.

    Trinary Authentication:
        IOTA operates on a trinary system (as opposed to binary), which aligns with its lightweight nature for IoT devices.
        Devices confirm data authenticity through mutual verification by at least two other devices in the network.

    AI Processing:
        The authenticated data is processed locally or centrally using AI algorithms for decision-making or analytics.

    Immutable Audit Trail:
        Validated data is written to a side chain ledger powered by IOTA for future auditing and traceability.




## Comment 4

author: [github.com/JBockmann](https://github.com/JBockmann)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12705635](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12705635)

created: 2025-04-02T19:12:36Z

id: DC_kwDOOMDw3M4Awd9j

I'm going to do my best to break down and categorize my thoughts; some of which will probably overlap with others (great minds think alike or so I hear).

First let's look at what we're attempting to gather _from_.
1. CSP hosting env (AWS GovCloud, Azure for Government, etc)
2. CSP product or offering (potentially bespoke, best case AWS firehose > SecLake with OCSF or similar)
3. Business SOP's and Policies.

Next (per the question), let's look at potential issues with each of these sources:

1. **CSP hosting env:** This is where we would potentially see the best benefit, as it's most likely the easiest to develop and publish standards or tools that allow for a relatively simple solution. An example of existing similar tool that could be leveraged as a part of this: AWS FedRAMP Compliance reporting (through Security Hub, Compliance, or Artifact).
2. **CSP offering:** This is a large task, and I won't be able to do it justice here, but I can think of a few points worth mentioning. This will depend on the control family in question. Something like AU (given the CSP uses an open/standard format), can be done. Tools could be built to automate validation of compliance to a degree. However, SC would be much more difficult. How exactly do you validate, across all offerings, that the resources are adequately segmented and not shared? For AU at least, it will likely be best to try and develop standards first before broaching the discussion of the tools and methods. Standards that govern audit formats, methods of ingestion for analysis by FedRAMP, etc.
3. **Business SOP's and Policies:** This task is also large and would require a significant change on the business side as to how the policies are handled and managed. Most SMB businesses today tend to have their policies be a set of word documents with low amounts of structure. To accurately validate compliance in this regard, it would require either the use of a GRC tool (which tend to cost too much for SMB), or be forced to use FedRAMP policy templates which can be validated verbatim (difficult to implement within SMB).

Also, possibly a dumb question, but is this project at all meant to influence or alter the way 3PAO's engage with FedRAMP packages and thus the evidence? In other words, when we talk about collecting evidence, is that only for FedRAMP's purposes, or are we also anticipating this can/will be used for evidence gathering for an auditor?

### Replies



#### Reply 1

author: [github.com/kamamanh](https://github.com/kamamanh)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12705670](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12705670)

created: 2025-04-02T19:19:28Z

id: DC_kwDOOMDw3M4Awd-G

> CSP hosting env: This is where we would potentially see the best benefit, as it's most likely the easiest to develop and publish standards or tools that allow for a relatively simple solution.

I believe there are some CSPs who are not making use of the big IaaS providers, but are running their own hardware in CoLo's. I think that needs to be considered as well, even if they are a minority in the market at current.  

I do agree that standards needs to be the starting point. And perhaps minimum viable product standards that we iterate on. 



#### Reply 2

author: [github.com/dan-fedramp](https://github.com/dan-fedramp)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12706708](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12706708)

created: 2025-04-02T21:44:27Z

id: DC_kwDOOMDw3M4AweOU

The FedRAMP team understands that there is going to be an 80/20 challenge in adopting this new paradigm. We are hoping to find solutions that work today for the majority of simple use cases but do not close us off from the edge cases in the future. 



#### Reply 3

author: [github.com/JBockmann](https://github.com/JBockmann)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12718610](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12718610)

created: 2025-04-03T20:33:21Z

id: DC_kwDOOMDw3M4AwhIS

@dan-fedramp I was responding to the prompt/question proposed and supplying potential issues with the desired goal. Are you instead looking for potential solutions?



#### Reply 4

author: [github.com/dan-fedramp](https://github.com/dan-fedramp)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12795271](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12795271)

created: 2025-04-10T18:32:03Z

id: DC_kwDOOMDw3M4Awz2H

Hey @JBockmann, I was addressing @kamamanh very legitimate concern. Thanks to both of you for your contributions. 



#### Reply 5

author: [github.com/sunstonesecure-robert](https://github.com/sunstonesecure-robert)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12881365](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12881365)

created: 2025-04-18T20:08:08Z

id: DC_kwDOOMDw3M4AxI3V

> running their own hardware in CoLo's

Unless you are a Fortune 50 company - I think this is a very bad idea. But if you want to take that risk - fine - maybe we have a new FedRAMP for "cloud native" that is automated, AI-native, fast, and cheap.  The non-cloud-native can do it the much slower, harder, more expensive way.



## Comment 5

author: [github.com/JosephScarzone](https://github.com/JosephScarzone)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12706399](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12706399)

created: 2025-04-02T20:54:46Z

id: DC_kwDOOMDw3M4AweJf

_what technical challenges do you foresee in providing real-time, verifiable security evidence? _

Such a great question. Define the KSI's first, then allow CSP's to ascertain the "how". Doing this will naturally change things, and sparking innovation CSP by CSP. I see this as a good thing. Eventually, (I predict), solutions/products will be developed by companies to accomplish the KSI's, COTS-style, but until then, I believe it rightly belongs on the shoulders/heads of CSPs. We will know our environments better than anyone and know how to build processes and "Compliance-as-Code" to be able to report on the results for the KSIs. 

I feel this naturally will force CSPs to then define/document the "how", i.e. explain how they achieved the measure, and it should be ok to be customized, as long as it can be proven out to be complete and accurate representation of what the measure intends to report out. 

The second we try to force the how as a standard will ultimately cause the dominoes to fall haphazardly, losing trust in the methodologies established. 

My goal as a CSP is to be able to prove adherence to the standards as continuous and automated as possible to reduce assessment costs. Having clear and defined KSI's will help CSPs figure out how to implement Compliance-as-Code within our environment(s), even if it means tweaking existing processes to support automation. 

### Replies



#### Reply 1

author: [github.com/kyhu65867](https://github.com/kyhu65867)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12718368](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12718368)

created: 2025-04-03T20:01:10Z

id: DC_kwDOOMDw3M4AwhEg

I'm happy to hear you say this-- one of our goals with 20x is to create the opportunity for industry competition and innovation. One of our main concerns as we work to develop the KSIs is making sure that industry has the tools and resources necessary to measure different indicators. It's not just a matter of what FedRAMP or agencies would like to see-- it's definitely a matter of what is possible without putting too much of a cost burden on CSPs right now. Your insight is very much appreciated!!



#### Reply 2

author: [github.com/JosephScarzone](https://github.com/JosephScarzone)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12718502](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12718502)

created: 2025-04-03T20:17:39Z

id: DC_kwDOOMDw3M4AwhGm

The cost burden will be welcome as long as that cuts costs in other things, i.e. Assessments - Initial and Annual. All of this has to change, and as a CSP, I would hope massively reduce or eliminate costs down to the bear minimum. Validating automation mechanisms for KSIs perhaps can be a focus of a new independent assessment requirement. Not necessarily as we do today, control-by-control, scratching surfaces, that provide little value overall, and just burdens all of us with "paperweight"...to what end? :-)

KSIs and automation/compliance-as-code should literally change everything. That is my hope and why I share my thoughts. :-)



#### Reply 3

author: [github.com/sunstonesecure-robert](https://github.com/sunstonesecure-robert)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12804697](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12804697)

created: 2025-04-11T14:15:02Z

id: DC_kwDOOMDw3M4Aw2JZ

> The cost burden will be welcome as long as that cuts costs in other things, i.e. Assessments - Initial and Annual. 

This. move the costs that are currently spent doing point-in-time assessments to the automation. the ROI is much higher AND the defensive value is order of magnitudes higher.





## Comment 6

author: [github.com/austinsonger](https://github.com/austinsonger)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12707746](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12707746)

created: 2025-04-03T01:10:42Z

id: DC_kwDOOMDw3M4Aweei

@kyhu65867 @jsantore-cgc @aj-stein-gsa @kamamanh @aparkar-panw @shah @JosephScarzone @dan-fedramp @JBockmann

### 1. Trustworthiness and Verification
As @jsantore-cgc mentioned, trust is a fundamental challenge. Even with continuous monitoring, ensuring that the evidence reported is accurate, verifiable, and tamper-proof is critical. This requires:
- **Attestation Mechanisms:** Ensuring evidence collection tools are verified through digital signatures or attestation mechanisms to prevent tampering. Leveraging technologies like RFC3161 timestamping (as mentioned by @aj-stein-gsa) or blockchain-based integrity verification could enhance credibility.
- **Transparency:** CSPs and third-party tools need to provide transparency about what is being monitored and how compliance is assessed. This could be achieved by publishing APIs or standards for evidence collection mechanisms.

### 2. Standardization of Policies as Code
As @shah pointed out, moving towards a **“Policies as Code”** approach is crucial. Defining clear and consistent **DSLs (Domain-Specific Languages)** will be necessary to ensure interoperability between CSPs, assessment tools, and auditors. The challenge lies in:
- Selecting a flexible and extensible DSL that supports various cloud environments (AWS, Azure, GCP, on-premises).
- Creating standards that can be applied consistently across different platforms while allowing customization for unique compliance requirements.

### 3. Cost and Scalability Concerns
@kamamanh brought up a valid point about cost. Smaller CSPs or those with bespoke architectures may not have the resources to implement advanced continuous monitoring solutions. Potential approaches include:
- Providing **baseline standards** that CSPs can implement with minimal cost.
- Developing **open-source tools** or APIs that can be adapted to various environments to reduce dependency on expensive third-party tools.

### 4. Mapping Evidence to FedRAMP Requirements
It is critical to clearly define how evidence collected by various tools maps back to FedRAMP requirements. For example:
- **Automating Control Verification:** Establishing mappings between NIST 800-53 controls and evidence collected through automated tools (e.g., using OPA or other compliance-as-code solutions).
- **Continuous Monitoring Frameworks:** Providing frameworks or guidelines that specify how continuous evidence collection maps to specific FedRAMP controls.

### 5. Alignment with 3PAO Processes
As @JBockmann noted, it's important to consider how this shift affects the engagement model with 3PAOs. Ensuring that evidence gathered continuously is usable and verifiable by auditors will require:
- Developing standards for presenting and exporting evidence for assessment.
- Ensuring evidence is **auditable** and can be verified independently by 3PAOs.

### 6. Integration with Existing Tools
Finally, we should consider how existing tools like AWS Security Hub, Azure Policy, or Google Cloud's Security Command Center can be leveraged and extended to meet FedRAMP’s requirements. Building integrations or adapters for these platforms could significantly reduce the friction of adopting real-time evidence collection.

Would it be helpful if I provide a draft framework for aligning continuous monitoring outputs with FedRAMP requirements, including a proposed schema for presenting evidence in a machine-readable format? 


### Replies



#### Reply 1

author: [github.com/kamamanh](https://github.com/kamamanh)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12728540](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12728540)

created: 2025-04-04T16:44:33Z

id: DC_kwDOOMDw3M4Awjjc

I like the above.  Being able to tie conmon automation to assessment control validation is critical.  

I also appreciate the recognition of the cost issue. For us, it's not just the $$$$ tooling licenses, but also people time. I'm a big proponent of opensource, but you own upgrades/patching/maintenance/etc and often require a more costly tier of person to do the work.  

Being able to leverage existing services within the big cloud providers would certainly be helpful. To date, the offerings I've seen required a fair bit of customization to get them to present an accurate picture of FedRAMP posture. I don't think anyone is keen on picking up a compliance automation tool that creates need for deviations. 

Having a (free, ideally) knowledgebase of "here's how to do X" would go a long way towards adoption because it'll cut down the research time and allow CSPs to better estimate the cost associated with adoption.  I know the PMO can't do that, and CSPs have been understandably cagey about sharing technical details, but it would be helpful to see examples of specific checks, tools, etc, that have been deemed acceptable evidence on audit.  I am hoping we can get that in these discussions, or maybe somewhere else.  




#### Reply 2

author: [github.com/aj-stein-gsa](https://github.com/aj-stein-gsa)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12730061](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12730061)

created: 2025-04-04T19:50:24Z

id: DC_kwDOOMDw3M4Awj7N

> * **Attestation Mechanisms:** Ensuring evidence collection tools are verified through digital signatures or attestation mechanisms to prevent tampering. Leveraging technologies like RFC3161 timestamping (as mentioned by @aj-stein-gsa) or blockchain-based integrity verification could enhance credibility.
> * **Transparency:** CSPs and third-party tools need to provide transparency about what is being monitored and how compliance is assessed. This could be achieved by publishing APIs or standards for evidence collection mechanisms.

I am a big fan of those principles, @austinsonger. Starting next week I may begin work on some notional prototypes to that end so interested parties can see _a perspective_ (not a single official FedRAMP product or perspective, just AJ's view. 😄)
 
> ### 2. Standardization of Policies as Code
>
> * Selecting a flexible and extensible DSL that supports various cloud environments (AWS, Azure, GCP, on-premises).
> * Creating standards that can be applied consistently across different platforms while allowing customization for unique compliance requirements.

One of the real challenges I have seen in the community (and would to stand corrected by others in the community)  if the more flexible or robust the DSL, the more elaborate the programming language and tooling needed. It would be cool to know your take and those in the community about what "supports various cloud environment" requires with some level of practical detail.

> ### 3. Cost and Scalability Concerns

Agree with all of this, economics is going to be an interesting theme to challenges these CWGs can hopefully solve. 🤞 

> ### 4. Mapping Evidence to FedRAMP Requirements
> It is critical to clearly define how evidence collected by various tools maps back to FedRAMP requirements. For example:

It would be good to hear more about why assessment criteria need to map back to NIST controls. How would you do that? I have found most solutions that are automation-heavy or assisted very vague or too precise and require heavy maintenance. Have you seen counterpoints?
 
> ### 6. Integration with Existing Tools
> Finally, we should consider how existing tools like AWS Security Hub, Azure Policy, or Google Cloud's Security Command Center can be leveraged and extended to meet FedRAMP’s requirements. Building integrations or adapters for these platforms could significantly reduce the friction of adopting real-time evidence collection.

It would be very cool to experiment and prototype with this kind of integration, excellent points!





#### Reply 3

author: [github.com/sunstonesecure-robert](https://github.com/sunstonesecure-robert)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12804751](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12804751)

created: 2025-04-11T14:18:58Z

id: DC_kwDOOMDw3M4Aw2KP

> * Providing **baseline standards** that CSPs can implement with minimal cost.

I would tweak this to be: provide a threat model that CSPs can map to their env and then implement the controls to address those.  choose the controls from the baseline that make sense for the threat model - and - adapt as the threat model changes.

1 year ago would we take seriously the threat of a completely fake video interview for a developer? No - How many CSPs laughed at the IA identity proofing controls.  Today - very much yes! Threats evolve. Baselines are good resource but the threat model is the key.



#### Reply 4

author: [github.com/sunstonesecure-robert](https://github.com/sunstonesecure-robert)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12804772](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12804772)

created: 2025-04-11T14:20:21Z

id: DC_kwDOOMDw3M4Aw2Kk

> Having a (free, ideally) knowledgebase of "here's how to do X" 

That is explicitly goal of the CNCF Compliance WG - there is a growing library of open source tools to do this





#### Reply 5

author: [github.com/sunstonesecure-robert](https://github.com/sunstonesecure-robert)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12804893](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12804893)

created: 2025-04-11T14:28:40Z

id: DC_kwDOOMDw3M4Aw2Md

> require heavy maintenance

not as much heavy maintenance as reading a 2000 page SSP or a POA&M with 300 rows :)

all kidding aside - the model of having bespoke integrations is fragile, yes.  But this is not necessary. All the NIST 800-53A criteria can be "mapped" (really interpreted) as cloud APIs and CSP APIs.  Even human processes now spin off a tremendous amount of digital API available data.  Have a meeting? I bet there's a transcript + calendar invite/attendance + notes + Jira tickets.  Have a manual review? Then check a box in a GHI.  All that rich data can be collected automatically without "connectors" and just managed as any other data with ETL tools and now LLM based code.

Yes - APIs change. But typically the speed of those changes is on the order of months not weeks or days, and the controls themselves rarely change so the interpretation of control <-> API evidence isn't that hard.  

However I agree that mapping control <-> evidence is backwards. First map threats <-> controls and decide what "evidence" the bad guys would generate for each threat and look for that evidence. Then - when there is NO evidence you are compliant :)  That's  how we should do audits - 30 seconds and you're done if you are doing the job well.    



## Comment 7

author: [github.com/gmengelberg](https://github.com/gmengelberg)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12759055](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12759055)

created: 2025-04-08T04:10:00Z

id: DC_kwDOOMDw3M4AwrAP

I will try to keep my list concise and focused on automated mechanisms to capture assessment evidence.

1. _point-in-time_ vs. _real-time_:  In this use case, I assume you mean point-in-time.  Real-time implies the generation and communication of compliance data triggered by events occurring in the system.  Real-time is best suited for monitoring.  Point-in-time is best suited for assessments (e.g., initial, annual, SCR) as it represents a snapshot of the system. The snapshots can be initiated based on events, a schedule, or manually.
2. Agents:  For real-time data, VMs would require an agent to be installed.  This would require a solution that can run on multiple platforms and would require long-term maintenance. In my opinion, this is not a good solution given that point-in-time data can easily be captured using existing scan tools.
3. Agentless: For real-time data, the CSP would need to develop an event-driven architecture to pass along events related to changes in compliance. This would be complex, costly, and difficult to standardize.  Point-in-time data would be far easier to capture using a cloud scanning tool (e.g., Prowler)
4. Inventory coverage: Whichever tool is used, there would need to be the ability for the 3PAO to verify that 100% of the in-scope configuration items were scanned.
5. Access Control:  Ensuring the credentials used have the required permissions to meet depth and breadth requirements may be challenging in some environments.
6. Cryptography: Standardizing and implementing the approach used to protect and validate the integrity of the results (e.g., encryption, hashing, digital signatures).
8. Parameters: Ensuring that organization-defined parameters can be used in place of FedRAMP default values.

### Replies



## Comment 8

author: [github.com/deepakantiya](https://github.com/deepakantiya)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12797183](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12797183)

created: 2025-04-10T22:50:48Z

id: DC_kwDOOMDw3M4Aw0T_

Providing real-time, verifiable information security evidence is a complex task that comes with several technical challenges considering there are multiple dependencies within a CSP environment. The list is never ending but here is my take on few hurdles -

1. Data volume and speed: Security systems generate massive amounts of data—logs, network traffic, alerts—constantly and at high speed. Triaging and resolving this is a firehose exercise and significant cost spike if it goes near realtime effort.

2. Latency: Real-time systems need to minimize latency for collecting, analyzing, and presenting evidence as #1 above (for instance like a breach or anomaly) has to happen fast enough to enable immediate action.

3. Multiple source system/CSP: Security evidence often comes from diverse sources—firewalls, endpoint detection systems, cloud platforms, etc. These systems don’t always use standardized formats or protocols, making it hard to aggregate and verify data cohesively in real time. Best example scenario would be when an application is hosted in hybrid cloud environment.

4. Cost Resource Constraints: Not every organization has the budget for high-end hardware or software. Building a solution that’s both real-time and verifiable on limited resources is a practical challenge, especially for smaller entities.

Finally it comes down to adoption of the change as stated by others but not impossible to achieve with the right approach.

### Replies



#### Reply 1

author: [github.com/sunstonesecure-robert](https://github.com/sunstonesecure-robert)

url: [https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12804998](https://github.com/FedRAMP/automating-assessment-cwg/discussions/8#discussioncomment-12804998)

created: 2025-04-11T14:34:30Z

id: DC_kwDOOMDw3M4Aw2OG

> ...volume and speed...

I agree they generate a massive amount of noise.  This needs to be fixed.  Bad guys hide in the noise. However you can flip the script and define what you are looking for first, and alert on those, and then you let the cloud control plane manage the firehose.

> latency

but you have to baseline to the latency of manual processes today. Perfect is not the goal.  Google for the published data but the average time for a real world attack to be detected today is on the order of *months* not minutes.  If we could move that down to *weeks* we would be orders of magnitudes better.

> use standardized formats or protocols

1 year ago I would have agreed - now - LLMs make writing conversion code trivial.  But yes - on-prem is harder and older and icky.  Agencies (and many vendors) wrung hands about moving to the cloud for a decade.  We pay the price for that lack of vision.  However even most legacy control planes now integrate with some form of cloud-connected management plane. Not all. But 80/20 as others have said. 

> especially for smaller entities.

fine but think of it from the agency's (or taxpayer's) perspective - the smallest vendor is often the target bad guys use to get into a larger value system.  So there has to be threat defenses at the weakest link.  There's just a cost of doing business if you are going to be trusted with Federal (taxpayer) data.  Would you accept that from a car manufacturer - airbags, seat belts are just too complex and expensive...

