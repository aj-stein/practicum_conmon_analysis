{
  "id": "D_kwDOOxfoic4AgAIE",
  "url": "https://github.com/FedRAMP/community/discussions/16",
  "title": "FedRAMP 20x Phase One Pilot Draft Submission -Meridian Knowledge Solutions",
  "body": "This submission was published early \u2014 prior to formal 3PAO (Fortreum) sign-off \u2014 as part of a collaborative effort with Fortreum to embrace the transparency and public participation ethos of the FedRAMP 20x initiative.\r\n\r\nWith mutual agreement, we\u2019re treating this public release as a draft submission, with the goal of gathering meaningful feedback and enabling iterative validation ahead of the final milestone.\r\n\r\nTo our knowledge, this is the first 20x submission being actively assessed in public, using GitHub as both a trust interface and audit mechanism. Our 3PAO has forked the private repository and is performing validation via tracked commits, Issues, and Pull Requests \u2014 including draft attestations for each KSI.\r\n\r\nWhile the package does not use OSCAL, it is purpose-built for auditability, traceability, and real-time validation, and includes:\r\n\r\n1. A machine-readable KSI validation file\r\n2. Git-tracked evidence references with commit SHA and timestamps\r\n3. A live dashboard showing assertion status, evidence freshness, and validation logic\r\n\r\nWe recognize this differs from traditional submission formats \u2014 and that\u2019s intentional. It is meant to demonstrate what 20x was designed to enable: continuous, verifiable, and publicly inspectable compliance. It also serves to show what smaller organizations \u2014 without dedicated GRC teams or analysts \u2014 can achieve with the right technical foundation and a commitment to transparency.\r\n\r\nWe welcome engagement via GitHub Issues and Pull Requests, and hope this submission contributes to the community\u2019s evolving understanding of trust-centered compliance and the upcoming S3AD standard.\r\n\r\nThis package is being evaluated in real time. Nothing here is final \u2014 and that\u2019s the point.\r\n\r\nhttps://github.com/Meridian-Knowledge-Solutions/fedramp_20x_public_submission_live",
  "author": "aburroughs",
  "created_at": "2025-05-22T03:45:10Z",
  "comments": [
    {
      "id": "DC_kwDOOxfoic4AyfpQ",
      "url": "https://github.com/FedRAMP/community/discussions/16#discussioncomment-13236816",
      "body": "Nicely done! I like the use of GitHub to track history, issues and make the assessment continuous and publicly accessible. I agree with you that this differs from traditional audit formats in the ways that 20x wants to be different -- continuous, automated, and low cost for CSPs. The SHA hashes are a nice touch we've been thinking about how to implement that and I really like what you've put together for it. I can see other CSPs being able to fork your repository and quickly get up and running with their own 20x repository and dashboard similar to what you've put together. \r\n\r\nOne point of feedback I have on your JSON schema is that it might be helpful to have multiple evidence artifacts within a single KSI validation. I noticed for KSI-CNA | Cloud Native Architecture | Configure firewalls/proxy servers to limit inbound and outbound traffic. you have two rows, one for (Inbound) and one for (Outbound). It makes sense to have multiple evidence artifacts for some of the KSIs that need to show more than just one file to demonstrate the KSI validation. \r\n\r\nIn your JSON schema you currently have \r\n\r\nPhase One Example\r\n`          \"evidence_reference\": \"evidence_v2/ksi-cna/waf_acl.json\"`\r\n    \r\nPhase Two Example\r\n`         \"evidence_reference\": \"evidence/ksi-cna/aws_shield_dos_protection.pdf\",`\r\n`         \"evidence_type\": \"static\",`\r\n\r\nIt may be helpful to change this to an array that could hold multiple evidence references which each have an evidence type so that multiple evidence artifacts (inbound firewall rules and outbound firewall rules) can be included within a single KSI validation instead of having to split out the KSI validations into multiple rows. \r\n\r\nOverall very impressed by your draft submission! Great work and thank you for contributing it! \r\n-- Isaac Teuscher (Paramify)",
      "author": "iteuscher",
      "created_at": "2025-05-22T16:13:36Z",
      "replies": [
        {
          "id": "DC_kwDOOxfoic4Ayfwk",
          "url": "https://github.com/FedRAMP/community/discussions/16#discussioncomment-13237284",
          "body": "@iteuscher Thank you so much \u2014 that feedback means a lot :)\r\n\r\n\r\n\r\nYou nailed exactly what we hoped this submission could model: a transparent, automatable, and replicable way for CSPs of any size to participate in 20x without heavy lift. The SHA-based evidence integrity and GPG-signed 3PAO validations were designed to unlock that kind of public trust signal - which frankly is really cool to see an audit happen this way. \r\n\r\n\r\n\r\nAnd you're right about the schema \u2014 grouping evidence references into an array (with type and path per artifact) is a great Phase Two refinement. We had originally split validations for clarity but this change would let us collapse KSI results while still keeping traceability intact.\r\n\r\n\r\n\r\nWe\u2019ll look into evolving the JSON structure to support that pattern. Thanks again for the thoughtful engagement \u2014 it means a lot to see the ecosystem moving in this direction together.",
          "author": "aburroughs",
          "created_at": "2025-05-22T17:04:17Z"
        }
      ]
    },
    {
      "id": "DC_kwDOOxfoic4AygkD",
      "url": "https://github.com/FedRAMP/community/discussions/16#discussioncomment-13240579",
      "body": "super dope!!  I love your KSI READMEs - gonna borrow those if ok with you.  Those should be *required* (@pete-gov )\r\n\r\nAnd you beat us to the punch with GitHub actions in the repo ;) \r\n\r\nKudos all around!",
      "author": "sunstonesecure-robert",
      "created_at": "2025-05-23T00:12:52Z",
      "replies": [
        {
          "id": "DC_kwDOOxfoic4Ayja4",
          "url": "https://github.com/FedRAMP/community/discussions/16#discussioncomment-13252280",
          "body": "Awesome - go for it! We do plan on adjusting the default (no license) state of our repo to be more in line with the sharing is caring model but we are waiting for more clarity on our submission before doing so. Thanks for the feedback! We appreciate the love",
          "author": "aburroughs",
          "created_at": "2025-05-23T23:16:56Z"
        }
      ]
    },
    {
      "id": "DC_kwDOOxfoic4Ay1s8",
      "url": "https://github.com/FedRAMP/community/discussions/16#discussioncomment-13327164",
      "body": "@aburroughs \r\n\r\nThank you for an early submission and doing so in the public.  We also wanted to commend you for initial approach, implementation, and your periodic updates to your example results with metrics for continuous reporting on the key security indicators (in the new GitHub repository, [Meridian-Knowledge-Solutions/fedramp_20x_public_submission_live](https://github.com/Meridian-Knowledge-Solutions/fedramp_20x_public_submission_live)).\r\n\r\nThe below comments and questions are meant to inspire more dialogue, both amongst the community and with Meridian Knowledge Solution\u2019s staff and their 3PAO to help iteratively enhance their submission. You should not construe the comments or questions as negative feedback or a positive endorsement.\r\n\r\n# Approach\r\n\r\n## Static Website as Dashboard\r\n\r\nWe really appreciate your use of a static website hosted on GitHub Pages. This platform choice enables you to dynamically generate current statuses for indicators and metrics by processing machine-readable JSON files from the same source repository. We consider this a pragmatic approach, with a preference for maintainability over time. Do you intend to continue with this approach for future submissions. Is it efficient and scalable, or are there challenges to this approach?\r\n\r\n## Git and GitHub for submission\r\n\r\nWe also appreciate your use of a git repository hosted on GitHub for describing validation methods for the KSIs, and methods in a structured JSON file over time to show not just the current state, but the history over time. This choice aligns well with the long-term philosophy of using the FedRAMP Key Security Indicators over time for continuous reporting. Do you see any challenges to this approach for short-term and long-term use? How will you manage the use of multiple automation tools and increased data added to the pipeline, with the CSP and 3PAO consuming the changing data, metrics, and resulting pass/fail/partial validation states for real-world use?\r\n\r\nIn this initial submission, certain sensitive evidence files and data are not included in the submission, and a reviewer is expected to open an issue. Is that the intention for future submissions? How will the CSP send the information requested in the issue? How will it scale for increased demand if you use this method for future submissions?\r\n\r\n## Failure Conditions\r\n\r\nWe also wanted to commend for itemizing a clear set of failure conditions to identify when you and the 3PAO determine a key security indicator is not met. If one or more conditions is not met but other criteria for the validation methods are successful, is that automatically a validation status of fail or partial?\r\n\r\n# Implementation\r\n\r\n## Digital Signing\r\n\r\nWe also support your use of digital signatures for confirming the integrity of artifacts. Your use of PGP keys with automated commit checking with GitHub Actions workflows is unique. We would like to fully understand the intent of the commit signing and how it signifies the 3PAO\u2019s assessment: only some of the commits are signed by the 3PAO, but many commits are signed by a CSP user\u2019s signing key (the default GitHub key; more on that below) and actions-user for automated GitHub Actions workflows. Both the CSP user and actions-user use the default PGP signing key GitHub defaults to for all users using the web interface, [web-flow.gpg](https://github.com/web-flow.gpg). How should FedRAMP reviewers and third parties interpret the signature of CSP commit after a previous commit specifically signed by a 3PAO staff member\u2019s custom PGP signing key? What does it mean if the 3PAO does or does not sign commits with KSI validation results for statuses of either failed or partial, not just true? What should it mean if the signature checking for the 3PAO signature in GitHub Actions fails but the data is already merged in a published branch the CSP and 3PAO share with FedRAMP for review? Some of these workflow considerations would help understanding the bigger context as part of a review.\r\n\r\n## Transparency of assessment activities\r\n\r\nThis submission also has a strong focus on transparency. This transparency and detailed information about assessment methods made the submission easy to understand. It did seem there was less detail in the specific assessment activities and validation methods, however. Many of the validation methods were the review of documentation or artifacts about the system implementation (diagrams, tool output) and say \u201c... requirement met.\u201d The verification status summarizes that the 3PAO completed the validation, but not what was checked and how. The repo does not include sensitive artifacts, so it is hard to spot check the assessment. Will you provide more detail in the evidence references and the notes in future submissions for the 3PAO\u2019s assessment activities? Are there challenges you would face with increasing \r\n\r\n## Data Format choices\r\n\r\nThe synchronized usage of JSON data and Markdown is very helpful and makes the submission accessible for different kinds of reviewers with differing levels of comfort in software development and data science. You did not provide a schema for the draft, so do you plan to publish a JSON schema or utilities for everyone to analyze the JSON data? Aside from that, do you have a mechanism to synchronize the Markdown and JSON data as they relate to one another? Will you continue to use it because it will scale well for a final 20x package, or would you do something differently?\r\n\r\nWe hope this feedback and the questions are constructive. We would love to hear from submitters and community participants as we move forward.",
      "author": "aj-stein-gsa",
      "created_at": "2025-05-31T04:04:59Z",
      "replies": [
        {
          "id": "DC_kwDOOxfoic4Ay5h9",
          "url": "https://github.com/FedRAMP/community/discussions/16#discussioncomment-13342845",
          "body": "@aj-stein-gsa Thank you for the thoughtful feedback. Below is our response by category:\r\n\r\n**Approach \u2013 Static Website as Dashboard**\r\n\r\nYes, we intend to continue with this model. The static GitHub Pages dashboard, backed by machine-readable JSON, is lightweight, version-controlled, and transparent. It scales well and lets reviewers instantly see changes and validation logic over time without needing proprietary systems or middleware.\r\n\r\n**Git and GitHub for Submission**\r\n\r\nWe intentionally designed our 20x submission around Git and GitHub to promote transparency, reproducibility, and automation:\r\n\r\n    Git provides immutable, timestamped evidence commits and version control across all artifacts.\r\n\r\n    GitHub Actions orchestrates the entire CLI validation lifecycle \u2014 from evidence collection, CLI execution, and assertion logic to failed report generation and PGP signing.\r\n\r\n    Private repo manages real-time automation and protected data, while the public repo surfaces safe, signed outputs (e.g., pass/fail states, interpreted CLI summaries, failure reports) \u2014 enabling 3PAOs and FedRAMP to observe validation results without requiring privileged access.\r\n\r\nTo manage increasing automation complexity:\r\n\r\n    We\u2019ve introduced auto-generated per-KSI documentation using a script that combines logic from cli_assertion_rules_full.py, the unified validation results, and our CLI command register.\r\n\r\n    CLI output is sanitized, truncated, and interpreted before publication to balance evidence transparency with security.\r\n\r\n    A formal JSON Schema has been published for unified_ksi_validations.json to help 3PAOs and FedRAMP reviewers validate structure, tooling compatibility, and long-term integration readiness.\r\n\r\nWe believe this architecture not only meets current FedRAMP 20x expectations but sets a scalable foundation for future iterations, including machine-readable assurance exchange and continuous assessment.\r\n\r\n**Sensitive Evidence and Issue-Based Access**\r\n\r\nInitially, we supported issue-based review for static files. Now that evidence is generated through automated CLI queries, we only use issue-based requests to explain failed assertions. Sensitive data is sanitized by default and never pushed. Failed KSIs are published in failed_ksi_report_readable.md, with contextual CLI output. This keeps the review model secure yet actionable.\r\n\r\n**Failure Conditions**\r\n\r\nOur logic enforces binary assertions: pass (\u2705) or fail (\u274c), driven by deterministic Python functions for each KSI. Each rule parses CLI command output (raw_output.json), applies structured logic (e.g. checking for the presence of resources, counts, values, or status codes), and returns a clear True/False result along with a human-readable explanation.\r\n\r\nPartial outcomes (\u26a0\ufe0f) are technically supported but intentionally disabled for now. Our current CLI-based rules are scoped to validate discrete security outcomes with high confidence. Once we expand to multi-command or hybrid evidence (e.g. combining AWS CLI and Terraform), we may revisit partials with weighted logic or fallback detection.\r\n\r\nThis approach ensures reviewers and 3PAOs can reproduce, audit, and trust the validation result without ambiguity.\r\n\r\n**Digital Signing**\r\n\r\nWe use commit signing across three trust tiers:\r\n\r\n    actions-user for validated, traceable automation\r\n\r\n    GitHub\u2019s web-flow.gpg for CSP commits\r\n\r\n    A custom GPG key for 3PAO-specific attestations\r\n\r\nWe\u2019ll provide clear guidance in our 3PAO_ASSESSMENT_GUIDE.md on how signatures should be interpreted \u2014 including what constitutes 3PAO review vs. automation. Commits are timestamped, signed, and reproducible.\r\n\r\n**Transparency of Assessment Activities**\r\n\r\nTo strengthen validation transparency, we auto-generate per-KSI documentation (docs/ksi_rules/) that includes:\r\n\r\n    KSI description and requirement\r\n\r\n    CLI command(s) executed\r\n\r\n    Rule logic and pass/fail criteria\r\n\r\n    Justification for evidence mapping\r\n\r\nThis addresses the feedback around \u201crequirement met\u201d phrasing by exposing the precise method of validation and what output is checked.\r\n\r\n**Data Format Choices**\r\n\r\nWe now publish:\r\n\r\n    unified_ksi_validations.json: full validation set\r\n\r\n    unified_ksi_validations.schema.json: schema for 3PAOs, CSPs, and GSA to verify formatting\r\n\r\n    failed_ksi_report_readable.md: markdown view of all \u274c validations\r\n\r\n    docs/ksi_rules/*.md: per-KSI rulebook\r\n\r\n    GitHub Actions trace and source CLI commands for reproducibility\r\n\r\nWe intend to continue using this model in future iterations, potentially expanding to:\r\n\r\n    A validation_bundle per KSI (like a mini JSON + signature + markdown trace)\r\n\r\n    Supporting OSCAL export or conversions for submission alignment",
          "author": "aburroughs",
          "created_at": "2025-06-02T11:53:37Z"
        }
      ]
    }
  ]
}