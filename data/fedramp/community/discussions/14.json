{
  "id": "D_kwDOOxfoic4AgAH_",
  "url": "https://github.com/FedRAMP/community/discussions/14",
  "title": "FedRAMP 20x Draft Pilot Submission (vanta.com)",
  "body": "Thread to post and discuss 20x Pilot Draft Submissions.\r\n\r\nTo kick things off Vanta has posted our Draft Submission. \r\n\r\nYou can find it on our Trust Center (https://trust.vanta.com) under Resources.",
  "author": "cooper-vanta",
  "created_at": "2025-05-20T15:39:53Z",
  "comments": [
    {
      "id": "DC_kwDOOxfoic4AyY1N",
      "url": "https://github.com/FedRAMP/community/discussions/14#discussioncomment-13208909",
      "body": "Just moving my comment here:\r\n\r\n@cooper-vanta\r\nInteresting. Kudos for both being the first, and doing something thorough. It's great to see an organization that put a lot of thought into this. I have some follow up questions/thoughts (for both Vanta and FedRAMP).\r\n\r\n\r\n1. If the intent was to provide status of the KSIs (and validated by a 3PAO), I think this is spot on. However, and this may be a big misunderstanding on my part, I always thought that the purpose was to have the output from various commands showing the actual technical validation of certain controls rather than just a status, and that's what always made me concerned about the viability of such a mechanism. For example, the results of some sort of query against a given control. Using the training KSI, showing the command pulling data from an LMS system showing that the 'role based training module' had 100 participation, or something like that. So one or two levels deeper than this. Not a criticism, by the way, more a calibration with the actual goal. I might have been overthinking this.\r\n\r\n\r\n1. If this is what FedRAMP is looking for, it seems that this is essentially a replacement of the old SRTM/Test Case Workbook. Rather than a 1400 item spreadsheet of doom, it seems sufficient for the 3PAO (and again, kudos to Schellman for their work here) to validate things and give them a pass/fail that is included in a JSON. https://github.com/FedRAMP people, is that the goal? If so, big thumbs up from me. That saves a ton of repetitive paperwork.\r\n\r\n1. I see this as a high level status, but if an agency or customer wanted to drill down, and say 'ok, show me the encryption stuff', what and how would that look like? Would that also be a machine readable thing, or that's where we revert back to SRTM, evidence, screenshots and the like.\r\n\r\n1. I like the fact that a 3PAO approved/reviewed this and how they did so. One of my initial concerns was 'oh look, here's a status dashboard and surprise surprise, everything is green.' The way Vanta and Schellman did this alleviated that concern.",
      "author": "jsantore-cgc",
      "created_at": "2025-05-20T15:46:31Z",
      "replies": [
        {
          "id": "DC_kwDOOxfoic4Ay9_6",
          "url": "https://github.com/FedRAMP/community/discussions/14#discussioncomment-13361146",
          "body": "Thank you @jsantore-cgc! I think showing the technical testing and validation would be ideal, but we were biased for speed and it was simpler to show a status at this stage.",
          "author": "arpita-vanta",
          "created_at": "2025-06-03T23:06:41Z"
        }
      ]
    },
    {
      "id": "DC_kwDOOxfoic4AyZXM",
      "url": "https://github.com/FedRAMP/community/discussions/14#discussioncomment-13211084",
      "body": "Strongly encourage other folks to chime in too, that's what community is all about! Just a drive by from me to say that some folks from the FedRAMP team are looking at this and will be providing some feedback shortly.\r\n\r\nI'm going to steal a tiny bit of thunder to be like...  did you just make me copy/paste JSON out of a PDF file?!?! \ud83e\udd23  \ud83d\udc79 ",
      "author": "pete-gov",
      "created_at": "2025-05-20T19:46:03Z",
      "replies": [
        {
          "id": "DC_kwDOOxfoic4AyaKW",
          "url": "https://github.com/FedRAMP/community/discussions/14#discussioncomment-13214358",
          "body": "How else would we digitally sign the output with our PIV \ud83d\ude1c",
          "author": "topperge",
          "created_at": "2025-05-21T02:48:35Z"
        },
        {
          "id": "DC_kwDOOxfoic4AycCD",
          "url": "https://github.com/FedRAMP/community/discussions/14#discussioncomment-13222019",
          "body": "Hey @pete-gov sorry we made you copy/paste. We biased for speed on our draft submission but we're addressing that.",
          "author": "cooper-vanta",
          "created_at": "2025-05-21T15:50:18Z"
        }
      ]
    },
    {
      "id": "DC_kwDOOxfoic4Aybc4",
      "url": "https://github.com/FedRAMP/community/discussions/14#discussioncomment-13219640",
      "body": "Hey @cooper-vanta, awesome work on the draft submission! Your Trust Center dashboard is legit impressive, and the JSON setup with Schellman\u2019s 3PAO stamp feels like a game-changer. Big nod to @jsantore-cgc\u2019s point\u2014if this swaps out the SRTM spreadsheet slog, I\u2019m here for it!\r\nThat said, I\u2019m a bit stressed thinking about how we\u2019d match this at our company, especially with our budget and dev resources stretched thin. A few questions and thoughts:\r\n\u2022  Custom Dashboards vs. Platforms: Are we all expected to build our own dashboards like Vanta\u2019s? That\u2019s a heavy lift for smaller CSPs like us. Could we use GRC platforms like Vanta, Hyperproof, or even AWS Audit Manager to host submissions instead? Any word on whether FedRAMP would greenlight that approach over custom websites?\r\n\u2022  Timeline and Technical Buffers: I know May 26, 2025, is for draft submissions, not the full rollout, but even getting a basic machine-readable KSI setup by then feels tight. Spinning up something like your dashboard could take us 2\u20133 years, factoring in dev time and budget approvals. Can FedRAMP build in buffers for the technical work? Like, maybe let CSPs submit simpler JSON outputs first and tackle fancier dashboards later?\r\n\u2022  Phased Rollout Plea: A \u201ccrawl-walk-run\u201d vibe would really help. Starting with bare-bones KSI data in Phase One, then scaling to robust dashboards in later phases, would give resource-strapped teams a shot at keeping up without scrambling.\r\n@pete-gov, any chance FedRAMP can share guidance on supporting CSPs with limited budgets or dev capacity? Also, curious how others are planning to tackle this: are you going in-house or leaning on third-party tools? Thanks for kicking this off, Vanta, and excited to hear more. ",
      "author": "c-weaver",
      "created_at": "2025-05-21T12:20:49Z",
      "replies": [
        {
          "id": "DC_kwDOOxfoic4AycEp",
          "url": "https://github.com/FedRAMP/community/discussions/14#discussioncomment-13222185",
          "body": "> use GRC platforms like Vanta, Hyperproof, or even AWS Audit Manager to host submissions instead?\r\n\r\n+1 - don't reinvent wheels that aren't your special sauce.  we look forward to using Vanta, et. al. for displaying our KSIs if that's a channel that this pilot opens up!\r\n\r\n> bare-bones KSI data in Phase One\r\n\r\nI hope there is room for \"agile\" iterations.  That said, the flip side is if the agencies don't see enough meat on the bones (sorry fellow veggiesaurs) then will they take 20x KSIs seriously? ",
          "author": "sunstonesecure-robert",
          "created_at": "2025-05-21T16:04:57Z"
        },
        {
          "id": "DC_kwDOOxfoic4AycG_",
          "url": "https://github.com/FedRAMP/community/discussions/14#discussioncomment-13222335",
          "body": "> Custom Dashboards vs. Platforms: Are we all expected to build our own dashboards like Vanta\u2019s? That\u2019s a heavy lift for smaller CSPs like us. Could we use GRC platforms like Vanta, Hyperproof, or even AWS Audit Manager to host submissions instead? Any word on whether FedRAMP would greenlight that approach over custom websites? \r\n\r\nThis is an [explicit goal of 20x](https://www.fedramp.gov/20x/), part of making it simple to automate the application and validation of FedRAMP security requirements: \"Industry will provide solutions and competition for varying business needs with FedRAMP aligning standards.\"\r\n\r\nWe are prioritizing GRC and compliance automation tools in the Phase One pilot for this purpose.\r\n\r\n > \u2022 Timeline and Technical Buffers: I know May 26, 2025, is for draft submissions, not the full rollout, but even getting a basic machine-readable KSI setup by then feels tight. \r\n\r\nThat timeline is not a deadline for submission, it is when we expect to _start_ accepting submissions. There's a note under the timeline that states \"FedRAMP will continue to accept Phase One submissions while preparing for Phase Two. Phase One submissions will remain open based on demand.\"\r\n\r\nAt some point we need to start focusing on Phase Two, and at some point we'll need to transition from a pilot to a real thing, but we haven't set any deadlines. FedRAMP can't make any promises or provide business advice about how to approach this, but in theory if we closed the Phase One pilot and opened a formal authorization path based on it then someone who didn't get their submission done during the pilot would just carry their work into formal authorization. \r\n\r\n> \u2022 Phased Rollout Plea: A \u201ccrawl-walk-run\u201d vibe would really help. Starting with bare-bones KSI data in Phase One, then scaling to robust dashboards in later phases, would give resource-strapped teams a shot at keeping up without scrambling. \r\n\r\nThat's pretty much what the pilot is. :)\r\n\r\n> @pete-gov, any chance FedRAMP can share guidance on supporting CSPs with limited budgets or dev capacity?\r\n\r\nIf 20x is successful then a year from now you will have access to a bunch of FedRAMP authorized tools and capabilities from host providers and third-parties to make this process as simple and painless as reasonably possible. FedRAMP can't provide business advice but if limited budget/capacity is a concern it seems reasonable to wait and see if things are successful to the point where limited budget/capacity is not a blocker.\r\n\r\n\r\n\r\n",
          "author": "pete-gov",
          "created_at": "2025-05-21T16:20:04Z"
        },
        {
          "id": "DC_kwDOOxfoic4Ay-AC",
          "url": "https://github.com/FedRAMP/community/discussions/14#discussioncomment-13361154",
          "body": "Thank you for the thoughtful feedback on Vanta's package @c-weaver ",
          "author": "arpita-vanta",
          "created_at": "2025-06-03T23:09:03Z"
        }
      ]
    },
    {
      "id": "DC_kwDOOxfoic4Aybf3",
      "url": "https://github.com/FedRAMP/community/discussions/14#discussioncomment-13219831",
      "body": "Nice job @cooper-vanta. To clarify, based on what I am reading in your submission, Schellman has not validated the completeness and accuracy of this output right? Do you know when  you will be submitting the work performed by Schellman?",
      "author": "troyfine",
      "created_at": "2025-05-21T12:38:21Z",
      "replies": []
    },
    {
      "id": "DC_kwDOOxfoic4AyckC",
      "url": "https://github.com/FedRAMP/community/discussions/14#discussioncomment-13224194",
      "body": "@cooper-vanta \r\n\r\nThank you for being one of the trailblazers and doing so publicly.  \r\n\r\nThe below questions/comments are meant to spur dialogue amongst the community while providing feedback to iterate/mature the submission in discussion.  This should by no means taken as negative feedback or an authorization/endorsement.  \r\n\r\n**Fidelity.**  \r\nOverall I believe this document provides a good framework to start with when it comes to understanding if the KSI\u2019s had been met.  What I do question is where are those portions that were done through automated technical validation?  For those checks that are/could be automated, where would a reviewer expect to see what parameters are validated within the environment?  I see the note section is used for those that may be more manual in nature or the generic overview.  There is a great discussion thread on what automated validation in this forum on automated means to prove MFA (with anti-phishing) in the discussion forum ([here](https://github.com/FedRAMP/automating-assessment-cwg/discussions/20)) along with some of the unspoken factors one must address when automating validation.  Things like not just proving that MFA is implemented correctly, but also proving other authentication methods are not implemented.   \r\n\r\n**Automated/Manual/Mixed Methods.**\r\nOf each of the compliance items, how does the current schema take into account, or identify those compliance checks that are automated and can be done routinely, vs those that can only be done manually?\r\n\r\n**Frequency/Dates.**\r\nShould each validation check, regardless of check type, have a frequency commensurate with type?  @rgutwein took a stab at this in another discussion forum ([here](https://github.com/FedRAMP/automating-assessment-cwg/discussions/4)), but an automated validation check could and probably should happen more than once a year as they should not be too resource intensive. But what does that balance look like?\r\n\r\n**Role of the 3PAO.**\r\nWith the concept being proposed, how does the role of the 3PAO change? Are they there to validate only those items identified for manual assessment (the JSON has a few notations for it)?  Are they there to simply validate the output? Or are they there beforehand to ensure those automated assessment parameters identified actually meet the KSIs (validating the process vice the output or control)?  Or is it a mix of these?  \r\n\r\nWe would love to hear the submitters and communities thoughts as we move forward.",
      "author": "paulagosta",
      "created_at": "2025-05-21T19:18:26Z",
      "replies": [
        {
          "id": "DC_kwDOOxfoic4AygGa",
          "url": "https://github.com/FedRAMP/community/discussions/14#discussioncomment-13238682",
          "body": "> Role of the 3PAO\r\n\r\nMy expectation is that we are to be involved in both adequacy & sufficiency validation--as that independent 3rd Party:\r\n1. Validate that the measurement(s) the CSP uses to determine the pass/fail/partial status of each KSI adequately covers all PMO-published aspects (& implied federal mandates) of the KSIs, and;\r\n2. Validate that the KSI results published by the CSP sufficiently cover the complete breadth & scope of the CSO seeking an ATO.\r\n\r\nI would love for the PMO to confirm/correct that expectation. \ud83d\ude01",
          "author": "tnnrjmsn-eit",
          "created_at": "2025-05-22T20:00:26Z"
        },
        {
          "id": "DC_kwDOOxfoic4Ayghn",
          "url": "https://github.com/FedRAMP/community/discussions/14#discussioncomment-13240423",
          "body": "1 seems crystal clear to me! 2 however seems a bit circular...I interpret the goal of 20x to be that the KSIs  themselves \"sufficiently cover the complete breadth & scope of the CSO\" insofar as PMO wants it to be covered. If that holds and thus if you have done 1, you have adequately and sufficiently covered the breadth and scope of the CSO...my $.02.",
          "author": "sunstonesecure-robert",
          "created_at": "2025-05-22T23:36:00Z"
        },
        {
          "id": "DC_kwDOOxfoic4AyiF5",
          "url": "https://github.com/FedRAMP/community/discussions/14#discussioncomment-13246841",
          "body": "As an example for my no. 2, thinking KSI-MLA.1, are all important event, activity, & change logs getting to the centralized SIEM, to include CSP-developed web, app, & data tier events, or is it just the IaaS connector set up in the SIEM? That sort of thing is what I have in mind when thinking about complete breadth & scope.\r\nOr, thinking KSI-IAM.4, does the CSO implement different, role-based permissions for the various _compute_ or just the interactive users/groups defined in the IdP (e.g., multiple AWS Instance Roles as appropriate)? As we know, the web compute shouldn't have the same permissions as your mgmt plane compute.\r\n[Edited to add another example.]",
          "author": "tnnrjmsn-eit",
          "created_at": "2025-05-23T13:10:51Z"
        },
        {
          "id": "DC_kwDOOxfoic4Ayib5",
          "url": "https://github.com/FedRAMP/community/discussions/14#discussioncomment-13248249",
          "body": "awesome, makes sense, thanks for clarifying! So , in the spirit of not just trying to map KSIs directly to controls - and instead measure the overall effectiveness of the totality of all security capabilities to deliver the characteristic the KSI wants, focused on the CIA of the Federal data - could I replay 1 and 2 to be thus: \r\n\r\n1. From the top down - assess that all the requirements of all KSI characteristics are measured, to ensure the CIA of the Federal data.\r\n2. From the bottom up, assess all Federal data (flows) across all components within the system to make sure that they are included in the KSI measurements.\r\n\r\nTo use your example: to meet KSI-MLA I need a SIEM and all its bells and whistles to monitor any/all data flows that touch Federal data, including web and data tiers (1), and for all my data sources, and the web apps that use those data sources, I need to measure how much coverage of their activity the SIEM is aware of (2).   So let's get super in the weeds - if I have a web app that renders red widgets and blue widgets but the SIEM only ingests logs the red widget events, my KSI would say boolean true -- I have a SIEM and use it effectively to monitor red widgets. But the 3PAO would find that the blue widget events logs are not being ingested and would call out that gap in the KSI assessment.  So if the CSO does indeed implement different, role-based permissions for the various compute AND interactive users/groups defined in the IdP (e.g., multiple AWS Instance Roles as appropriate) - then we will ONLY see those CloudTrail/audit log events in any/all the aggregate CloudTrail API events.  In other words, we will NOT see trail (success) events for the web compute using the same IAM permissions as the mgmt plane compute.\r\n \r\nIt makes sense to me that you would want both top down \"all KSI coverage\" and bottom up \"all event consistency\".",
          "author": "sunstonesecure-robert",
          "created_at": "2025-05-23T15:22:35Z"
        },
        {
          "id": "DC_kwDOOxfoic4Ayinp",
          "url": "https://github.com/FedRAMP/community/discussions/14#discussioncomment-13249001",
          "body": "> My expectation is that we are to be involved in both adequacy & sufficiency validation--as that independent 3rd Party:\r\n> \r\n> 1. Validate that the measurement(s) the CSP uses to determine the pass/fail/partial status of each KSI adequately covers all PMO-published aspects (& implied federal mandates) of the KSIs, and;\r\n> 2. Validate that the KSI results published by the CSP sufficiently cover the complete breadth & scope of the CSO seeking an ATO.\r\n\r\nThis is also the expectation and way we have been looking at the role of the 3PAO. Very concise and clear summary! Nicely written.\r\n-- Isaac Teuscher (Paramify)",
          "author": "iteuscher",
          "created_at": "2025-05-23T16:51:16Z"
        },
        {
          "id": "DC_kwDOOxfoic4Ayivp",
          "url": "https://github.com/FedRAMP/community/discussions/14#discussioncomment-13249513",
          "body": "> both top down \"all KSI coverage\" and bottom up \"all event consistency\"\r\n\r\nYep! That's the idea. \ud83e\udd13 \r\n\r\n> Very concise and clear summary! Nicely written.\r\n\r\nThanks! I was, dare I say, _inspired_ by the terminology used in my recent CMMC training. \ud83d\ude04 \r\nAnd, fwiw, HITRUST also uses a similar matrix (strength & coverage) to determine compliance.\r\n#TheMoreYouKnow\r\n\r\n",
          "author": "tnnrjmsn-eit",
          "created_at": "2025-05-23T17:34:53Z"
        },
        {
          "id": "DC_kwDOOxfoic4AyjKm",
          "url": "https://github.com/FedRAMP/community/discussions/14#discussioncomment-13251238",
          "body": "Inspiring CMMC training... that is a new one! \ud83d\ude02 \ud83d\ude04",
          "author": "iteuscher",
          "created_at": "2025-05-23T21:20:29Z"
        },
        {
          "id": "DC_kwDOOxfoic4Ay-AH",
          "url": "https://github.com/FedRAMP/community/discussions/14#discussioncomment-13361159",
          "body": "Great discussions here -\r\n\r\nFidelity: I think fully transparent technical testing results is an ideal end state that we are working towards with respect to KSI validation.\r\n\r\nAutomated/Manual: Questions around how to technically validate \u201cmanual\u201d evidence like documents is a deep question that would benefit from further community discussion and engagement.\r\n\r\n3PAO Role: I think the auditor will ideally validate manual items as well as the validity of technical tests and their results.",
          "author": "arpita-vanta",
          "created_at": "2025-06-03T23:10:03Z"
        }
      ]
    }
  ]
}