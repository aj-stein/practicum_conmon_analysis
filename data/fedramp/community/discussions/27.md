# Metadata

title:Best Practices and Lessons Learned in Multi-Agency Continuous Monitoring

author: [github.com/ryan-hodges-gsa](https://github.com/ryan-hodges-gsa)

url: [https://github.com/FedRAMP/community/discussions/27](https://github.com/FedRAMP/community/discussions/27)

created: 2025-03-31T16:14:41Z

id: D_kwDOOxfoic4AgALI



# Post

For Cloud Service Providers with multiple agencies associated with a single offering, how are you successfully navigating multi-agency continuous monitoring?  What are some of the complexities you have dealt with (e.g. approvals, charters, etc) and what are some lessons learned for some of the newer providers who are building their federal portfolio? 

# Comments




## Comment 1

author: [github.com/Bscudera9](https://github.com/Bscudera9)

url: [https://github.com/FedRAMP/community/discussions/27#discussioncomment-12679488](https://github.com/FedRAMP/community/discussions/27#discussioncomment-12679488)

created: 2025-03-31T17:24:54Z

id: DC_kwDOOxfoic4AwXlA

From the WG description: "meet the needs of agency security professionals to validate the risk posture of the CSO" 

Multi-agency ConMon expects validated ConMon which either needs to be a deeply technical automated implementation with verification checks or requires independent validation. We as a Working Group need to ensure that this purpose is front and center. The first step is continual assurance that the tools are effective from both breadth (inventory) and depth (auth, checks enabled, etc). 

Each CSP has deployed their own tools on top of their own stack which adds to the complexity of this challenge. We need to maintain a consistent and defensible reporting approach that is able to distill information from many sources and against many targets (different OS's, DBs, containers, Web Apps).

### Replies



#### Reply 1

author: [github.com/patrawBAH](https://github.com/patrawBAH)

url: [https://github.com/FedRAMP/community/discussions/27#discussioncomment-12679634](https://github.com/FedRAMP/community/discussions/27#discussioncomment-12679634)

created: 2025-03-31T17:36:53Z

id: DC_kwDOOxfoic4AwXnS

Agree with this.  The need for FedRAMP PMO/Board to pull back is understandable, but there will be an increased need for a rigid framework supporting streamline of consistent and repeatable data delivery to each Agency.  First and foremost in my mind is the eventuality that 3PAOs/other agencies will start getting the classic "but that's not how X Y Z 3PAO/Agency does it" causing confusion and contention.  In short, 3PAOs and Agencies are definitely going to need at least some guardrails (in the form of standardization) from the governing body to keep things from going haywire...



#### Reply 2

author: [github.com/sam-aydlette](https://github.com/sam-aydlette)

url: [https://github.com/FedRAMP/community/discussions/27#discussioncomment-12806603](https://github.com/FedRAMP/community/discussions/27#discussioncomment-12806603)

created: 2025-04-11T16:48:33Z

id: DC_kwDOOxfoic4Aw2nL

@patrawBAH @atfurman @kkettner @awilmo8 would something like a charter template and example RACI be helpful here?



## Comment 2

author: [github.com/JosephScarzone](https://github.com/JosephScarzone)

url: [https://github.com/FedRAMP/community/discussions/27#discussioncomment-12681139](https://github.com/FedRAMP/community/discussions/27#discussioncomment-12681139)

created: 2025-03-31T20:36:36Z

id: DC_kwDOOxfoic4AwX-z

I agree with all these comments, but with a slightly different perspective, but perhaps saying the same thing in a different way. Re-evaluating our stance on the control set, moving to a Control Domain approach, defining KSI's and then building automation (let's call it "Compliance-as-Code") based on automating/continuous reporting standards set by FedRAMP and this community can achieve the consistency and standardization we all are looking for. The glue in my opinion is in a workflow management tool that will guide users through the authorization process and continuous monitoring process. CSP's should then be able to implement "the new standards"  and automate as much of the testing as possible, aggregated to Control Domain KSI scores that help articulate the security posture of any CSO at any point in time. The Workflow Management Tool is a way for CSPs to interface with to incorporate these new automated/continous methods. And so yeah, some development there to do, because the fact remains is that multi-agency brings it challenges, and so CSPs want to demonstrate their compliance once, not 10 different times for 10 different agencies, and this presentation of security results should be as continuous as possible, so that each and every agency, whenever they want, can view the security posture, grades and results of a CSO at any point in time. 

### Replies



#### Reply 1

author: [github.com/JosephScarzone](https://github.com/JosephScarzone)

url: [https://github.com/FedRAMP/community/discussions/27#discussioncomment-12690109](https://github.com/FedRAMP/community/discussions/27#discussioncomment-12690109)

created: 2025-04-01T15:10:28Z

id: DC_kwDOOxfoic4AwaK9

To expand on my thoughts, I want to break down the conceptual presentation of a CSP’s security posture within what I’m now envisioning in my head as the FedRAMP Authorization Workflow Tool, structured on the premise of the following:
•	**CSP Security Posture Dashboard**

- o	Key concept – Dashboard view of all monitoring results, contains both current snapshot metrics and trends over time. 
- o	Scoring Metrics – we can do a lot here, but I’m imagining metrics that show:

- 	Control Domain KSI measures – i.e. Access Control Domain, Incident Response Domain, Risk Assessment Domain, etc. (only a Domain viewpoint, not every nitty-gritty control by control). 
- 	Scanning measures – i.e. counts, mitigation closures data, trends, etc.
- o	APIs – metrics updated per defined frequency we set, minimum monthly, but CSPs can set whatever frequency within 0-30 days, goal is to go as continuous real time as possible. KSI results are sent via API to automatically update the Dashboard. 
- o	Multi-layered – high-level presentation on main Dashboard view, with the ability to dive into any specific Control Domain metrics/KSI results. 

•	**Multi-Agency Invitations**

- o	Key concept – CSPs can invite Agencies to see their Security Posture Dashboard. Only invited Agencies and FedRAMP can see the CSP Dashboard. 
- o	The Invitation process involves simple workflow steps to obtain authorization, all orchestrated by the Workflow Tool. This connects all of us together within the tool itself, gaining major efficiencies, with possibilities of continuous improvement along the way. 
- o	Dashboard can then show authorizations in progress and with whom and present all authorizations as well. 
- o	The Workflow tool orchestrates annual review requirements where applicable and appropriate to do so.

•	**Shift to Control Domain perspective**

- o	Key Concept – move away from reporting control by control, instead, all results are represented by Control Domain. For instance, there are 1000+ test procedures in Rev5, High…. controls, sub-controls, etc., creating lots of paperwork and effort. My approach is to take it up one level and go Control Domain shift. KSI’s can now represent the key controls that must be considered (and hopefully automated), all contained within 1 Control Domain. Think about that – 18 Control Domains to update information for hitting on all key control domain themes within 1 instance of itself, not broken down by 20,30,40,50,60 different control objectives. We can still keep the same depth, just report on it from a Control Domain perspective, instead of a control-by-control perspective. 

•	**New Standard – Automation**

- o	Key Concept – Shift the standard to require CSPs to automate testing and results via API to the new FedRAMP Authorization Workflow Tool. Putting it on the CSPs will drive innovation across the industry. Soon, many companies will build solutions to interface with FedRAMP to ease continuous reporting/monitoring. CSPs will want to automate, which will significantly decrease costs and change the way independent testing is conducted, priced, etc. This could help alleviate costs for the CSP, motivating to be innovative and implement Compliance-as-Code mechanisms.

•	**CSP-driven Vulnerability Management**

- o	Scans should never leave a CSP’s environment. There is no value in sending sensitive information anywhere, so leave it in the CSP environment. 
- o	CSPs can then create access control very specifically to only those users and external users that need to see scan output.
- o	The goal is continuous monitoring and automating scan generation and analytics in a POAM that stays in CSP hands, but data is sent via API to populate the CSP Security Posture Dashboard within the FedRAMP workflow tool. 
- o	In the moment scanning and scan targets are based on code to ensure complete scans are performed against a complete an accurate inventory that is maintained within the cloud environment itself. The days of trying to maintain a spreadsheet for both inventory and POAM should be over. This is so archaic, and such a waste of our time to try to represent a constantly changing thing. We need to let technology/code/AI help us manage results. We want to get away from having to spend unbelievable amount of time translating machine results into a spreadsheet. 

I recognize this is a lot of conceptual high-level view of my thoughts on this and know that once we figure out the details for an Authorization Workflow, and how the presentation of security posture results is defined, I can see how this would really help all of us do our thing, our role in this process. FedRAMP, CSPs, 3PAOs, Agencies all have a role to play, and so we kind of have to step-up a few levels and look down to conceptualize how we want to structure the authorization workflow. I can assure you, if we align on the conceptual flow, all the details can then be filled in. I think this is why I’m trying to get my head around “orchestration” first, feeling it can set the stage for all the automation we want to manage this process. 
Anyway, hope this helps spark ideas…at least I can say I tried to share my ideas, for whatever it’s worth. 😊




## Comment 3

author: [github.com/austinsonger](https://github.com/austinsonger)

url: [https://github.com/FedRAMP/community/discussions/27#discussioncomment-12708229](https://github.com/FedRAMP/community/discussions/27#discussioncomment-12708229)

created: 2025-04-03T02:32:31Z

id: DC_kwDOOxfoic4AwemF

@ryan-hodges-gsa @JosephScarzone @Bscudera9 @patrawBAH


#### 1. **Standardized Control Domain Reporting**
Adopting a Control Domain approach for monitoring simplifies the process of aggregating and presenting results across multiple agencies.

- **Control Domain-Based Metrics:** Consolidate individual control requirements into broader domains, such as Access Control, Incident Response, and Configuration Management.
- **Customizable Metrics by Agency:** Allow agencies to weigh certain domains more heavily if they have specific compliance needs, while maintaining a consistent reporting structure.
- **Federated Reporting Model:** Provide agencies with tailored dashboards that draw from a unified, CSP-managed data source to reduce duplicative efforts.

---

#### 2. **Multi-Tiered Dashboard System**
A dashboard-centric approach provides both high-level summaries and detailed drill-down capabilities for authorized agency stakeholders.

- **Overview Dashboard:** Displays overall compliance scores, Control Domain health, and risk trends over time.
- **Agency-Specific Dashboards:** Allows agencies to customize their view of a CSP’s posture, focusing on their priority domains and metrics.
- **Automated Data Ingestion:** Feeds real-time metrics directly from CSP’s monitoring systems to agency dashboards via APIs, ensuring continuous reporting with minimal manual intervention.

---

#### 3. **Compliance-as-Code (CaC) Integration**
Building on the concept of Compliance-as-Code to drive consistency and repeatability in the assessment process.

- **Automated Evidence Collection:** Continuously collect evidence from monitoring tools and configuration management systems without human intervention.
- **Dynamic POA&M Generation:** Automatically generate POA&Ms based on detected vulnerabilities and track remediation efforts in real-time.
- **Unified Assessment Artifacts:** Provide agencies with consistent reports formatted according to FedRAMP's standards, but with the flexibility to add agency-specific requirements as needed.

---

#### 4. **Cross-Agency Authorization Management**
Addressing the challenge of providing a single security posture view to multiple agencies without duplicating work.

- **Invitation-Based Access:** CSPs can selectively invite agencies to view their monitoring dashboards.
- **Data Partitioning:** Ensure agencies can only view data relevant to their authorization without compromising confidentiality for other agencies.
- **Audit Trails and Activity Logs:** Maintain comprehensive logs of all agency interactions with the monitoring system for accountability.

---

#### 5. **Centralized API Framework**
Implementing a standardized API framework to streamline communication between CSPs and agencies.

- **JSON & OSCAL Support:** Provide machine-readable formats to facilitate ingestion by agency tools.
- **On-Demand Reporting:** Agencies can query the CSP’s monitoring system directly for real-time data.
- **Interoperability with Existing FedRAMP Tools:** Ensure seamless integration with established reporting and monitoring frameworks.


### Replies



## Comment 4

author: [github.com/Leah-GovRAMP](https://github.com/Leah-GovRAMP)

url: [https://github.com/FedRAMP/community/discussions/27#discussioncomment-12806166](https://github.com/FedRAMP/community/discussions/27#discussioncomment-12806166)

created: 2025-04-11T16:08:04Z

id: DC_kwDOOxfoic4Aw2gW

Serving multiple agencies, we have found the StateRAMP (dba GovRAMP) ConMon Escalation Policy and process to be extremely valuable for providers and the participating government agencies.  The GovRAMP PMO is centralized so that the provider is reporting with the PMO team directly. The PMO team generates an executive summary each month of the product's ConMon that includes any significant changes, as well as relevant POA&M items.  Providers control this information and can share access with their participating government customers. If there is a trigger (identified in the ConMon Escalation Policy) then any government with access to the ConMon will receive a notification to login and take a look.  Government users can be provisioned access to executive summary details (which include the PMO Report) or full details which include artifacts. The type of access granted (executive or full details) is determined by the provider, often pursuant to their contractual obligations. This process streamlines the continuous monitoring process for both the providers who report once and for government users who benefit from the proactive notifications. The policies are reviewed annually by members for comments and by the Standards and Technical Committee at least annually for updates as we continue to iterate.  We recognize that each agency and use case is different. GovRAMP's ConMon process makes the risk posture of products visible and transparent for government users so that they can make risk-based decisions that are right for them, based on the potential data impact and risk needs.

### Replies



## Comment 5

author: [github.com/Telos-sa](https://github.com/Telos-sa)

url: [https://github.com/FedRAMP/community/discussions/27#discussioncomment-13038405](https://github.com/FedRAMP/community/discussions/27#discussioncomment-13038405)

created: 2025-05-05T11:57:33Z

id: DC_kwDOOxfoic4AxvNF

@ryan-hodges-gsaThe challenge for Multi-Agency Continuous monitoring is the difference in Risk Tolerance between different Agencies, and the CSP's ability to track that difference while maintaining a single package for all Agency Consumption.  The question then becomes, who is on the hook for tracking the Risk Tolerance Disparities?  Should it be the Agency, PMO, CSP or all three?  GovRAMP does a good job of centralizing the reporting before disseminating to downstream Government consumers.  This centralized approach is something that FedRAMP is moving away from, but this may increase the complexity of Package Deliverables, Reporting, and Risk Tolerance.  

@sam-aydlette A Charter template could help, especially if it comes with guidance and understanding the requirements against that specific CSO.  The Risk Tolerance for each AO, and the level of reporting agreements. IE a Low Water Mark for acceptance (like FedRAMP currently Has), and concurrence from the Agencies that this is what they are going to follow, plus any additional agreed upon requirements. 

@JosephScarzone  I can see the value of reporting at the Control Domain, and I can see the value of a standardized set of KSI's that all Agency Authorizations accept and Utilize, similar to the GovRAMP process.  This will make it easier for the AO's to review packages monthly, getting them through the process faster, when all data can be analyzed programmatically and converted to an easy to read dashboard that will give the AO's what they need.  

Bottom line is that each CSO should be providing enough information to make a single determination: `Accept the Risk of the CSO, or Not`.  And if that data can be distilled into a single dashboard, all the better. 
The risks overtime is crucial, as this is what I would expect an AO to look at, but I think there are additional elements that we should incorporate into any reporting.  Specifically, the difference in content of the SSP compared to the results of the Assessment.  

For those dashboard report elements to be complete and thorough, the CSP's must continue to generate the granular data.  
The control baseline should matter, as the requirements become more stringent the higher the impact, and this data will need to be available for review of Charter Members.  

### Replies



#### Reply 1

author: [github.com/JosephScarzone](https://github.com/JosephScarzone)

url: [https://github.com/FedRAMP/community/discussions/27#discussioncomment-13042970](https://github.com/FedRAMP/community/discussions/27#discussioncomment-13042970)

created: 2025-05-05T18:16:06Z

id: DC_kwDOOxfoic4AxwUa

@Telos-sa Thanks for your thoughts! I certainly have been advocating this Control Domain presentation of results as I think it will really move us toward "themes" by control family (as an example). The goal is to make it easier, yet still having enough depth via KSI metric results, to determine an authorization decision. Having it all contained in what I like to call a CSP Security Posture Dashboard (preferably online) brings tremendous advantages and efficiencies. 

Being in the GRC game for 22+ years, I like to remind my peers, colleagues and those I mentor that a control framework like FedRAMP or PCI DSS, or ISO27001, HITRUST, etc., is a great starting point for a CSP to institute industry-standard and beyond best practices, but it's not intended to be the say-all, end-all with regards to all the many different things a company does to protect its investments. And so, going to a more continuous monitoring/reporting approach should be geared toward providing a reasonable enough assurance to make an educated decision to determine authorization. 

The challenge is what is considered reasonable enough? And I think that's where the KSIs come into play. To me, being a Six Sigma Black Belt, it's just a fancy word for Measure. We seem to be calling for a measurement system, and I absolutely 100% agree on the value of that. Each control family that we all know and love (haha) can be "themed" into KSIs which should translate into a metric.  And these metrics will come in different shapes and forms, for instance, some can be completely automated on, some will be partially automated and partially manually calculated, and maybe some will be totally manually calculated (and that's OK). The CSP would figure this out and send results via an API to the Dashboard. 

Each control domain in NIST can be 'themed' out and translated into KSIs and results presented in an individual control domain and aggregate fashion. It can be digested easier by Agencies and FedRAMP to help make an authorization decision. Having an independent validation by a 3PAO of the "measurement systems" put in place perhaps with the assistance of an AI solution should not only streamline independent validation steps but also help raise assurances that the CSPs KSI measurement system is built properly and accurate so the agencies can trust the results of the CSP Security Posture Dashboard. But, and I'm sure this is obvious, now the 3PAO assessment is very different indeed, and probably could be automated as well using AI solutions (like my company's product lol). 

I'm not worried one bit at all, as I know my company will be using our product to automate as much as possible. Just give me the KSIs, give me an API, give me an online Dashboard, allow me to create my own KSIs on top of the Core ones from FedRAMP. That's all I need LOL. :-) 





