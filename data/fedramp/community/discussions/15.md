# Metadata

title:Public submission of security compliance data

author: [github.com/dan-fedramp](https://github.com/dan-fedramp)

url: [https://github.com/FedRAMP/community/discussions/15](https://github.com/FedRAMP/community/discussions/15)

created: 2025-05-14T17:06:41Z

id: D_kwDOOxfoic4AgAIC



# Post

What are the risks and challenges you are facing when asked to publish your compliance metrics publicly? What ideas do you have to address these barriers? We want to hear from the community as we continue to define our submission process.

# Comments




## Comment 1

author: [github.com/aj-stein-gsa](https://github.com/aj-stein-gsa)

url: [https://github.com/FedRAMP/community/discussions/15#discussioncomment-13149671](https://github.com/FedRAMP/community/discussions/15#discussioncomment-13149671)

created: 2025-05-14T20:02:54Z

id: DC_kwDOOxfoic4AyKXn

I am excited for responses to this topic! I am not really the target audience, @dan-fedramp, but in the title you say security compliance data and in the body mention compliance metrics? Can you elaborate on what you see as security data versus compliance data, or this dichotomy is subject to interpretation of whomever sumbits data to FedRAMP?


### Replies



#### Reply 1

author: [github.com/dan-fedramp](https://github.com/dan-fedramp)

url: [https://github.com/FedRAMP/community/discussions/15#discussioncomment-13162781](https://github.com/FedRAMP/community/discussions/15#discussioncomment-13162781)

created: 2025-05-15T19:09:35Z

id: DC_kwDOOxfoic4AyNkd

The use of two different terms was unintentional.  In this context I meant the same thing by data and metrics.  I guess you could say that all metrics are data but not all datum are metrics ðŸ˜„ 



#### Reply 2

author: [github.com/aj-stein-gsa](https://github.com/aj-stein-gsa)

url: [https://github.com/FedRAMP/community/discussions/15#discussioncomment-13171335](https://github.com/FedRAMP/community/discussions/15#discussioncomment-13171335)

created: 2025-05-16T13:42:55Z

id: DC_kwDOOxfoic4AyPqH

Good enough for me, I perceive people have different perspectives on security data versus more summary compliance data if I could make a silly dichotomy, but I am much more interested in the former anyway. 



## Comment 2

author: [github.com/JustinPadilla-Kratos](https://github.com/JustinPadilla-Kratos)

url: [https://github.com/FedRAMP/community/discussions/15#discussioncomment-13149732](https://github.com/FedRAMP/community/discussions/15#discussioncomment-13149732)

created: 2025-05-14T20:11:45Z

id: DC_kwDOOxfoic4AyKYk

IMO publishing compliance metrics publicly introduces several risks and challenges that could undermine the intended goals of AO risk-based decision-making as well as zero trust architecture:

The intent of KSIs and automation is to provide a technical means for AOs to risk tolerance associated cloud service offering risks. In a risk-based model, impact is constant, but public visibility can increase the likelihood of exploitation, potentially altering risk decisions that may have been acceptable in a more controlled context.

Public exposure of compliance metrics may discourage CSPs from sharing real-time or near real-time information, especially when addressing short-term or low-risk non-conformities that are actively being remediated. Fear of reputational damage may delay communication, reducing the value of timely and transparent updates.

Publicly disclosing detailed compliance status tied to KSIs may be counterproductive in a zero trust model, where minimizing exposure and limiting implicit trust is important. Broadcasting this data publicly could offer unnecessary insight to threat actors.

Overall, while transparency is important, publishing compliance metrics publicly, especially in raw or real-time form, can introduce new risks, undermine trust frameworks like zero trust, and ultimately hinder the effectiveness of informed, risk-based decisions by the AOs.

### Replies



#### Reply 1

author: [github.com/dan-fedramp](https://github.com/dan-fedramp)

url: [https://github.com/FedRAMP/community/discussions/15#discussioncomment-13163095](https://github.com/FedRAMP/community/discussions/15#discussioncomment-13163095)

created: 2025-05-15T19:57:03Z

id: DC_kwDOOxfoic4AyNpX

Thanks @JustinPadilla-Kratos for being brave enough to kick off this conversation. You raise really good points. My thoughts below are not intended to discount the concerns you are raising. I'm interested in your response as well as feedback from other community members.

I think I can sum up your concerns into two categories:
1. Adversaries might be able to use the information we are posting to attack us, and
2. Companies may have concerns about posting data, even if there is no benefit to an attacker, for other reasons

**Adversaries might be able to use the information we are posting to attack us**
While I agree this is and should be a concern, I think it is somewhat OBE because in most cases we should assume our adversaries already have this information. IMHO the idea that a vulnerability is obscure and my adversaries may not find it or know about it is a very dangerous position. Especially in the government where our adversaries are often nation-state level actors. 

**Companies may have concerns about posting data regardless of any benefit to an attacker**
I think you raise a really important issue here. Not only might a company be concerned for their reputation but may also have legal or regulatory issues that make publicly disclosing vulnerabilities infeasible. Although in an ideal world everyone would want to publish real time data publically to show how awesome they are ðŸ˜„. I'd like to hear from people about ways to mitigate this. For example, what about a solution where monthly data showing the past 30 days is published publicly and real time or more frequent data is restricted?

One last point, we should also consider the potential benefits public disclosures could create. Just a few possible examples include:
1. Agencies can easily compare multiple vendor's security to decide which product(s) best match their risk tolerance for a project
2. The reputational risk we are discussing might provide leverage for security teams to get the support and resources they need
3. Publically available data streamlines the necessary data collection when major security events like zero-day vulnerabilities occur.  

I'm really interested to hear from the community here about these and other potential benefits as well as concerns and challenges.




#### Reply 2

author: [github.com/jsantore-cgc](https://github.com/jsantore-cgc)

url: [https://github.com/FedRAMP/community/discussions/15#discussioncomment-13163250](https://github.com/FedRAMP/community/discussions/15#discussioncomment-13163250)

created: 2025-05-15T20:21:22Z

id: DC_kwDOOxfoic4AyNry

@dan-fedramp 

Remember that the specs were: no login, no NDA.

My read on this was to create fake data to test this as a proof of concept at this point and nothing more.

Actually sharing this data publicly is a bad idea for what @JustinPadilla-Kratos said, plus many other reasons.  IT's misuse of CUI for sure. 
 Also, you'd get dinged pretty hard from FedRAMP in the pre-20x days if you did this.   Disclosing vulnerability data was a huge no-no and you would not receive FedRAMP approval until this was fixed.  In fact, you weren't even allowed to share SSPs with non-government customers.  (Side note: I did get to sit on a meeting between DHS and the NYPD as they argued over this.  It was like one of those turf wars from TV cop shows.  It got resolved amiably).

To your point, though:
> Adversaries might be able to use the information we are posting to attack us
> While I agree this is and should be a concern, I think it is somewhat OBE because in most cases we should assume our adversaries already have this information. IMHO the idea that a vulnerability is obscure and my adversaries may not find it or know about it is a very dangerous position. Especially in the government where our adversaries are often nation-state level actors.

It's not a matter of 'does this vulnerability exist in the world, or in general' but 'this vulnerability EXISTS IN THIS SYSTEM' which is tempting all kinds of fate.

There's a reason that reports (think SOC 2 type 2) require NDAs before organizations share this, and why a SOC 3 exists because it's deliberately designed to be public.  









#### Reply 3

author: [github.com/peplin](https://github.com/peplin)

url: [https://github.com/FedRAMP/community/discussions/15#discussioncomment-13163334](https://github.com/FedRAMP/community/discussions/15#discussioncomment-13163334)

created: 2025-05-15T20:33:46Z

id: DC_kwDOOxfoic4AyNtG

The phrase that comes to mind for me is "defense in depth". I also agree that we should assume attackers have this information already, but to me that implies that we must not rely on obscurity or secrecy as our only or primary protection mechanism - not that we should abandon it.



#### Reply 4

author: [github.com/iteuscher](https://github.com/iteuscher)

url: [https://github.com/FedRAMP/community/discussions/15#discussioncomment-13164093](https://github.com/FedRAMP/community/discussions/15#discussioncomment-13164093)

created: 2025-05-15T21:58:33Z

id: DC_kwDOOxfoic4AyN49

I agree with the hesitations described above in this thread. Just because an adversary can find out security configurations doesn't mean CSPs should make it easier for them. Of course a nation-state level actor can uncover much of this information but the cost of time and resources to acquire that information is a deterrent to threat activity. Additionally, if adversaries could publicly access data for CSPs they could keep a repository of which CSPs use specific tools or configurations and when a zero day for those tools/configurations is available know who to exploit. Providing some abstraction or generality to the data (just overall metrics without specific implementations) would help reduce that risk but then would make the data less useful for agencies and others looking to perform a risk assessment of the CSP. 

In terms of a solution that balances transparency with "least privilege" and privacy I could see:
1) a web based platform where agencies or companies could request access to security data and be approved by the CSP (similar to [CISA's Repository for Software Attestations and Artifacts](https://www.cisa.gov/resources-tools/resources/secure-software-development-attestation-form)) 
2) a delay to publish security data so that gaps can be addressed before the information is public 
3) publicly available 3PAO report without technical specifics (agencies/customers would need to trust the 3PAO to assess accurately and the CSP would need to trust the 3PAO to not share technical specifics)

To directly answer the original question of **What are the risks and challenges you are facing when asked to publish your compliance metrics publicly?** â€” a major concern is the potential perception by others (customers, agencies, etc) that we are insecure or not following best practices if our security data is available publicly without any access control.

-- Isaac Teuscher (Paramify)



#### Reply 5

author: [github.com/JustinPadilla-Kratos](https://github.com/JustinPadilla-Kratos)

url: [https://github.com/FedRAMP/community/discussions/15#discussioncomment-13170394](https://github.com/FedRAMP/community/discussions/15#discussioncomment-13170394)

created: 2025-05-16T12:30:37Z

id: DC_kwDOOxfoic4AyPba

Your feedback is fair, and glad to see some of the additional input. I'd echo sentiments from @jsantore-cgc, @peplin, and @iteuscher and further add to your first point:

> Adversaries might be able to use the information we are posting to attack us
> While I agree this is and should be a concern, I think it is somewhat OBE because in most cases we should assume our adversaries already have this information. IMHO the idea that a vulnerability is obscure and my adversaries may not find it or know about it is a very dangerous position. Especially in the government where our adversaries are often nation-state level actors.

1. OSINT is one of the initial steps for an attacker, and the more information that is shared openly, the easier it is for an attacker to craft an attack
2. Who is more prepared than the government to protect against a nation state actor, yet I cannot think of a scenario where the government is sharing this level of information about their systems publicly.  
3. My point about risk-based decisions was that risk tolerance changes based on the likelihood. If I leave my car unlocked in the airport parking amongst hundreds of other cars for a day, the risk changes if I add a sign on the roof saying its unlocked.  

Perhaps my initial read of the question was misinterpreted considering @jsantore-cgc comment, "My read on this was to create fake data to test this as a proof of concept at this point and nothing more."

Was the intent of the public posting intended to only be dummy-data to show proof of concept, or was the intent to actually KSI validation data for anyone to access?



#### Reply 6

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/15#discussioncomment-13196528](https://github.com/FedRAMP/community/discussions/15#discussioncomment-13196528)

created: 2025-05-19T17:06:44Z

id: DC_kwDOOxfoic4AyVzw

FedRAMP's position, in alignment with BOD 20-01, is that making security information available to the public increases accountability and security when matched with appropriate policies and procedures. 

[See CISA BOD 20-01](https://www.cisa.gov/news-events/directives/bod-20-01-develop-and-publish-vulnerability-disclosure-policy): "Cybersecurity is a public good that is strongest when the public is given the ability to contribute. A key component to receiving cybersecurity help from the public is to establish a formal policy that describes the activities that can be undertaken in order to find and report vulnerabilities in a legally authorized manner. Such policies enable federal agencies to remediate vulnerabilities before they can be exploited by an adversary â€“ to immense public benefit."

> Was the intent of the public posting intended to only be dummy-data to show proof of concept, or was the intent to actually KSI validation data for anyone to access?

FedRAMP expects pilot candidates to make their own risk based determinations about what aspects of this data they wish to share publicly, and will monitor the justifications and results. 

I don't expect people will make a risk based determination to publicly share information that may lead directly to the compromise of their system. At the same time, I expect folks will see the benefits of transparency about their architecture and approach. Transparency coupled with true responsiveness is a proven route to success when it comes to securing systems and software (there's a reason so many folks trust linux, for example) and we encourage that and will prioritize those systems.







#### Reply 7

author: [github.com/JosephScarzone](https://github.com/JosephScarzone)

url: [https://github.com/FedRAMP/community/discussions/15#discussioncomment-13208167](https://github.com/FedRAMP/community/discussions/15#discussioncomment-13208167)

created: 2025-05-20T14:31:09Z

id: DC_kwDOOxfoic4AyYpn

Interesting discussion...I guess I'm old-school. I'm a big fan of Need to Know and Least Privilege principles. Controlling who has access to the KSI results/metrics makes the most sense to me. I consider these results as sensitive information. ;-)



#### Reply 8

author: [github.com/tnnrjmsn-eit](https://github.com/tnnrjmsn-eit)

url: [https://github.com/FedRAMP/community/discussions/15#discussioncomment-13249010](https://github.com/FedRAMP/community/discussions/15#discussioncomment-13249010)

created: 2025-05-23T16:52:49Z

id: DC_kwDOOxfoic4Ayiny

Not to turn this into a semantic debate, @pete-gov, but I think there is quite a difference between your stated FedRAMP position of "making security information available to the public" and CISA's statement that "Cybersecurity ... is strongest when the public is given the ability to contribute." (unless, of course, I'm misinterpreting what you mean by "security information")

In my mind, the CISA Directive calls for a public channel by which anyone can inform the CSP, and you seem to be calling for the CSP to inform the public. Are these not opposites from an information flow perspective?

That said, I fully support more transparency and collaboration in the FedRAMP/federal space (e.g., the CSP's "architecture and approach"); excepting CIA Triad-impacting (meta)data--as that should be protected and explicitly authorized for disclosure w/ all due accountability. 
Let's all work together & be more efficient (read repeatable) about _how we implement systems_ to protect federal (meta)data, but let's not make it more efficient for adversaries to discover _how well_ each CSO is currently protecting that federal (meta)data.



#### Reply 9

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/15#discussioncomment-13249894](https://github.com/FedRAMP/community/discussions/15#discussioncomment-13249894)

created: 2025-05-23T18:14:55Z

id: DC_kwDOOxfoic4Ayi1m

> In my mind, the CISA Directive calls for a public channel by which anyone can inform the CSP, and you seem to be calling for the CSP to inform the public. Are these not opposites from an information flow perspective?

They're a dependent cycle. The ability for the public to contribute is most effective when there is publicly available information for the public to review and thereby contribute to the security of the system by disclosing issues to the owner of the information. Hiding information prevents the public from contributing.

A system with a responsibly but publicly published security architecture with a supporting vulnerability disclosure policy and an effective program for encouraging and handling disclosures will be _more secure_ and _less likely to be compromised_ than the same system with the same policy that hides its security architecture because the public is given much more ability to contribute. Those who put effort into such programs (responsibly, deliberately) are demonstrating more effective security than those who fear responsible and deliberate disclosure would likely lead to compromise.

Adversaries who can see exactly _how well_ a service is protecting federal information will be less likely to attack and potentially compromise secure systems. This concept is a core tenet of modern cybersecurity seen all across systems, services, and programs - I cannot imagine folks arguing that Kubernetes or the Linux kernel should be closed source to increase their security posture.



#### Reply 10

author: [github.com/tnnrjmsn-eit](https://github.com/tnnrjmsn-eit)

url: [https://github.com/FedRAMP/community/discussions/15#discussioncomment-13251189](https://github.com/FedRAMP/community/discussions/15#discussioncomment-13251189)

created: 2025-05-23T21:08:00Z

id: DC_kwDOOxfoic4AyjJ1

I think we agree that the tech stack should be open to public scrutiny so light can be shown on all the cracks, then they can be patched; however, I don't yet understand the value of advertising weaknesses, i.e., failed KSIâ€˜s--especially naming the tech stack--to the public for bad actors to find.

I'm very much looking forward to seeing how this all shakes out!



#### Reply 11

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/15#discussioncomment-13251244](https://github.com/FedRAMP/community/discussions/15#discussioncomment-13251244)

created: 2025-05-23T21:21:17Z

id: DC_kwDOOxfoic4AyjKs

Totally fair! And to be extra clear, FedRAMP is by no means encouraging irresponsible or casual public disclosure of weaknesses. We are encouraging responsible and deliberate sharing of security decisions and information, in situations where security and engineering teams have made informed decisions that it would be to the overall security advantage of the system to do so, supported by appropriate policy, risk review, and justification. 

It's ultimately the benefits of establishing that process that matter as much as anything! Asking "what might happen if we publish this publicly today" is a great table top exercise.



#### Reply 12

author: [github.com/tnnrjmsn-eit](https://github.com/tnnrjmsn-eit)

url: [https://github.com/FedRAMP/community/discussions/15#discussioncomment-13251309](https://github.com/FedRAMP/community/discussions/15#discussioncomment-13251309)

created: 2025-05-23T21:30:31Z

id: DC_kwDOOxfoic4AyjLt

> And to be extra clear, FedRAMP is by no means encouraging irresponsible or casual public disclosure of weaknesses.

I think _that's_ the clarity we were looking for here, @pete-gov. (At least I was. ðŸ¤“) Thank you!
Have a great (long) weekend!



## Comment 3

author: [github.com/c-weaver](https://github.com/c-weaver)

url: [https://github.com/FedRAMP/community/discussions/15#discussioncomment-13225029](https://github.com/FedRAMP/community/discussions/15#discussioncomment-13225029)

created: 2025-05-21T20:26:09Z

id: DC_kwDOOxfoic4AycxF

@dan-fedramp 
I'm trying to wrap my head around the metadata definition we're using. Right now it's super broad - that NIST SP 800-53 language about "information describing characteristics of data" covers practically everything.

Here's where we keep hitting roadblocks - we get dinged anytime FedRAMP "metadata" touches a non-authorized system, but some of this stuff is pretty benign.

A real example from our world: We've kept our AWS accounts completely split (commercial vs FedRAMP) because we're worried about metadata leakage - even just internal IPs, stack names, basic account identifiers because some of the names could be tied to the type of data "RecordingsService" as an example. But this separation means we can't use AWS Organizations to manage security configs centrally. So when new accounts get created, we don't have automatic security controls applied by AWS and we have to implement it all through IaC. Kind of feels like we're creating bigger security gaps while trying to follow the metadata rules.

Those dashboard requirements (no login/no NDA) are also tricky. Seems like we're caught between "share more openly!" and "keep all metadata locked down in authorized systems only!"

Not trying to be difficult, just wondering if there's a way to get more practical guidance. Maybe all metadata isn't equal? Some types might need strict controls while others could be handled differently based on actual risk?

Curious how other folks in the thread are handling this balance.

### Replies



#### Reply 1

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/15#discussioncomment-13226193](https://github.com/FedRAMP/community/discussions/15#discussioncomment-13226193)

created: 2025-05-21T21:58:23Z

id: DC_kwDOOxfoic4AydDR

FedRAMP has an open concurrent RFC on an updated assessment scope/boundary standard that would apply to 20x Phase One pilot authorizations: https://www.fedramp.gov/rfcs/0005/

This standard clarifies that metadata that doesn't contain direct federal information or likely impact the confidentiality, integrity, and availability of federal information is outside the scope/boundary for FedRAMP. Things like internal ips, stack names, and basic account identifiers would be the type of metadata excluded in this standard because, yeah, it's pretty benign. 





#### Reply 2

author: [github.com/c-weaver](https://github.com/c-weaver)

url: [https://github.com/FedRAMP/community/discussions/15#discussioncomment-13237019](https://github.com/FedRAMP/community/discussions/15#discussioncomment-13237019)

created: 2025-05-22T16:35:37Z

id: DC_kwDOOxfoic4Ayfsb

@pete-gov 

This is fantastic news!

That RFC on assessment scope is going to be a game-changer. We've been stuck in this weird metadata limbo for so long (our security team once spent an entire meeting debating whether an IP address in a log file was "federal metadata"... not kidding).

We've got our FedRAMP Moderate authorization already, so we're not in the 20x pilot, but we're trying to stay ahead on all this automation stuff. The clearer boundary definitions will finally let us implement some architecture improvements we've been sitting on.

Right now we're running duplicate security tools in both environments because of these metadata worries - expensive and causes headaches when trying to get a complete security picture.

We've started looking at AWS Audit Manager + Hyperproof (our GRC platform) to help automate evidence collection. This metadata clarification should make that integration much smoother.

Really appreciate the transparency here. Makes a huge difference for those of us trying to plan our roadmaps when we can actually see where the program is heading!



## Comment 4

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/15#discussioncomment-13312004](https://github.com/FedRAMP/community/discussions/15#discussioncomment-13312004)

created: 2025-05-29T16:43:42Z

id: DC_kwDOOxfoic4AyyAE

Closing this discussion out as we move into the next phase - thanks for so many thoughtful perspectives, I'm sure this topic will be revisited many times!

### Replies



## Comment 5

author: [github.com/priyasingh96](https://github.com/priyasingh96)

url: [https://github.com/FedRAMP/community/discussions/15#discussioncomment-13406924](https://github.com/FedRAMP/community/discussions/15#discussioncomment-13406924)

created: 2025-06-09T06:53:24Z

id: DC_kwDOOxfoic4AzJLM

Public submission of security compliance data helps promote transparency, but it must be handled carefully to avoid exposure risks. Always sanitize sensitive details. Tools like Sangfor and Palo Alto Networks offer secure compliance management and protection against threats like Zero Day Attacks, ensuring your data stays safe during submissions.

### Replies

