# Metadata

title:FedRAMP RFC-0006: 20x Phase One Key Security Indicators (Closed)

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3](https://github.com/FedRAMP/community/discussions/3)

created: 2025-04-24T15:06:12Z

id: D_kwDOOxfoic4Af-ME



# Post

# RFC-0006 20x Phase One Key Security Indicators

> - Status: Closed
> - Created By: FedRAMP PMO
> - Start Date: 2025-04-24
> - Closing Date: 2025-05-24
> - Short Name: rfc-0006-key-security-indicators

## Where to Comment

Mon May 26 09:52:49 EDT 2025

This RFC is now closed to public comment. Many thanks to all the participants!

## Summary

FedRAMP’s 20x Phase One Key Security Indicators creates an abstraction layer to summarize the security capabilities expected of a cloud-native service offering to meet FedRAMP Low authorization requirements. These indicators align to NIST SP 800-53 controls and form a baseline equivalent.

These Key Security Indicators will be updated after public comment and formalized for use in the FedRAMP 20x Phase One Pilot to grant FedRAMP Low authorizations. During Phase Two, Key Security Indicators will be expanded for FedRAMP Moderate authorizations.

Authorization packages based on Key Security Indicators must be machine-readable, supported by evidence, and should include automated technical validation whenever possible.

## Motivation and Rationale

FedRAMP 20x describes key goals for a new assessment approach that is being designed by FedRAMP in collaboration with industry stakeholders and agency experts. Automation efforts have historically focused on automating the production of documentation materials to be used in an assessment, but the FedRAMP Authorization Act requires FedRAMP to establish a means for the “automation of security assessments and reviews.” FedRAMP asserts that automatically producing and reviewing documentation alone will not meet this requirement.

FedRAMP 20x encourages the development of truly automated security assessment with continuous validation and enforcement by following NIST guidance to focus on required security capabilities. This initial release will serve as a foundation for the FedRAMP 20x pilot program, allowing us to refine the approach based on real-world implementation before expanding to additional service types and impact levels.

## Explanation

The full draft standard is approximately 5 pages and is available for review in the following formats:

- [Basic web formatting on fedramp.gov](https://fedramp.gov/updates/rfcs/0006)
- Basic text markdown on GitHub (below)
- PDF file:  [rfc-0006-key-security-indicators.pdf](https://github.com/FedRAMP/rfcs/raw/main/rfc/assets/0006-key-security-indicators.pdf)
- DOCX file:  [rfc-0006-key-security-indicators.docx](https://github.com/FedRAMP/rfcs/raw/main/rfc/assets/0006-key-security-indicators.docx)

## Discussion Requested

This draft standard is open for any public comment. FedRAMP encourages fast, informal comments from any member of the public. The public may submit multiple comments and may respond to other public comments. All comments from the public sent via email will be made public.

The FedRAMP Automating Assessments Working Group will simultaneously host discussions on potential best practices and implementation methods for integration of Key Security Indicators into the FedRAMP 20x Phase One Pilot for FedRAMP Low authorizations.

---

# RFC-0006 20x Phase One Key Security Indicators

Thursday, April 24, 2025

---

# Background

> [OMB Circular A-130: Managing Information as a Strategic Resource](https://obamawhitehouse.archives.gov/sites/default/files/omb/assets/OMB/circulars/a130/a130revised.pdf) Appendix I states _“Agencies may also develop overlays for specific types of information or communities of interest (e.g., all web-based applications, all health care-related systems) as part of the security control selection process. Overlays provide a specification of security or privacy controls, control enhancements, supplemental guidance, and other supporting information as part of the tailoring process, that is intended to complement (and further refine) security control baselines. The overlay may be more stringent or less stringent than the original security control baseline and can be applied to multiple information systems.”_

> [NIST SP 800-53B: Control Baselines for Information Systems and Organizations](https://csrc.nist.gov/pubs/sp/800/53/b/upd1/final) Section 2.5 states _“As the number of controls in \[SP 800-53\] grows in response to an increasingly sophisticated threat space, it is important for organizations to have the ability to describe key capabilities needed to protect organizational missions and business functions, and to subsequently select controls that—if properly designed, developed, and implemented—produce such capabilities. The use of capabilities simplifies how the protection problem is viewed conceptually. Using the construct of a capability provides a method of grouping controls that are employed for a common purpose or to  achieve a common objective.”_
>
> This section later states _“Ultimately, authorization decisions (i.e., risk acceptance decisions) are made based on the degree to which the desired capabilities have been effectively achieved.”_

> [NIST SP 800-53A*:* Assessing Security and Privacy Controls in Information Systems and Organizations](https://csrc.nist.gov/pubs/sp/800/53/a/r5/final) Section 3.5 states “_When organizations employ the concept of capabilities, automated and manual assessments account for all security and privacy controls that comprise the security and privacy capabilities. Assessors are aware of  how the controls work together to provide such capabilities.”_

> [The FedRAMP Authorization Act (44 USC § 3609 (a) (1))](https://www.govinfo.gov/app/details/USCODE-2023-title44/USCODE-2023-title44-chap36-sec3609)  requires that the Administrator of the General Services Administration shall _“in consultation with the \[DHS\] Secretary, develop, coordinate, and implement a process to support agency review, reuse, and standardization, where appropriate, of security assessments of cloud computing products and services…”_ 44 USC § 3609 (c) (2) further states that _“the \[GSA\] Administrator shall establish a means for the automation of security assessments and reviews.”_ These responsibilities are [delegated to the FedRAMP Director](https://www.gsa.gov/directives-library/gsa-delegations-of-authority-fedramp).

# Introduction

Modern cloud services often use automated or code-driven configuration management and control planes to ensure predictable, repeatable, reliable, and secure outcomes during deployment and operation.

Consequently, FedRAMP asserts that the majority of a service security assessment can take place continuously via automated validation for simple cloud-native services if the need for a traditional control-by-control narrative approach is removed.

The [FedRAMP 20x Phase One Pilot](https://www.fedramp.gov/20x/phase-one/) will test this assertion for a subset of low impact systems by granting conditional FedRAMP Low authorization to services that meet the full Phase One eligibility requirements and qualifications. To qualify for this authorization, cloud services must at minimum provide a machine readable package that demonstrates a continuous, automated validation approach for a significant portion of the FedRAMP Key Security Indicators (KSIs) outlined in this standard.

The resulting packages and validation approaches will inform Phase Two and other formal standards for FedRAMP 20x. Services that receive FedRAMP 20x Low authorizations during Phase One will be prioritized for the FedRAMP 20x Moderate pilot in Phase Two.

# Key Security Indicators

FedRAMP Key Security Indicators summarize the capabilities that satisfy FedRAMP security requirements aligned to NIST SP 800-53 controls, providing an abstraction layer that is simpler to approach and assess. Each Key Security Indicator includes critical security capabilities that must be met and validated. These capabilities are designed to provide a concrete approach to evaluating cloud security risks that can often be automatically derived from technical configurations and resolved to true or false.

Key Security Indicators are engineered to address critical limitations in existing security assessment approaches:

- Simplified capabilities: Reduce lengthy and complex security compliance to clear, actionable, capability-based standards

- Automation-Friendly: Eliminate reliance on narrative to create a foundation for future automated security assessment processes

- Flexible Implementation: Enable private innovation to design different methods for validation

Although Key Security Indicators are designed to produce final validations that are true or false, the minimum expectations for validation and assessment will require cloud service providers and third party assessment organizations to provide reasonable evidence supporting the final validation.

To maximize innovation, this standard does not propose validation, evidence, or assessment expectations for Key Security Indicators. Instead, minimum expectations for validation, evidence, and assessment will be determined during active FedRAMP 20x pilots in collaboration with cloud service providers, third party assessment organizations, and federal agencies.

All FedRAMP 20x packages submitted for assessment based on these standards must be in a machine-readable format that can be regenerated on demand.

# **Key Security Indicators (FedRAMP Low, Cloud Native)**

This release includes the Key Security Indicators that must be addressed to meet security requirements for FedRAMP Low authorization for cloud service offerings that meet the following eligibility criteria:

1. Deployed on an existing FedRAMP authorized cloud service offering
   1. Using primarily cloud-native services from the host provider
   2. Using only FedRAMP authorized external services
2. Service is provided only via the public internet (browser and/or APIs)
3. Has completed a SOC 2 Type 2 audit or federal agency ATO process within the last 12 months

## Cloud Native Architecture

**KSI-CNA:** A secure cloud service offering will use cloud native architecture and design principles to enforce and enhance the Confidentiality, Integrity and Availability of the system.

**Validation**

Cloud service providers MUST:

1. Have denial of service (DoS) protection
2. Configure firewalls/proxy servers to limit inbound and outbound traffic
3. Use immutable containers and serverless functions with strictly defined functionality and privileges
4. Design systems as logically segmented micro-services to minimize the attack surface and lateral movement if compromised
5. Use cloud native virtual networks and related capabilities to enforce logical traffic flow controls
6. Execute continuous scanning of cloud native system components
7. Use high availability design principles to maximize uptime

**Related NIST SP 800-53 Controls:** SC-5, SC-7, SC-12, SC-39, SR-12

## Service Configuration

**KSI-SC:** A secure cloud service offering will enforce the use of approved cryptography, continuously verify component integrity, and restrict access to external services.

**Validation**

Cloud service providers MUST:

1. Harden and review network and system configurations
2. Encrypt all network traffic
3. Encrypt all federal and sensitive information at rest
4. Manage configuration centrally
5. Enforce system and component integrity through cryptographic means
6. Use a key management capability to execute regular rotation of digital keys
7. Use a consistent, risk-informed approach for applying security patches

**Related NIST SP 800-53 Controls:** CM-2, CM-4, CM-8, IA-7, RA-7, SC-8, SC-8 (1), SC-13, SC-28, SC-28 (1), SI-3, SI-4

## Identity and Access Management

**KSI-IAM:** A secure cloud service offering will protect user data, control access, and implement zero trust practices.

**Validation**

Cloud service providers MUST:

1. Enforce phishing-resistant multi-factor authentication (MFA)
2. Enforce strong passwords
3. Use secure API authentication methods via industry standard protocols
4. Use a least-privileged, role-based, and just-in-time security model

**Related NIST SP 800-53 Controls:** AC-2, AC-3, AU-9, AC-14, IA-2, IA-2 (1), IA-2 (2), IA-2 (8), IA-2 (12), IA-4, IA-5, IA-5 (1), IA-6, IA-8, IA-8 (1) ,IA-8 (2), IA-8 (4), IA-11, PS-2, PS-3, PS-4, PS-5, PS-7, PS-9

## Monitoring, Logging, and Auditing

**KSI-MLA:** A secure cloud service offering will monitor, log, and audit all important events, activity, and changes.

**Validation**

Cloud service providers MUST:

1. Operate a Security Information and Event Management (SIEM) system for
   centralized, tamper-resistent event, activity, and change logging
2. Regularly review and audit logs
3. Rapidly detect and remediate or mitigate vulnerabilities
4. Perform authenticated vulnerability scanning on publicly accessible components
5. Perform Infrastructure as Code (IaC) and configuration scanning
6. Centrally track and prioritize the remediation of identified vulnerabilities

**Related NIST SP 800-53 Controls:** AC-7, AU-2, AU-3, AU-4, AU-8, AU-11, AU-12, RA-5, SI-2

## Change Management

**KSI-CM:** A secure cloud service provider will ensure that all system changes are properly documented and configuration baselines are updated accordingly.

**Validation**

Cloud service providers MUST:

1. Log and monitor system modifications
2. Execute changes though redeployment of version controlled immutable resources  rather than direct modification wherever possible
3. Implement automated testing and validation of changes prior to deployment
4. Have a documented change management procedure
5. Evaluate the risk and potential impact of any change

**Related NIST SP 800-53 Controls:** CM-6, CM-7, CM-10, CM-11

## Policy and Inventory

**KSI-PI:** A secure cloud service offering will have intentional, organized, universal guidance for how every asset, including personnel, is secured.

**Validation**

Cloud service providers MUST:

1. Have an up-to-date asset inventory or code defining all deployed assets
2. Have policies outlining their security objectives
3. Maintain a vulnerability disclosure program
4. Build security considerations into the Software Development Lifecycle (SDLC) and aligning with Secure By Design principles
5. Document methods used to automatically evaluate implementations
6. Have a dedicated staff and budget for security

**Related NIST SP 800-53 Controls:** AC-1, AU-1, CA-1, CM-1, CM-8, CP-1, IA-1, IR-1, PL-1, PL-2, PS-1, RA-1, SA-1, SA-2, SA-3, SA-5, SA-8, SC-1, SI-1, SR-1

## Third Party Information Resources

**KSI-3IR:** A secure cloud service offering will understand, monitor, and manage supply chain risks from third party services or components.

**Validation**

Cloud service providers MUST:

1. Regularly confirm that services storing Federal information are all FedRAMP authorized and securely configured
2. Identify and prioritize potential supply chain risks
3. Obtain a Software Bill of Materials (SBOM) for third party commercial software components
4. Confirm that third party information resources have a Secure Software Development Attestation with CISA
5. Implement zero trust design principles

**Related NIST SP 800-53 Controls:** AC-2, AC-20, AC-23, CA-3, CA-9, RA-3 (1), SA-4, SA-9, SA-22, SI-5, SR-2, SR-2 (1), SR-3, SR-5, SR-8, SR-10, SR-11, SR-11 (2)

## Cybersecurity Education

**KSI-CE:** A secure cloud service provider will continuously educate their employees on cybersecurity measures, testing them regularly to ensure their knowledge is satisfactory.

**Validation**

Cloud service providers MUST:

1. Ensure all employees receive security awareness training
2. Require role-specific training for high risk roles

**Related NIST SP 800-53 Controls:** AT-2, AT-3, AT-6

## Incident Response

**KSI-IR:** A secure cloud service offering will maintain, test, and execute effective Incident Response Plans for routine incidents such as vulnerability discovery, abnormal activity detection, and exfiltration of data.

**Validation**

Cloud service providers MUST:

1. Define Recovery Time Objective (RTO) and Recovery Point Objective (RPO)
2. Perform system backups aligned with the RTO and RPO
3. Test the capability to recover from incidents and contingencies
4. Report incidents according to federal requirements
5. Maintain a log of incidents and periodically review past incidents for patterns or vulnerabilities
6. Measure Mean Time To Detect (MTTD) and Mean Time To Resolution (MTTR) for incidents

**Related NIST SP 800-53 Controls:** CP-2, CP-4, CP-9, CP-10, IR-4, IR-5, IR-6, IR-7, IR-8, PS-8, RA-3, RA-5 (2), RA-5 (11)




# Comments




## Comment 1

author: [github.com/jsantore-cgc](https://github.com/jsantore-cgc)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-12947261](https://github.com/FedRAMP/community/discussions/3#discussioncomment-12947261)

created: 2025-04-25T13:01:26Z

id: DC_kwDOOxfoic4AxY89

Just for avoidance of doubt.  This sounds like this must occur 'post initial review', correct

> Has completed a SOC 2 Type 2 audit or federal agency ATO process within the last 12 months

My take on this is, is that you must already be in the continuous monitoring phase, and so the KSIs are more analogous to 'annual assessments' rather than 'initial.'  (with a SOC 2 serving in lieu of an initial FedRAMP Low/LI-SaaS).  

Please correct me if I am reading this wrong.

### Replies



#### Reply 1

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-12947462](https://github.com/FedRAMP/community/discussions/3#discussioncomment-12947462)

created: 2025-04-25T13:23:26Z

id: DC_kwDOOxfoic4AxZAG

Thank you for your comment (this is not endorsement of the comment).

> Just for avoidance of doubt. This sounds like this must occur 'post initial review', correct
> 
> > Has completed a SOC 2 Type 2 audit or federal agency ATO process within the last 12 months
> 
> My take on this is, is that you must already be in the continuous monitoring phase, and so the KSIs are more analogous to 'annual assessments' rather than 'initial.' (with a SOC 2 serving in lieu of an initial FedRAMP Low/LI-SaaS).

For public clarification, this particular aspect of the draft standard is aligned with the [FedRAMP 20x Phase One pilot](https://www.fedramp.gov/20x/phase-one/).

These Key Security Indicators are intended for both initial assessment _and_ ongoing assessment.

The second part of the above statement is targeted at cloud services that seek FedRAMP authorization and have completed a federal agency ATO process at Low or higher _without_ sponsorship for FedRAMP authorization via the Rev 5 Agency Authorization path. This standard could be applied to cloud services who currently have a FedRAMP Li-SaaS or Low authorization, meet the other criteria, and wish to transition from a Rev 5 Agency Authorization.









#### Reply 2

author: [github.com/Telos-sa](https://github.com/Telos-sa)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-12979988](https://github.com/FedRAMP/community/discussions/3#discussioncomment-12979988)

created: 2025-04-29T11:49:00Z

id: DC_kwDOOxfoic4Axg8U

What is the application process like, for CSPs that have a SOC2 type 2?  Do they submit their SOC2 results and immediately get their FedRAMP Low, or do they still need to produce the package in the machine readable format (IE FedRAMP package)? 

I see that the requirement is machine readable format for submission, that can be regenerated on Demand.  Is OSCAL the requirement, or is there a different structure in mind?   

Is this going to be a strategy that is buildable to the next Impact category?  IE Low must do all KSI's above.  Eventually Moderate will do all of Low and their additional requirements, and High will build off of low and moderate.  Are these controls highlighted above going to be the core controls for for annual assessment (with additional added for Moderate and High)? 

For validation and assessment, do you plan on continuing to use the Nist 800.53r5A objectives or are there going to be specific assessment objectives to validate the KSI's?  Is this going to tie into continuous monitoring, where we should be associating specific plug-ins or or tests types that should be assessed for monthly re-validation of specific controls (part of monthly scan cycle?).  




#### Reply 3

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-12984980](https://github.com/FedRAMP/community/discussions/3#discussioncomment-12984980)

created: 2025-04-29T20:06:40Z

id: DC_kwDOOxfoic4AxiKU

For public clarification, Q&A about the Phase One Pilot should take place in the appropriate working group. There are a couple questions here that align with different working groups. The pilot is exploring where materials produced for commercial compliance frameworks can be applied to FedRAMP KSIs. There is no world in which someone presents a SOC 2 Type 2 audit result and receives FedRAMP Low. The [Phase One Pilot page](https://www.fedramp.gov/20x/phase-one/) has additional information.

The RFC process is specifically requesting comments on approach and KSIs.



## Comment 2

author: [github.com/openprivacy](https://github.com/openprivacy)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-12952345](https://github.com/FedRAMP/community/discussions/3#discussioncomment-12952345)

created: 2025-04-26T01:15:25Z

id: DC_kwDOOxfoic4AxaMZ

In KSI-3IR I believe the word "commercial" can be removed from
3. Obtain a Software Bill of Materials (SBOM) for third party commercial software components

Ref: inclusion of "open source software" in (CISA):
* [Secure Software Development Attestation form](https://www.cisa.gov/sites/default/files/2024-04/Self_Attestation_Common_Form_FINAL_508c.pdf) (.pdf)
* [Secure by Demand Guide](https://www.cisa.gov/resources-tools/resources/secure-demand-guide)

### Replies



## Comment 3

author: [github.com/Christcpd](https://github.com/Christcpd)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-12982518](https://github.com/FedRAMP/community/discussions/3#discussioncomment-12982518)

created: 2025-04-29T15:25:51Z

id: DC_kwDOOxfoic4Axhj2

I know I sound like a broken record but the success of 20x relies heavily on the GRC vendor community and not the organization seeking 20x.   Without the GRC tool, a machine readable format will be extremely difficult.

Perhaps another requirement should be the organization has a GRC tool that can generate the machine readable output. Or explain in detail how they will generate such information.  

### Replies



#### Reply 1

author: [github.com/jsantore-cgc](https://github.com/jsantore-cgc)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-12982945](https://github.com/FedRAMP/community/discussions/3#discussioncomment-12982945)

created: 2025-04-29T16:01:18Z

id: DC_kwDOOxfoic4Axhqh

@Christcpd 
Mandating a GRC tool is tricky, and there are many different flavors, etc.  I'd be loathe to *require* a CSP or 3PAO actually use a tool.  Many/most are not FedRAMP authorized, it's another expense/complexity to manage, etc.  

Depends on what each specific KSIs is, I don't think you need a GRC tool for this (remember, the old scan xml files were machine readable).  Would it help?  Possibly, but I don't know that I'd require it.  I'd more worry about the 'machine readable formatting standard' though.  I am unconvinced OSCAL is the magic answer, either.

I will say that as a 3PAO, I found those CSPs that did use a GRC tool were not inherently better prepared or easier to assess than those without (and in some cases, they were worse).





#### Reply 2

author: [github.com/Christcpd](https://github.com/Christcpd)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-12983016](https://github.com/FedRAMP/community/discussions/3#discussioncomment-12983016)

created: 2025-04-29T16:07:09Z

id: DC_kwDOOxfoic4Axhro

So how do you propose that automation be conducted without the use of a tool?   20x wants to do automated evidence collection on an ongoing basis.  That requires tooling.  Whether it is open source or commercial.  



#### Reply 3

author: [github.com/jsantore-cgc](https://github.com/jsantore-cgc)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-12983175](https://github.com/FedRAMP/community/discussions/3#discussioncomment-12983175)

created: 2025-04-29T16:23:12Z

id: DC_kwDOOxfoic4AxhuH

Let's use this as an example:

> KSI-CE: A secure cloud service provider will continuously educate their employees on cybersecurity measures, testing them regularly to ensure their knowledge is satisfactory.
>
>Validation
>
>Cloud service providers MUST:
>
>Ensure all employees receive security awareness training
>Require role-specific training for high risk roles
>Related NIST SP 800-53 Controls: AT-2, AT-3, AT-6

That's not easily automatable anyway.  Not without a few human checks in there.  I'm not sure what a GRC tool would add for this.  




#### Reply 4

author: [github.com/Christcpd](https://github.com/Christcpd)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-12983753](https://github.com/FedRAMP/community/discussions/3#discussioncomment-12983753)

created: 2025-04-29T17:24:43Z

id: DC_kwDOOxfoic4Axh3J

Actually, that is really easy to automate as many vendors have already done so.  I won't mention names.  But if you Know Before... ;)

This is a combination of tools. First is the Learning Management System that automatically assigns training based on triggering event (Onboarding - discovered via IAM integration, quarterly, annual, etc.)    LMS tracks user completion.  LMS can also assign training based on user roles determined from IAM based on user role (Admin, HIPAA Users, etc.)  GRC tool integrates with LMS and gathers training logs noting successes and failures of completion (of which we hope there are none). If there are incompletes, it can send warning notices to admins or directly to impact employees notifying them to complete their training although the LMS should handle that.  GRC tool then packages the findings into a machine readable format with all the other automated checks and balances it conducted.

So, while there are some overseer functions that a human can engage, the vast portion of the training process can be automated (and without AI!)  It is already done and in production in several platforms.



#### Reply 5

author: [github.com/openprivacy](https://github.com/openprivacy)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-12985030](https://github.com/FedRAMP/community/discussions/3#discussioncomment-12985030)

created: 2025-04-29T20:14:09Z

id: DC_kwDOOxfoic4AxiLG

Depends on what a GRC is. Traditionally, the GRC has served as a front-end database abstraction on top of Word docs and spreadsheets.

The promise of OSCAL (a data centric SSP) brings with it the ability to write a collection of scripts that walk the OSCAL tree and perform validations directly.

The promise of AI is that a machine can ingest, understand and answer queries regarding those Word docs and spreadsheets.

Are the scripts a GRC? (I believe this is feasible). Is the AI?  (I don't believe we are there yet.)



#### Reply 6

author: [github.com/Christcpd](https://github.com/Christcpd)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-12995357](https://github.com/FedRAMP/community/discussions/3#discussioncomment-12995357)

created: 2025-04-30T14:57:41Z

id: DC_kwDOOxfoic4Axksd

> Depends on what a GRC is. Traditionally, the GRC has served as a front-end database abstraction on top of Word docs and spreadsheets.

Not in my experience.  To name a few: Drata, Vanta, SecureFrame, Hyperproof, and others.  These are GRC tools that help manage the compliance by organizing it, complying it, integrations with other platforms like EntraID, AWS, Azure, and many, many more.  These are not "abstractions on top of Word docs or spreadsheets" by any stretch of the imagination.

It is these vendors and GRC tools that will bring true automation to 20x.  Otherwise, you will still have a convoluted process that detracts from efficiency.



#### Reply 7

author: [github.com/ryantpatrick](https://github.com/ryantpatrick)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-12997727](https://github.com/FedRAMP/community/discussions/3#discussioncomment-12997727)

created: 2025-04-30T18:56:46Z

id: DC_kwDOOxfoic4AxlRf

I would offer that it isn't solely dependent on GRC tools. There is at least one commercial standard (HITRUST) that offers testing results in a JSON export from the testing platform that can be consumed by FedRAMP. 



## Comment 4

author: [github.com/Christcpd](https://github.com/Christcpd)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-12983917](https://github.com/FedRAMP/community/discussions/3#discussioncomment-12983917)

created: 2025-04-29T17:40:29Z

id: DC_kwDOOxfoic4Axh5t

KSI-MLA
"Rapidly detect and remediate or mitigate vulnerabilities
Perform authenticated vulnerability scanning on publicly accessible components"

As a CISO, I live every day worrying about patching abilities and the entire vulnerability management approach of the companies I assist including my own.  With the tremendous advancement of Information Stealers (InfoStealers) including in the corporate environment, it is no longer viable to just scan "publicly accessible components" unless the definition of public accessible components includes each and every desktop, laptop, server, etc that has an Internet connection even if is behind a firewall.  If that is the case, my comment here can be ignored.

However, if by publicly accessible components it is referring only to those assets that the general public can reach, then my point is it should be replaced with corporate assets that pose a risk, based on the organization's risk analysis, for compromise.  To me, and based on the information above, any corporate asset that connects to the internet and can support an authenticated scan, should be scanned if it is within boundary.  

A CSP often times has virtual desktops within the boundary.  They won't be publicly accessible per se but they certainly can touch other sensitive assets within the boundary so they pose a higher risk than an asset outside the boundary.

### Replies



## Comment 5

author: [github.com/aburroughs](https://github.com/aburroughs)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-12987877](https://github.com/FedRAMP/community/discussions/3#discussioncomment-12987877)

created: 2025-04-30T03:36:23Z

id: DC_kwDOOxfoic4Axi3l

**RFC-0006 Feedback: Real-World KSI Implementation Perspective**

As a cloud service provider actively building and preparing to submit a machine-readable package under the 20x Phase One pilot, I want to express deep appreciation for this new direction.

While our company is entering the FedRAMP ecosystem for the first time, I personally bring prior experience managing FedRAMP Rev. 4 and Rev. 5 Agency ATOs at the Moderate level. That experience has given me a clear lens into both the value and complexity of the traditional FedRAMP process. It’s also why I find the 20x model — especially the KSI framework — so compelling.

Too often in legacy FedRAMP efforts, implementation teams are caught in the gap between control interpretation and security intent. I’ve seen firsthand how technically sound architectures still get flagged because they don’t map 1:1 with prescriptive control narratives. The KSI approach resolves this by focusing on capabilities — real, testable outcomes — and abstracts away the ambiguity that often leads to unnecessary audit friction.

We’ve structured a machine-readable package around the current KSIs and built a Git-tracked repository of aligned evidence for submission. In doing so, we’ve seen how:

    The true/false assertions dramatically reduce compliance ambiguity

    JSON-based structure enables long-term reporting and QA opportunities

    Smaller, high-performance teams like ours can move faster without compromising assurance

**Implementation Snapshot: Sample Evidence**

In our KSI implementation, each validation result is asserted as true or false and backed by linked evidence. For example:

**KSI-IAM: Identity and Access Management**

    MFA enforcement: evidence/ksi-iam/mfa_enforcement.png

    Strong password policy aligned to NIST 800-63B: evidence/ksi-iam/password_policy_nist_800_63b.pdf

    Secure API access (OAuth 2.0/SAML): evidence/ksi-iam/saml.png

    Least privilege model (Permission Sets + SCPs): evidence/ksi-cna/permission_sets.pdf

This pattern continues across all nine KSIs using static PDFs, screenshots, policies, and system configurations. We are also building a second folder structure (evidence_v2/) to begin ingesting CLI outputs and API scans as part of future continuous validation reporting.

**To future-proof our JSON structure, we’ve prototyped lightweight extensions including:**

    validation_method: Manual vs. automated

    validation_timestamp: Date of last validation

    evidence_type: Screenshot, config, policy, etc.

    service_dependencies: Supporting cloud-native services

**Suggestion**: It may be helpful to add a short “KSI intent narrative” to each indicator — a single sentence explaining why the capability matters. That kind of clarity would go a long way for new CSPs trying to implement securely without falling into legacy compliance traps.

**Broader Perspective: Inviting a New Class of CSPs**

From my vantage point, one of the most profound long-term impacts of FedRAMP 20x will be its ability to open the floodgates to a new generation of cloud service providers — particularly small and medium-sized businesses (SMBs), legacy platforms seeking modernization, and commercial-first products looking to enter the federal space.

These companies may:

    Lack a formal GRC team (or even a dedicated compliance function)

    Have modern, secure architectures that don’t map cleanly to legacy narrative controls

    Be exploring FedRAMP authorization for the first time as a growth vector

In that context, the KSI framework does something revolutionary: it welcomes these providers into the ecosystem without compromising security. By anchoring expectations in outcomes — not lengthy documentation — it gives capable but lean teams a clear, achievable path to compliance.

That’s the beauty I see in the 20x approach: it’s not just modernization for the sake of efficiency — it’s modernization for the sake of accessibility, scale, and innovation. And it sends a powerful signal to industry that secure-by-design doesn’t need to be compliance-burdened-by-default.

If the intent of FedRAMP is to expand the federal cloud marketplace securely, 20x — and specifically KSIs — are the most promising invitation we’ve seen.

### Replies



## Comment 6

author: [github.com/iteuscher](https://github.com/iteuscher)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-12996601](https://github.com/FedRAMP/community/discussions/3#discussioncomment-12996601)

created: 2025-04-30T16:47:47Z

id: DC_kwDOOxfoic4Axk_5

KSI-CNA refers to the CIA triad but the validation sub-points are not arranged in C-I-A order. Obviously some of the validations cross into multiple aspects (eg: micro-services help with confidentiality and integrity) however some clearly fit into one part of the CIA triad. I wonder if rearranging the order of the sub-points would make the KSI feel more organized and understandable. The CIA headings are likely not necessary but included to demonstrate the organization. For example:

### KSI-CNA
##### Confidentiality
1. Configure firewalls/proxy servers to limit inbound and outbound traffic
2. Design systems as logically segmented micro-services to minimize the attack surface and lateral movement if compromised
##### Integrity
3. Use immutable containers and serverless functions with strictly defined functionality and privileges
4. Use cloud native virtual networks and related capabilities to enforce logical traffic flow controls
##### Availability 
5. Have denial of service (DoS) protection
6. Use high availability design principles to maximize uptime

_Side Note: isn't DoS protection--validation 1--a "high availability design principle to maximize uptime"? Maybe validation 1 should be a subset of validation 7._

Validation 6 "Execute continuous scanning of cloud native system components" is somewhat vauge. I'm not sure what kind of scanning this implies. Is it a health check scan (ping) for availability? Is it an integrity and change control scan? Is it a vulnerability scan (confidentiality)? All of the above? 

In short, rearranging the order of the validations in KSI-CNA could make it more readable and understandable. Clarifying what is meant by "high availability design principles" and "continuous scanning" would be beneficial as well. 

-- Isaac Teuscher (Paramify)

### Replies



## Comment 7

author: [github.com/Christcpd](https://github.com/Christcpd)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-12997208](https://github.com/FedRAMP/community/discussions/3#discussioncomment-12997208)

created: 2025-04-30T17:49:30Z

id: DC_kwDOOxfoic4AxlJY

Why binary answers don't work in an automated assessment.

Consider this KSI: "Enforce phishing-resistant multi-factor authentication (MFA)"  Seems easy to test.  It is either on or off for each account.  If found to be off for any single account, the control "fails".  Enforce and Enable carry two different meanings.  Enabled gives the user the choice to enroll.  Enforce means no choice.  Most of the time though this setting is per user and not per organization.  It can't be the latter.

Service Accounts are those accounts used for integrations or performing operations.  It is generally very difficult to Enforce MFA across all Service Accounts.  Yes, you can use certs to a degree but it will not get you 100% in compliance.

Most controls therefore can't be binary: Yes or No, On or Off, True or False.  That is not enough granularity.  During an audit, an auditor would ask to see that other mitigating controls are in play.  For example, Service Accounts without MFA do not allow interactive login and use extremely long passwords.  

While FedRAMP is not dictating a format to report and are asking for suggestions, this is certainly something to consider for the final reporting.  Especially those participating in the pilot.  

"Enforce phishing-resistant multi-factor authentication (MFA)" answers should be something like "Fully Complies", "Fully Complies with Mitigating Controls", "Substantially Complies", "Does Not Comply Substantially".  This introduces granularity into a "scoring system" which is the next nature step for anything machine readable.

### Replies



#### Reply 1

author: [github.com/gmengelberg](https://github.com/gmengelberg)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13065957](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13065957)

created: 2025-05-07T17:01:29Z

id: DC_kwDOOxfoic4Ax17l

Instead of all or nothing, the pass/fail criterial for each KSI element could be based off a % of compliance (e.g. 85%+ = pass) which would allow for a more nuanced approach.



#### Reply 2

author: [github.com/aburroughs](https://github.com/aburroughs)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13066633](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13066633)

created: 2025-05-07T18:24:50Z

id: DC_kwDOOxfoic4Ax2GJ

I do want to support the broader goal of 20x: enabling faster, continuous, and more transparent assurance.

That said, I want to flag one critical caution regarding the idea of replacing binary control outcomes with nuanced scoring models (e.g., “85% compliance = pass” or “substantially compliant”). While this appears to introduce flexibility, it does introduce risks undermining the integrity of federal assurance baselines.

FedRAMP was built on the idea that either a control meets the bar, or it doesn't. Allowing partial passes—even with mitigating context—could set dangerous precedents and weaken the clarity that auditors, AOs, and agencies rely on to make trust decisions.

I strongly support machine-readable evidence and structured compliance outputs that include granularity (e.g., compliant_with_mitigation, partial_scope, etc.). But these should always roll up to a binary pass/fail conclusion for each KSI to preserve auditability and authorization integrity.

In short: nuance belongs in the evidence layer, but policy outcomes should remain definitive (Dave Fairburn Jr aka "The Father of FedRAMP") would appreciate if at least that aspect of the program remained intact :)

Seriously though - I offer this feedback as someone who deeply believes in the promise of 20x and wants to ensure its scalability doesn’t come at the cost of clarity or trust.



#### Reply 3

author: [github.com/gmengelberg](https://github.com/gmengelberg)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13093862](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13093862)

created: 2025-05-09T16:24:53Z

id: DC_kwDOOxfoic4Ax8vm

I totally get your point.  The benefit of a percent-based approach is it provides context into how much a CSP/CSO is missing the mark.  For example, does the CSO implement MFAs on 100% of accounts, 85%, 84%, or 1%.  Pass/Fail does not provide that context; however, Pass/Fail coupled w/ percent compliance does.



## Comment 8

author: [github.com/aburroughs](https://github.com/aburroughs)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-12999747](https://github.com/FedRAMP/community/discussions/3#discussioncomment-12999747)

created: 2025-05-01T00:19:51Z

id: DC_kwDOOxfoic4AxlxD

**Additional Comment – Lessons from Active Implementation**

As a follow-up to our initial RFC comment, I’d like to offer deeper insights now that we’re nearing completion of our Low submission under the 20x pilot.

We're a small CSP actively building out a machine-readable KSI package in GitHub, and I believe our real-world implementation offers meaningful observations that could inform the PMO and the broader community as this process matures.

1. **KSI Framework Is Solid — but Prioritization Would Help**
The current KSIs are well-aligned with core FedRAMP Low capabilities. However, they’re all presented equally. In practice, some (like IAM and MLA) are far more critical to risk posture. A tiered or weighted structure (e.g., Tier 1 Critical, Tier 2 Operational, Tier 3 Administrative) could help CSPs prioritize appropriately.

2. **KSIs Vary in Their Automation Suitability**
Many KSIs are ideal for technical attestation (IAM, CM, SC), while others (like CE or PI) are inherently more process-driven. Tagging each KSI with a validation modality — e.g., automatable, process-driven, or hybrid — could clarify what’s expected and help CSPs avoid overengineering non-technical areas.

3. **Binary Assertions Don't Always Reflect Real-World Risk**
Certain validations (e.g., enforcing phishing-resistant MFA) oversimplify the implementation realities for edge cases like service accounts. A more flexible compliance scale (e.g., “fully compliant,” “compliant with mitigations,” “not applicable”) would better support risk-based decisions while staying true to intent.

4. **KSI-to-Control Mappings Should Be Standardized**
We've added manual mappings to NIST SP 800-53 controls in our JSON package, which has helped crosswalk our legacy control framework. It would be valuable for the PMO to provide and maintain an official KSI-to-Control mapping table, particularly as Moderate-level KSIs are introduced in Phase Two.

5. **Evidence Expectations Would Benefit from Clarification**
Right now, it's unclear whether a PDF screenshot, policy doc, Terraform config, or CLI output is considered “sufficient” for each KSI. A KSI-specific evidence reference guide would help CSPs and 3PAOs calibrate their efforts and avoid mismatched expectations.

6. **Smaller Teams Need a Clear, Realistic Path**
As a team with no full-time compliance or GRC resources, we've built our pilot submission using GitHub, AWS-native tools, and JSON. The framework is working — but only because we've interpreted the KSIs carefully. A lightweight reference implementation (e.g., a public repo using native tooling and markdown evidence) could go a long way in opening the 20x door for others like us.

7. **Infrastructure as Code Should Be Acknowledged, Even Without Full Automation**
We’re using Terraform and GitHub to manage system configuration and track evidence, even though we haven't yet built automated validation pipelines (e.g., GitHub Actions or scheduled scans). For small CSPs, this is often the first step before full CI/CD automation. Encouraging a validation_origin field — e.g., manual, automated, pipeline — would improve clarity and traceability, and would set the stage for eventual continuous monitoring under Rev 5.


### Replies



## Comment 9

author: [github.com/aburroughs](https://github.com/aburroughs)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13008861](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13008861)

created: 2025-05-01T23:43:47Z

id: DC_kwDOOxfoic4Axn_d

**Building on Our Pilot Participation: Operational Feedback to Strengthen the 20x KSI Model**

Having now spent considerable time actively implementing the 20x KSI structure in support of an upcoming pilot submission, we wanted to share additional insights informed by hands-on experience and real conversations with 3PAOs. These are intended to further refine and support the framework’s goal of reducing unnecessary burden while delivering real, verifiable security outcomes. There might be some overlap in this comment from our previous one but the context is with 3PAOs and agencies in mind. 

1. **3PAO Validation Guidance Needed for Consistency**

Under traditional FedRAMP, 3PAOs rely on control-level objectives from NIST 800-53A. In 20x, evidence seems to be slated to be derived from automation outputs — CLI scans, IaC configuration states, screenshots, or GitHub pipelines — all valid, but without standardized assessment criteria, difficult to evaluate uniformly.

We recommend FedRAMP develop lightweight validation objectives or sufficiency criteria per KSI. This would reduce inconsistency across assessors and clarify what "adequate evidence" means in the 20x model.

To improve auditability, we propose a validation_origin field in each KSI result to denote how the evidence was generated:

`"validation_origin": "automated" // or "manual", "pipeline", etc.`

This improves trust and transparency for both 3PAOs and agency reviewers.


2. **Proposal: Automate Posture Awareness via Dashboard**

To align with the FedRAMP Authorization Act’s intent for automation (44 USC §3609) and continuous validation, we propose:

`Encourage CSPs to develop public/private read-only dashboards that render KSI validation status using the existing machine-readable JSON structure. This allows 3PAOs and agencies to monitor security posture without requiring full package re-submission or manual artifact collection. It also aligns with NIST SP 800-53A’s emphasis on observable, testable evidence.`

We plan to begin prototyping this capability using GitHub, Infrastructure-as-Code (Terraform), and static site generation — and would be happy to share lessons learned if it proves to be useful.


3. **Ensure Agency Adoption Through Control Mapping**

A concern raised by our 3PAO was agency-level acceptance. Many federal security teams remain grounded in traditional 800-53 control interpretation. If FedRAMP 20x is perceived as “less rigorous” or too commercially abstract, agencies may hesitate to adopt even validly authorized services.

We recommend FedRAMP publicly release or endorse a KSI-to-800-53 mapping, even if imperfect. This bridge will help agency Authorizing Officials translate KSIs into familiar language and reduce resistance to accepting 20x-based packages.

### Replies



## Comment 10

author: [github.com/austinsonger](https://github.com/austinsonger)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13010039](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13010039)

created: 2025-05-02T04:13:21Z

id: DC_kwDOOxfoic4AxoR3

### ✅ Clarify “Evidence” Expectations for CSPs and 3PAOs

The draft rightly emphasizes machine-readable, regenerable evidence, but leaves too much ambiguity around **what constitutes acceptable evidence**. Suggest FedRAMP provide:

- A minimal evidence taxonomy per KSI (e.g., CLI output, IaC config, policy excerpt, signed attestation)
- A mapping between “evidence type” and “validation origin” (manual vs. automated vs. pipeline)

This will reduce rework and prevent misalignment between CSPs and 3PAOs, especially for small teams using GitOps but not fully automated CI/CD pipelines.

---

### ✅ Define and Scope “Zero Trust” Mentions in KSI-IAM and KSI-3IR

Several KSIs reference “zero trust design principles” or “zero trust security model” without defining scope. Recommend:

- Providing a FedRAMP-aligned baseline for what qualifies as a “zero trust approach” under FedRAMP Low
- Clarifying if ZTA is expected to cover identity brokering, network segmentation, software-defined perimeters, etc.

Otherwise, “zero trust” may become a vague expectation that varies wildly between CSPs and assessors.

---

### ✅ Add “Validation Origin” Metadata to All Machine-Readable KSI Submissions

To improve transparency, traceability, and automation-readiness, recommend that each KSI validation include a `validation_origin` field with values such as:

- `automated` (fully derived via API or IaC)
- `manual` (human-reviewed evidence like policies or screenshots)
- `pipeline` (derived from structured CI/CD runs)

This helps 3PAOs and AOs quickly assess rigor and future automation potential.

---

### ✅ Add “Rationale” Field for True/False Assertions

Binary assertions alone lack sufficient context, especially for edge cases (e.g., service accounts lacking MFA). Recommend allowing an optional `"rationale"` field per KSI validation:

```json
"rationale": "MFA not enforced for non-interactive service accounts; compensating controls include long password, IP allow-list, and no console access."
```

This strikes a balance between machine-readability and risk-context clarity.

---

### ✅ Clarify Scope of “CSP” in Training and Awareness KSI (KSI-CE)

KSI-CE applies to "all employees," but FedRAMP Low cloud-native systems may involve contractors, shared service providers, or off-shore DevOps partners. Please clarify:

- Whether training requirements apply to only those with boundary access
- Whether CSPs can provide evidence via HRIS exports or LMS dashboards

Otherwise, CSPs with federated or hybrid workforces may over- or under-scope their training KPIs.

---

### ✅ Recommend Crosswalk Table from KSI to FedRAMP Rev 5 Controls

To support broader reuse, request FedRAMP publish a **machine-readable crosswalk** showing:

- Which KSIs map to which 800-53 controls or enhancements (1-to-many)
- Whether that mapping covers full or partial implementation

This will help CSPs migrating from Rev 5 packages and improve interpretability for agency AOs.

---

### ✅ Add Metadata Field for “Validation Freshness”

Security assertions that are valid today may not be valid tomorrow. Recommend allowing:

```json
"validated_on": "2025-05-01"
```

and/or

```json
"expiration_date": "2025-06-01"
```

This supports trustworthiness in continuous monitoring and future FedRAMP dashboarding.

---

### ✅ Clarify if Third-Party Agents Used by the CSP Are In-Scope for KSI-3IR

Many CSPs rely on third-party agents (e.g., endpoint detection tools, patch management systems, RUM or APM agents). Please clarify:

- If these require SBOMs and Secure Software Attestations
- Whether their vendors’ FedRAMP authorization must also be verified

This would clarify inclusion thresholds and reduce disagreements over what is “third party.”

---

### ✅ Encourage Optional Metadata Fields for FedRAMP Low Packages

To support automated dashboards and version control, recommend the machine-readable KSI package support optional metadata fields such as:

- `package_version`
- `maintainer_email`
- `repo_url` or `evidence_repo`

These lightweight fields would improve CI/CD integration, support reuse, and enable future community-based dashboards.

---

### ✅ Recommend Standardization of Validation Result Schema Across KSIs

To reduce variability in implementation, recommend that FedRAMP standardize the JSON schema for KSI results, including:

```json
{
  "ksi_id": "KSI-IAM",
  "result": true,
  "validated_on": "2025-05-01",
  "validation_origin": "automated",
  "rationale": "MFA enforced via EntraID policy; verified by Azure CLI output.",
  "evidence_url": "https://repo.internal/evidence/iam/mfa_policy.json"
}
```

Standardization at the schema level ensures compatibility with future dashboards, validators, and audit tooling.

### Replies



## Comment 11

author: [github.com/jdettweiler](https://github.com/jdettweiler)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13038213](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13038213)

created: 2025-05-05T11:42:32Z

id: DC_kwDOOxfoic4AxvKF

For KSI-IR3: Confirm that third party information resources have a Secure Software Development Attestation with CISA

Does CISA publish a publicly available resource to consume this information? Something similar to the JSON used to update the FedRAMP marketplace:  - https://raw.githubusercontent.com/GSA/marketplace-fedramp-gov-data/refs/heads/main/data.json. 

I tried requesting an account to the CISA Repository for Software Attestations and Artifacts through: https://softwaresecurity.cisa.gov/request-account

However, you have two options for account types "Federal User" or "Software Producer" when selecting software producer, you are required to select a vendor from a list of software providers (I'm guessing these might be companies that have submitted SSDF attestations, but not sure). I don't work for any of those vendors and there was no "other" field, so I was unable to get an account going. 

A public-facing way to consume this information will be required. Preferably in a way that can be consumed and automated, such as a published JSON.  


### Replies



#### Reply 1

author: [github.com/aj-stein-gsa](https://github.com/aj-stein-gsa)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13039252](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13039252)

created: 2025-05-05T13:00:31Z

id: DC_kwDOOxfoic4AxvaU

> For KSI-IR3: Confirm that third party information resources have a Secure Software Development Attestation with CISA
> 
> Does CISA publish a publicly available resource to consume this information? Something similar to the JSON used to update the FedRAMP marketplace: - https://raw.githubusercontent.com/GSA/marketplace-fedramp-gov-data/refs/heads/main/data.json.

As far as I know, they do not. Or they are not publishing information and developer instructions in [their official user guides](https://www.cisa.gov/sites/default/files/2024-03/CISA_RSAA_User_Guide_18_March_2024.pdf) since I last checked. (I checked again this morning.)

> However, you have two options for account types "Federal User" or "Software Producer" when selecting software producer, you are required to select a vendor from a list of software providers (I'm guessing these might be companies that have submitted SSDF attestations, but not sure). I don't work for any of those vendors and there was no "other" field, so I was unable to get an account going.

I had the same observation when I began using it; there are many different personas that fall between those two or a persona that is neither of these two.





## Comment 12

author: [github.com/troyfine](https://github.com/troyfine)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13076344](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13076344)

created: 2025-05-08T13:39:35Z

id: DC_kwDOOxfoic4Ax4d4

@pete-gov If a SOC 2 Type 2 report included a mapping of the KSIs to controls tested during the audit and included testing procedures that covered the KSI validation procedures, could a 3PAO review the report and test results and rely on the report to prove that a KSI was met, assuming the 3PAO agreed with the tests performed and trusted the competency of the auditors that performed the SOC 2 Type 2 audit? Assume for this question, the SOC 2 Type 2 was completed 3 months ago.

### Replies



#### Reply 1

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13078840](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13078840)

created: 2025-05-08T16:43:07Z

id: DC_kwDOOxfoic4Ax5E4

Thank you for the comment (this is not an endorsement of the comment or commenter). 

For public awareness, there is some discussion related to this in the related working group: https://github.com/FedRAMP/applying-existing-frameworks-cwg/discussions/31#discussioncomment-13053134 That working group is a good place to discuss specific scenarios beyond commenting here for FedRAMP's awareness that it is on your mind.



#### Reply 2

author: [github.com/troyfine](https://github.com/troyfine)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13078877](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13078877)

created: 2025-05-08T16:46:11Z

id: DC_kwDOOxfoic4Ax5Fd

Thank you for the response.



## Comment 13

author: [github.com/greg-egnyte](https://github.com/greg-egnyte)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13079678](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13079678)

created: 2025-05-08T18:14:51Z

id: DC_kwDOOxfoic4Ax5R-

I submitted my comments/questions via the RFC form yesterday but don't see it on here. Can you advise?

### Replies



#### Reply 1

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13080211](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13080211)

created: 2025-05-08T19:25:21Z

id: DC_kwDOOxfoic4Ax5aT

For public clarification, comments submitted via the RFC form and email will be published for public awareness separately. 



## Comment 14

author: [github.com/greg-egnyte](https://github.com/greg-egnyte)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13080371](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13080371)

created: 2025-05-08T19:51:13Z

id: DC_kwDOOxfoic4Ax5cz



### Replies



#### Reply 1

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13080397](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13080397)

created: 2025-05-08T19:54:37Z

id: DC_kwDOOxfoic4Ax5dN

Ah, for public clarification, they _will_ be published separately but have not yet. We will likely publish them in this thread.



## Comment 15

author: [github.com/greg-egnyte](https://github.com/greg-egnyte)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13087984](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13087984)

created: 2025-05-09T11:05:46Z

id: DC_kwDOOxfoic4Ax7Tw

Pete,

Thanks again for the response and again apologies for one more important
question. Is there a better place for me to get a response to Phase One
Pilot Comments (Questions). Timelines for Phase One Pilot are winding down
(my understanding from attending working groups and reading the website is
that we have until May 25th to send our submission).

We are situated perfectly to be included based on the KSI indicators as we
will shortly have FedRAMP Ready status and DoD FedRAMP Equivalency
compliance. I've allocated our internal resources and communicated with our
3PAO about Phase One Pilot duties. Our only concern is that we may not get
responses in time to inform our submission.



On Thu, May 8, 2025 at 3:55 PM Pete Waterman ***@***.***>
wrote:

> Ah, for public clarification, they *will* be published separately but
> have not yet. We will likely publish them in this thread.
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/FedRAMP/rfcs/discussions/18#discussioncomment-13080397>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/BSJAXLXZVA34CNT6TESSORT25OZBLAVCNFSM6AAAAAB3ZJMJRWVHI2DSMVQWIX3LMV43URDJONRXK43TNFXW4Q3PNVWWK3TUHMYTGMBYGAZTSNY>
> .
> You are receiving this because you commented.Message ID:
> ***@***.***>
>


### Replies



#### Reply 1

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13093681](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13093681)

created: 2025-05-09T16:08:52Z

id: DC_kwDOOxfoic4Ax8sx

> Pete, Thanks again for the response and again apologies for one more important question. Is there a better place for me to get a response to Phase One Pilot Comments (Questions). Timelines for Phase One Pilot are winding down (my understanding from attending working groups and reading the website is that we have until May 25th to send our submission). We are situated perfectly to be included based on the KSI indicators as we will shortly have FedRAMP Ready status and DoD FedRAMP Equivalency compliance. I've allocated our internal resources and communicated with our 3PAO about Phase One Pilot duties. Our only concern is that we may not get responses in time to inform our submission.

For public clarification, our community working groups are the appropriate place for Q&A about the pilot. [Here is a thread in one](https://github.com/FedRAMP/applying-existing-frameworks-cwg/discussions/31).



## Comment 16

author: [github.com/anonymous-participant](https://github.com/anonymous-participant)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13093999](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13093999)

created: 2025-05-09T16:44:06Z

id: DC_kwDOOxfoic4Ax8xv

**What is the coverage of buy-in from agencies?**

Has fedramp polled agencies on using ksis instead of controls?  Would love to see stats on buy-in from adjudicating officials.  Who is on board and who needs convincing?

### Replies



#### Reply 1

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13209572](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13209572)

created: 2025-05-20T16:58:12Z

id: DC_kwDOOxfoic4AyY_k

For public clarification, questions that are seeking answers outside of the formal public comment process can be posted in FedRAMP's Community Working Groups, such as in the Automating Assessment group's [General Q&A for Participation and Submission in the 20x pilot](https://github.com/FedRAMP/automating-assessment-cwg/discussions/27) thread.



## Comment 17

author: [github.com/vennemp](https://github.com/vennemp)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13094851](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13094851)

created: 2025-05-09T18:43:17Z

id: DC_kwDOOxfoic4Ax8_D

What do you mean by "just-in-time security"? Are you speaking about a mechanism for "zero standing privileges"? While most would agree that is a great solution, it is NOT currently a requirement for FedRAMP on any level.  To insert that as a requirement for LOW systems arbitrarily at this stage seems problematic, especially when the controls do not actually mandate it.  They only mandate defining processes and timelines for granting access to solutions, not "Thou shalt only have authorization provisioned dynamically upon approval from your ISSM and said access revoked automatically after a pre-established timelines."

Also, there are several layers of zero standing privileges/ JIT acccess.  Many solutions offer only OS level access - but not necessarily at the CSP IaaS or other systems (not all solutions support that access model).  You're effectively requiring LOW systems to add in multiple security tool and/or change their entire environment to incorporate solutions that do support it.   

### Replies



#### Reply 1

author: [github.com/aburroughs](https://github.com/aburroughs)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13096541](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13096541)

created: 2025-05-09T23:26:04Z

id: DC_kwDOOxfoic4Ax9Zd

In our case, we interpreted the phrase “just-in-time security model” in KSI-IAM not as a strict mandate to implement commercial zero standing privilege tooling or dynamic provisioning frameworks, but as a design model reflecting the intent behind Zero Trust principles — specifically:

- Eliminating standing, persistent access to production resources 
- Ensuring access is granted only when needed, scoped to a role, and automatically expires
- Logging and auditing every session for full traceability
- Identity verification
- Least privilege

In our AWS environment, we’ve configured:

- IAM Permission Sets via Identity Center for role-based, time-limited/session based access (ultimately still IAM roles under the hood)
- SSM Session Manager only for infrastructure access (no SSH or keys)
- SCPs and IAM boundaries to restrict escalation paths
- CloudTrail and SSM logs for monitoring all access actions

We chose IAM Permission Sets over IAM roles because they allow us to centrally manage role-based, time-limited access across accounts without long-lived credentials or unmanaged role sprawl. This we believe supports Zero Trust principles and makes it easier to audit and revoke access — which we believe aligns exactly with KSI-IAM intent.  

We described this as a “just-in-time security model” not to imply a formal JIT platform, but to reflect an implementation that avoids persistent access and aligns with Zero Trust posture (JIT) — using only native AWS capabilities, and well within the FedRAMP Low boundary.



#### Reply 2

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13209570](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13209570)

created: 2025-05-20T16:58:06Z

id: DC_kwDOOxfoic4AyY_i

For public clarification, questions that are seeking answers outside of the formal public comment process can be posted in FedRAMP's Community Working Groups, such as in the Automating Assessment group's [General Q&A for Participation and Submission in the 20x pilot](https://github.com/FedRAMP/automating-assessment-cwg/discussions/27) thread.



## Comment 18

author: [github.com/troyfine](https://github.com/troyfine)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13099928](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13099928)

created: 2025-05-10T13:45:09Z

id: DC_kwDOOxfoic4Ax-OY

> FedRAMP Key Security Indicators summarize the capabilities that satisfy FedRAMP security requirements aligned to NIST SP 800-53 controls, providing an abstraction layer that is simpler to approach and assess. Each Key Security Indicator includes critical security capabilities that must be met and validated. These capabilities are designed to provide a concrete approach to evaluating cloud security risks that can often be automatically derived from technical configurations and resolved to true or false.

Does this mean that KSI’s are meant to replace NIST 800-53 controls? As part of the pilot program, will a 3PAO evaluate KSIs against the validation requirements or do will they test KSIs against the referenced NIST 800-53 controls for each KSI and follow the standard assessment objectives for each NIST 800-53 control referenced?

> 

### Replies



#### Reply 1

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13209567](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13209567)

created: 2025-05-20T16:57:56Z

id: DC_kwDOOxfoic4AyY_f

For public clarification, questions that are seeking answers outside of the formal public comment process can be posted in FedRAMP's Community Working Groups, such as in the Automating Assessment group's [General Q&A for Participation and Submission in the 20x pilot](https://github.com/FedRAMP/automating-assessment-cwg/discussions/27) thread.



## Comment 19

author: [github.com/Rene2mt](https://github.com/Rene2mt)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13131407](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13131407)

created: 2025-05-13T13:31:05Z

id: DC_kwDOOxfoic4AyF6P

# General Observations / Feedback

We're excited about this new streamlined authorization approach and the potential it has to accelerate adoption of modern, innovative cloud services in the federal government while preserving visibility into the security posture of those services. 

As we gear up to participate in the Phase One pilot, we've been reviewing all proposed KSIs and validations and have some general observations and feedback


---

### 1) KSIs in RFC-0006 and Continuous Monitoring

The proposed KSIs in this RFC ([RFC-0006](https://www.fedramp.gov/rfcs/0006/)) are independent from / unrelated to the KSIs that CSOs would presumably need to report on for continuous monitoring ([FedRAMP Continuous Monitoring KSIs](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/blob/main/conmon_ksi_report.md#report-details)).

- **a.** Are the proposed Phase One pilot KSIs only intended for initial authorization, or will they be an integral part of a broader continuous authorization-to-operate strategy?
- **b.** Can we confirm that the ConMon KSIs are out of scope for this pilot, but may be required after authorization?

---

### 2) Validation IDs

In order to facilitate processing by FedRAMP and other stakeholder, it would be beneficial to establish unique IDs for each required validation.  We proprose the following (***KSI-{ksi_acronym}-{seq_num}***):
```
KSI-CNA-1, KSI-CNA-2, KSI-CNA-3, KSI-CNA-4, KSI-CNA-5, KSI-CNA-6, KSI-CNA-7, KSI-SC-1, KSI-SC-2, KSI-SC-3, KSI-SC-4, KSI-SC-5, KSI-SC-6, KSI-SC-7, KSI-IAM-1, KSI-IAM-2, KSI-IAM-3, KSI-IAM-4, KSI-LA-1, KSI-LA-2, KSI-LA-3, KSI-LA-4, KSI-LA-5, KSI-LA-6, KSI-CM-1, KSI-CM-2, KSI-CM-3, KSI-CM-4, KSI-CM-5, KSI-PI-1, KSI-PI-2, KSI-PI-3, KSI-PI-4, KSI-PI-5, KSI-PI-6, KSI-3IR-1, KSI-3IR-2, KSI-3IR-3, KSI-3IR-4, KSI-3IR-5, KSI-CE-1, KSI-CE-2, KSI-IR-1, KSI-IR-2, KSI-IR-3, KSI-IR-4, KSI-IR-5, KSI-IR-6

```

### 3) Validation Methodology Consistency

Without more prescriptive guidance around expected or acceptable validation methods for each KSI, there could be significant inconsistency in KSI validations from CSO to CSO. 

- Is the expectation that a 3PAO's attestation that a CSP has satisfied each KSI validation (along with the evidence, all in a machine-readable bundle) be sufficient for FedRAMP to make an authorization decision in this pilot?

---

### 4) Handling of "Partially" Validated KSIs

How will "partially" validated KSIs be handled? Does any occurrence of a "partial" on a KSI disqualify a CSP from obtaining the low authorization?

---

### 5) Qualitative Context for "Partial" Validations

While the FedRAMP 20x Pilot Phase One requires submitted packages to provide **True/False/Partial** assertions for each KSI validation, is FedRAMP open to additional qualitative information in the package to provide context? 

For example, if a CSO has a "Partial" status for KSI-CE validation 1, additional information could be provided (comments and supporting evidence) quantifying how compliant the CSO is. This kind of approach could be very useful for FedRAMP, allowing it to set different minimum thresholds for each security impact level. For example:

- **a.** High impact systems - require 97.5% compliance with KSI-CE validation 1
- **b.** Moderate impact systems - require 95% compliance with KSI-CE validation 1
- **c.** Low impact systems - require 90% compliance with KSI-CE validation 1

---

### 6) Submitting Machine-Readable Packages with Traditional Artifacts

While the submitted FedRAMP 20x packages must be machine-readable, is it acceptable for the package to also contain traditional evidentiary artifacts (e.g., screenshots, log samples, etc.) where appropriate?

Additionally, are traditional package documents (e.g., SSP including appendices, SAP, SAR, RET, SRTM) not required for pilot submissions?  What are FedRAMP's longer term plans for these package components going forward?


---

### 7) KSI-specific Observations and Feedback

#### KSI-IAM Validation 4

This validation mandates the use of a "just-in-time" security model which likely exceeds existing FedRAMP requirements for low impact systems.  Is this a "hard" requirement for the pilot and is FedRAMP mandating this going forward?  My colleague already posted a question about this (https://github.com/FedRAMP/rfcs/discussions/18#discussioncomment-13094851) but interested to see if the community response to that comment aligns with FedRAMP's view on this.

#### KSI-CNA

Similar to questions 4 and 5 above, if the KSI's are True/False, how does FedRAMP plan to treat a customer that meets a majority of the list but are not using container or serverless workloads or have a more legacy deployment not fully segmented into micro-services (as mandated by proposed validations 3 and 4 for this KSI)?

#### KSI-3IR

How does FedRAMP (as an oversight body) plan to address/manage the risk acceptance needs for come cloud providers that are dependent upon non-ATO'd services for components of their system (as mandated in validation 1)?


---

We look forward to working closely with FedRAMP on the Phase One pilot and contributing to the successful implementation of these validations.



### Replies



## Comment 20

author: [github.com/pauldoomgov](https://github.com/pauldoomgov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13132888](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13132888)

created: 2025-05-13T15:01:19Z

id: DC_kwDOOxfoic4AyGRY

# KSI-IR Feedback

Suggestions:
## Remove "Measure Mean Time To Detect (MTTD) and Mean Time To Resolution (MTTR) for incidents

These are both highly subjective, variable, context dependent, and gameable signals. Taking the mean of them makes them even more useless for helping drive better security outcomes.

What does knowing the average of how long it takes a typical attack to be "detected" (e.g. "we are being DDoSed") tell you about how long it takes to uncover compromise by a APT group? If the time to resolution clock starts after "detection" what is "resolved"? (E.g. - If a server is compromised, do we mark resolved as when we think we have cleaned up the machine, after we have replaced the machine, or after we have completed analysis to ensure there was not further activity throughout our boundary?)

## Relabel as `KSI-CP-IR Contingency Planning and Incident Response`

RTO/RPO are applicable to a subset of incident types and are generally grouped as part of Contingency Planning (CP). Renaming this section to include the most relevant families would align better with what folks are probably used to.



### Replies



#### Reply 1

author: [github.com/wisecryptic](https://github.com/wisecryptic)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13136925](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13136925)

created: 2025-05-13T22:07:33Z

id: DC_kwDOOxfoic4AyHQd

@pauldoomgov are there discussions about the relative value of mttd and mttr in non-fedramp industry forums?



#### Reply 2

author: [github.com/pauldoomgov](https://github.com/pauldoomgov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13197175](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13197175)

created: 2025-05-19T18:14:22Z

id: DC_kwDOOxfoic4AyV93

["MTTR Is (Still) Lying to You" by Courtney Nash](https://resilienceinsoftware.org/news/1157532) provides a good overview of the topic with good references to explore.



## Comment 21

author: [github.com/arimojiri](https://github.com/arimojiri)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13136315](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13136315)

created: 2025-05-13T21:02:11Z

id: DC_kwDOOxfoic4AyHG7

I'd like to reiterate a couple of points that have already been made:

1. Having an intent statement or basic expectations in terms of evidence would go a long way.
2. Validation IDs would be helpful and help with standardization; suggest a minor tweak to the above and suggest a 2-digit number for ease of sorting (e.g., KSI-CNA-01).

### Replies



## Comment 22

author: [github.com/iteuscher](https://github.com/iteuscher)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13136849](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13136849)

created: 2025-05-13T21:54:18Z

id: DC_kwDOOxfoic4AyHPR

Comment on **KSI-PI-05**:
More clarity would be helpful for KSI-PI-05: _"Document methods used to automatically evaluate implementations."_ Specifically the term "_implementations_" is vague. 

My assumption is that this KSI validation is asking for a written description of how the CSP's evidence artifacts are gathered and automatically evaluated by the CSP. For example: "Our KSI implementations are evaluated by scripts that call AWS Config and compare our AWS Config output to expected best practices." I'm not sure if that is consistent with what FedRAMP is hoping to see for this KSI validation. 

Lastly, is this KSI validation intended to be a machine-readable validation or does this specific KSI validation require human readable written documentation?

Thanks,
Isaac Teuscher (Paramify)

### Replies



#### Reply 1

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13209583](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13209583)

created: 2025-05-20T16:59:27Z

id: DC_kwDOOxfoic4AyY_v

For public clarification, questions that are seeking answers outside of the formal public comment process can be posted in FedRAMP's Community Working Groups, such as in the Automating Assessment group's [General Q&A for Participation and Submission in the 20x pilot](https://github.com/FedRAMP/automating-assessment-cwg/discussions/27) thread.



## Comment 23

author: [github.com/wisecryptic](https://github.com/wisecryptic)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13136977](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13136977)

created: 2025-05-13T22:16:51Z

id: DC_kwDOOxfoic4AyHRR

some of the criteria raised a few questions

### Key Security Indicators commentary
THANK YOU
### Commentary on FedRAMP Low, Cloud Native)
Will the eligibility criteria change after the pilot? Will this restrict some offerings from getting low if so? Or is the intent that any non cloud native offering that maintains its own datacenters etc. complex enough that it should automatically be rated as moderate?
### Cloud Native Architecture

> Use immutable containers and serverless functions with strictly defined functionality and privileges

-  I understand the security advantages of immutable containers, but educate me here: Is the container architecture at a state where we want to say ALL containers are immutable and MUST be immutable? What about legacy architectures where a CSP makes the decision to wrap a legacy service into a container for uniformity or simplicity or management or as a transition step? Is this not included in Low because risk is deemed higher? Sometimes one-off testing is helpful with container instance access. Sometimes an SSH service is wrapped in a container that accesses other infra. Maybe these exceptions are so small and temporary that it won’t matter and the rule should be kept. But I would consider rewriting it: Cloud service providers MUST Use immutable containers by default, mutable containers by exception and…
Or use the language for change management validation 2 which I think is better written

> Design systems as logically segmented micro-services to minimize the attack surface and lateral movement if compromised

- Same question for micro-services. Do we want to be prescribing this architecture? If so, I’m assuming this will be loosely defined to account for normal variance and future variance?
### Service Configuration

> Encrypt all network traffic

- same question as above for "encrypt ALL network traffic". Would recommend a “by default” type language
### Third Party Information Resources

> Obtain a Software Bill of Materials (SBOM) for third party commercial software components

- SBOM – how ready is industry to support this? SBOMs are big in federal, but they don’t go by this label in many private sector circles. Furthermore, there may be a possible issue with vendor privacy questions. I see a yellow flag here creating a process change from how this is currently done.

> Confirm that third party information resources have a Secure Software Development Attestation with CISA

- CISA attestation – same question. This seems like a fairly simple process, but it is an additional step and one that I don’t believe is enforced widely today. Is the intent to require this for all CSPs in the future beyond the scope of Low impact systems? Was the intent of the CISA attestation to be applied in Tier 2 supply chain providers (i.e. CSP’s vendor)? Is this serving as a simple proxy for a more onerous assessment step for Low only?


### Replies



## Comment 24

author: [github.com/mhungate-schellman](https://github.com/mhungate-schellman)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13206258](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13206258)

created: 2025-05-20T12:12:45Z

id: DC_kwDOOxfoic4AyYLy

@pete-gov we would like to seek clarification on whether the 20x KSI Measures are intended to streamline the expression of requirements while maintaining alignment with existing federal mandates, or if they reflect a shift away from prescriptive references altogether. If the former, should requirements such as FIPS-validated encryption and federal incident reporting obligations still be considered applicable to cloud service providers operating under the 20x Low baseline? The streamlined language is appreciated, but some clarity on how these foundational mandates fit into the revised framework would be helpful to ensure consistent interpretation and implementation.

For instance, the statement that systems must “encrypt all federal and sensitive information at rest” does not reference the longstanding requirement to use FIPS validated cryptographic modules, as mandated under FISMA and OMB Circular A-130. Without this reference, there is potential for confusion regarding acceptable encryption methods, especially among providers newer to federal compliance.

In terms of incident response, while it’s clear that timely action is emphasized, there is no mention of specific requirements like the one-hour incident reporting mandate to CISA. Explicitly including such requirements, or pointing to where they are maintained, could help ensure that service providers maintain alignment with federal expectations.

We recognize and support FedRAMP’s effort to modernize and simplify compliance through the 20x initiative. The examples discussed above—encryption standards and incident reporting obligations—are intended to illustrate the broader concern that essential, federally mandated requirements may be overlooked if they are not explicitly referenced or clearly tied into the KSI framework. These are just a few areas used for discussion purposes, but the underlying issue extends across the broader compliance landscape. Unless KSIs explicitly integrate or reference the full range of applicable federal mandates, there is a significant risk that cloud service providers and 3PAOs may miss critical obligations that are currently dispersed across numerous government policies, memoranda, and standards. 

Ensuring that KSIs serve as a centralized, authoritative touchpoint for both compliance expectations and implementation clarity would greatly support the success of the 20x model. We appreciate the opportunity to provide this feedback and look forward to continued collaboration on strengthening the FedRAMP program.

### Replies



#### Reply 1

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13207686](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13207686)

created: 2025-05-20T14:02:51Z

id: DC_kwDOOxfoic4AyYiG

For public clarification, FedRAMP will maintain technical assistance, best practices, and other materials _separate_ from standards. This has been noted in more recent RFCs but was not formalized when RFC-0006 was originally published.

- Standards are base requirements that can be applied in any environment and will change rarely
- Best Practices support standards with methods, techniques, or examples and may change often
- Technical Assistance supports standards with additional technical nuance to support decision making and may change often



#### Reply 2

author: [github.com/mhungate-schellman](https://github.com/mhungate-schellman)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13209412](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13209412)

created: 2025-05-20T16:41:46Z

id: DC_kwDOOxfoic4AyY9E

@pete-gov thank you for the clarification. That said, for CSPs and 3PAOs currently participating in 20x pilot assessments, we would welcome FedRAMP's thoughts on how KSIs are to be applied in practice during the pilot phase—particularly in areas where statutory or policy-driven obligations (e.g., FIPS-validated encryption or incident reporting timeframes) are not explicitly referenced in the KSI language.

Specifically, we ask:
1. Should assessors and CSPs assume that these federally mandated requirements remain in scope even if they are not included in the KSIs?
2. Will FedRAMP provide supplemental guidance during the pilot that explicitly maps relevant mandates to the appropriate KSIs or support materials?

We raise these questions to ensure alignment and avoid divergence across pilot assessments—particularly given that CSPs and 3PAOs may interpret the KSIs differently in the absence of clear technical references.



#### Reply 3

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13209543](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13209543)

created: 2025-05-20T16:54:27Z

id: DC_kwDOOxfoic4AyY_H

For public clarification, FedRAMP can respond to Q&A related to the 20x Phase One Pilot in the Community Working Groups. There is [a thread in the Automating Assessment CWG](https://github.com/FedRAMP/automating-assessment-cwg/discussions/27) that would be great for this. If you post there and @me I will ensure there is a timely response.

Sorry, it's a whole government thing, I know it's confusing, but from a rules standpoint the public comment process is an extremely different thing from our community working groups. On the public comment forum we generally need to just accept your statement above as a comment that these questions need to be addressed.



## Comment 25

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13211304](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13211304)

created: 2025-05-20T20:11:12Z

id: DC_kwDOOxfoic4AyZao

Public comment from form

5/5/2025 16:39:41
Salesforce
Cloud Service Provider (CSP)

What is the implication of if a KSI is not met? If each KSI is graded as a binary pass/fail, that leaves no room for nuance. Is something like "Encrypt all network traffic" the right threshold to set? Proposing that KSIs are not graded on a true/false for every validation, as this (in some spots) is an oversimplification.



### Replies



## Comment 26

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13211306](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13211306)

created: 2025-05-20T20:11:23Z

id: DC_kwDOOxfoic4AyZaq

pub comment from form

5/5/2025 16:40:23
Salesforce


Cloud Service Provider (CSP)
CMMC rolled out with a glossary and FAQ to define many terms. It would be nice to have FedRAMP define many ambiguous terms for us or examples to better guide CSPs. Proposing that FedRAMP groups official definitions of relevant terms in an official repository online.



### Replies



## Comment 27

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13211310](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13211310)

created: 2025-05-20T20:11:36Z

id: DC_kwDOOxfoic4AyZau

public comment from form

5/5/2025 16:41:00
Salesforce


Cloud Service Provider (CSP)
What if there's a critical legacy system integrated into our environment, which can't easily be rebuilt & re-deployed as an immutable container without major downtime or risk -- can we document an exception, or is this another strict pass/fail?

What about immutable virtual servers? Why are we pushing containers specifically since not all container technologies/architectures are the same and some are more immutable/stripped down than others.

Proposing that the language is extended beyond immutable containers to include other types of technologies a CSP may be using.



### Replies



## Comment 28

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13211313](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13211313)

created: 2025-05-20T20:11:52Z

id: DC_kwDOOxfoic4AyZax

public comment from form

5/5/2025 16:41:26
Salesforce


Cloud Service Provider (CSP)
What counts as logically segmented? Using AWS as an example - does it make economical sense to put each micro-service on its own VPC, or are we looking at using hub-and-spoke style routing within a VPC to segment, or are NACLS/ACLS sufficient?

Proposing that the language clarifies what logically segmented means here.



### Replies



## Comment 29

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13211315](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13211315)

created: 2025-05-20T20:12:05Z

id: DC_kwDOOxfoic4AyZaz

public comment from form

5/5/2025 16:42:06
Salesforce


Cloud Service Provider (CSP)
What are we considering continuous for scanning here? Especially if we are using immutable containers. If they are immutable, then why would we need to scan them repeatedly?

Proposing that either 1) continuous is better defined or 2) that the need for "continuous" is dropped, as these assets are immutable and thus shouldn't change over time.



### Replies



## Comment 30

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13211317](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13211317)

created: 2025-05-20T20:12:17Z

id: DC_kwDOOxfoic4AyZa1

public comment from form

5/5/2025 16:43:06
Salesforce


Cloud Service Provider (CSP)
How do we determine if information is "sensitive"? Is federal metadata no longer in scope as per RFC 0005?

Proposing that FedRAMP better defines what "sensitive" is - if this is the same definition as RFC 0005, then that should be mentioned.



### Replies



## Comment 31

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13211322](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13211322)

created: 2025-05-20T20:12:29Z

id: DC_kwDOOxfoic4AyZa6

public comment from form

5/5/2025 16:43:52
Salesforce


Cloud Service Provider (CSP)
Proposing that FedRAMP requires that a SIEM OR A SIMILAR SYSTEM be deployed (such that smaller teams are not required to over-invest on a SIEM).



### Replies



## Comment 32

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13211324](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13211324)

created: 2025-05-20T20:12:47Z

id: DC_kwDOOxfoic4AyZa8

public comment from form

5/5/2025 16:44:36
Salesforce


Cloud Service Provider (CSP)
"Centrally track and prioritize the remediation of identified vulnerabilities"

Large CSPs see constant new vulns daily. "Prioritize" sure, but remediating 100% in tight SLAs is operationally impossible sometimes.

What happens when a vendor's patch is delayed? Or a vuln awaiting a fix? Or if we can only apply fixes within certain operational maintenance windows?

Any mention of a DR process is absent in this doc.

Proposing that the language is changed from "remediation" to "mitigation", as some vulnerabilities may undergo risk acceptance, risk transferrence, or deviation.



### Replies



## Comment 33

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13211325](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13211325)

created: 2025-05-20T20:13:02Z

id: DC_kwDOOxfoic4AyZa9

public comment from form

5/5/2025 16:45:18
Salesforce


Cloud Service Provider (CSP)
Minor nitpick, but would prefer to keep numbers out of KSI IDs.

Proposing that "KSI-3IR" becomes "KSI-TPIR".



### Replies



## Comment 34

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13211328](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13211328)

created: 2025-05-20T20:13:22Z

id: DC_kwDOOxfoic4AyZbA

public comment from form

5/5/2025 16:46:01
Salesforce


Cloud Service Provider (CSP)
"Obtain a Software Bill of Materials (SBOM) for third party commercial software components"

Some vendors may not oblige this. Large CSPs are especially likely to run into this issue, as a large CSP may have dozens or hudnreds of external components in FedRAMP scope.

Is there room to prioritize your most critical 3rd parties, vs. attestation from everyone in your ecosystem?

Proposing that this is changed to be obtain a SBOM from third-party commercial software components "that make them available".



### Replies



## Comment 35

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13211330](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13211330)

created: 2025-05-20T20:13:35Z

id: DC_kwDOOxfoic4AyZbC

public comment from form

5/5/2025 16:46:32
Salesforce


Cloud Service Provider (CSP)
"Confirm that third party information resources have a Secure Software Development Attestation with CISA"

Does this include the 4 specific exception granted in the Secure Software Development Attestation form?
1. Software developed by Federal agencies;
2. Open source software that is freely and directly obtained directly by a Federal agency;
3. Third-party open source and proprietary components that are incorporated into the
software end product used by the agency; or
4. Software that is freely obtained and publicly available

Proposing that the exceptions are taken into account for this validation.



### Replies



## Comment 36

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13211335](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13211335)

created: 2025-05-20T20:13:48Z

id: DC_kwDOOxfoic4AyZbH

public comment from form

5/5/2025 16:47:01
Salesforce


Cloud Service Provider (CSP)
"Measure Mean Time To Detect (MTTD) and Mean Time To Resolution (MTTR) for incidents"

This could be harder than it sounds at scale. Defining "incident" is non-trivial -- does every low-severity event count?

Proposing that FedRAMP provides guidance on what an incident is.
Incident Response



### Replies



## Comment 37

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13211339](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13211339)

created: 2025-05-20T20:14:08Z

id: DC_kwDOOxfoic4AyZbL

public comment from form

5/7/2025 3:04:04
CSP-AB
Cloud Service Provider (CSP)

Cloud Native Architecture:
In general, these seem to describe solutions with intent. Should they be written for the intent and provide examples of the "how"? For example, "1. Protect from DOS attacks" and leave the how up to CSP, but provide example. "5. Enforce logical traffic flow. E.g., Setting up security groups and network access control lists"

"Identity and Access Management: Use a least-privileged, role-based, and just-in-time security model"
Instead say: "Use a least-privileged, role-based, and/or just-in-time security model"

Monitoring, Logging, and Auditing: Perform Infrastructure as Code (IaC) and configuration scanning.
We concerned that this could lead to an increase in the number of scans required to be submitted to agencies. These agencies rarely use IAC and often do not understand its scanning results. This could create confusion and inefficiencies in our processes. The configuration scanning of CSP infrastructure provided to AOs should be directly linked to a security objective, enabling them to accurately assess the associated risks.

Third Party Information Resources: Obtain a Software Bill of Materials (SBOM) for third party commercial software components.
1. There is no universally accepted standard for SBOMs, which can lead to inconsistencies and difficulties in interpretation and use across different platforms and stakeholders.
2. Applications are frequently updated, making it difficult to maintain an up-to-date SBOM. The continuous integration and deployment (CI/CD) pipelines used can result in rapid changes to the software components.
3. Solutions often rely on a complex web of dependencies, including third-party libraries and services. Tracking and documenting all these dependencies accurately can be cumbersome
4. SBOM is not an accurate depiction of risk



### Replies



## Comment 38

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13211343](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13211343)

created: 2025-05-20T20:14:28Z

id: DC_kwDOOxfoic4AyZbP

public comment from form

5/7/2025 13:35:24
Egnyte
Cloud Service Provider (CSP)

Egnyte will be FedRAMP Ready, Moderate Impact Level, in June 2025
- Will having an ATO Low be detrimental to us?
- How soon could we be moved to Moderate if we already have our full Body of Evidence and are FedRAMP Moderate Equivalency approved (by DIBCAC)
- Currently, FedRAMP Low Authorized status' are not published on the FedRAMP Marketplace. Will this still be the case if we achieve FedRAMP Low Authorization through the Phase One process.
- What is the process for an agency to grant us an ATO if we have a Phase One ATO? I am assuming agencies will still have to have an AO approve.
- If/When we achieve FedRAMP Moderate Impact Level Authorization under the Phase One program, what is the process for the agency to issue us an ATO. i.e. Will the agencies still have to perform their security assessment before issuing the ATO?
- Will there be a separate section on the Marketplace, (in addition to FedRAMP Ready, FedRAMP In Process, and FedRAMP Authorized sections) for Phase One Authorization listings?



### Replies



## Comment 39

author: [github.com/JosiahOne](https://github.com/JosiahOne)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13222268](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13222268)

created: 2025-05-21T16:12:24Z

id: DC_kwDOOxfoic4AycF8

Organization: jellyfish.co
Cloud Service Provider

# Holistic Feedback


Thank you for the work on this initiative. I have provided detailed comments after reading through the RFC in its entirety. For context, my perspectives are from that of a lead security engineer concerned with the security of my org, not in compliance activities (although I have experience supporting there). I also have experience in other standards, like Uptane. As such, please consider that engineering-lean in my notes.


Important things:


0. Most importantly: as-is this proposal is a bit awkward. It attempts to be lightweight (vs. traditional FedRAMP) by making requirements flexible but by being so ambiguous almost makes it harder. This basically puts the complete onus on auditors to understand the intention and validity of organization's evidence, but does not define the rationale for each validation criteria or requirement.
1. Relatedly, I have seen only two kinds of successful "certification" programs: 1) Ones that allow some flexibility in implementation but require auditors to review well-defined controls and push on orgs to understand misses (e.g. "traditional" FedRAMP) or 2) very well-defined technical requirements where verification is done (often using tooling) to ensure conformance (see NIST's many resources on "conformance testing"). FedRAMP 20x currently sits in the middle, which I believe is a mistake. I'd suggest it becoming more like the conformance testing model.


Smaller things:


1. The KSIs are presented with "Validation" criteria. However, I suggest renaming this to "Verification" criteria, as you seem to be looking to answer the question "Are you building it right"? (verification) not "Are you building the right thing?" (validation).
2. I agree with others that IDs should exist per validation criteria to make it much easier to build automation and cross-reference the standard.


# Specific Feedback


## Introduction Section


> Modern cloud services often use automated or code-driven configuration management and control planes to ensure predictable, repeatable, reliable, and secure outcomes during deployment and operation.


Yes, but also: portions of such deployments almost always include a non-negligible amount of ad-hoc changes that may affect the security posture of the organization, and yet may not be evident simply by examining code-driven config management or equivalent. As one example, an org who diligently uses terraform + AWS to manage all infrastructure will eventually make ad-hoc changes using the AWS console during incidents, or even while repairing issues with terraform.


> Consequently, FedRAMP asserts that the majority of a service security assessment can take place continuously via automated validation for simple cloud-native services if the need for a traditional control-by-control narrative approach is removed.


Maybe, but this does come with risk. While you can try to locate manual changes by relying on extra automated tooling to inspect an environment, this is going to be challenging to ensure it is done properly. Infrastructure is often quite distributed, and it would be easy for organizations to "plug in" only a portion of their infrastructure such that scans "look good".


This also puts a lot of faith in the tooling itself that will be used to generate final packages. For orgs with even slightly elaborate infrastructure, the ability to completely self-manage such tooling is probably unreasonable, and third-parties will be increasingly used to generate evidence packages. This is not strictly a problem, but could encourage perverse incentives. Specifically, it may encourage third-parties to build rules and detections that "look complete" rather than actually are. Missed evidence is much less bad than "too much evidence" from many orgs perspectives.


## Key Security Indicators


>  These capabilities are designed to provide a concrete approach to evaluating cloud security risks that can often be automatically derived from technical configurations and resolved to true or false.


As has been noted several times already, I strongly recommend against a boolean narrative here. If the goal is to stay lightweight and flexible, reducing capabilities down to true/false will negate the usefulness of the process and encourage "gaming" answers. It also implicitly defines security improperly: security is impact x likelihood (i.e. a numeric value on a gradient), not a "secure/insecure" situation.


While the simplicity of true/false assertions is nice, given the limitations, I'd suggest switching to a simple maturity scale and threshold for "clearing". This will make it more useful (an org can more clearly see how mature they are and where they need to go) and also makes it more flexible ("Moderate" authorization could, in theory, use the same KSIs with a different threshold).


> To maximize innovation, this standard does not propose validation, evidence, or assessment expectations for Key Security Indicators. Instead, minimum expectations for validation, evidence, and assessment will be determined during active FedRAMP 20x pilots in collaboration with cloud service providers, third party assessment organizations, and federal agencies.


This sounds nice but is not satisfying. Without *any* kind of expectation we should expect assessments to be gamed and auditors to be hugely confused. Auditing is a well-known field and I'd encourage more interactions with such auditors during this process to understand what is reasonable. It's not at all clear to me how anyone could audit something that has, essentially, not a single requirement.


## Key Security Indicators (FedRAMP Low, Cloud Native)


> Using primarily cloud-native services from the host provider


This is too ambiguous for a requirement. What does it mean to "primarily" use cloud-native services from the host provider?


Also, what is a "host provider"? This isn't defined anywhere. I'm assuming that's the cloud service offering provider?


> Using only FedRAMP authorized external services


What does this mean? Does this refer to core infrastructure or any service that might be relevant to your application (e.g. say you use some analytics SaaS provider - do all of those need to be FedRAMP authorized?)


> Service is provided only via the public internet (browser and/or APIs)


I'd suggest clarifying this further. Does this mean models where you allow VPC-peering (for example) between orgs as *one possible* model of network connectivity are not allowed? If so, that seems to arbitrarily limit security capabilities of the cloud service in an unnecessary fashion.


Is the intention here to limit what connection types are in-scope (i.e. to narrow this to classic "SaaS" providers)? If so, it might be better to define this as simply the "Internet Protocol".


If the intention is instead to indicate "on-prem" deployments are out-of-scope, I would suggest re-wording this to define where primary services are *deployed* not how network traffic is managed.


### Cloud Native Architecture


> Have denial of service (DoS) protection


Unclear what this means and what it's trying to get at. This could mean anything from: "your service is resilient to short-bursts of high traffic and can reliably deter huge DDoS attacks" to "in theory you can add a rule to your security group and block a malicious IP". This really needs to be presented in terms of what outcomes you are asserting.


> Configure firewalls/proxy servers to limit inbound and outbound traffic


This is practically useless as-is. I could just choose to block some arbitrary incoming and outgoing port and I've magically met this requirement.


> Use immutable containers and serverless functions with strictly defined functionality and privileges


Unclear what "use immutable containers" means. Clearly even in container-driven architectures you eventually have to update the container images. Does that count as immutable?


Also unclear what "use serverless functions" means. This feels quite arbitrary and doesn't necessarily imply anything about the security posture of a service.


Finally, this is written too ambiguously in terms of coverage. If I have one immutable container and one serverless function, even if largely irrelevant to the product, do I meet this requirement?


> Design systems as logically segmented micro-services to minimize the attack surface and lateral movement if compromised


I like the point of this: encourage segmentation and defense-in-depth but as-is it reads as dictating architecture unnecessarily. Also, it's unclear what a "micro-service" actually is.


> Use cloud native virtual networks and related capabilities to enforce logical traffic flow controls


Again, too ambiguous to be useful. I could simply create two virtual networks (a production and test one, for example) and claim I have the capabilities to enforce flow controls.


> Execute continuous scanning of cloud native system components


Totally unclear what this means. What is a "cloud native system component"? What does "scanning" mean? What does "continuous" mean? Do I need to do anything with the results of the scan?


> Use high availability design principles to maximize uptime


Too ambiguous to be useful. I'd suggest defining this in terms of "an ability to measure uptime + enough historical data to ensure uptime is greater than <whatever the government expects>."


### Service Configuration


> Harden and review network and system configurations


Too unclear what this means. Also, conflating "hardening" and "reviewing" in one validation criteria is confusing and will be challenging for auditors. Providing evidence of "review" implies a partially manual process that doesn't lend itself to automation vs. hardening which might.


> Encrypt all network traffic


This needs to be scoped down. As-is this implies you need encrypted traffic (BTW: how should we encrypt?) everywhere. What about cases where multiple local services exist on the same machine? Do you really need to encrypt local-only traffic? What about inside tightly controlled virtual clouds (for example: using load balancers to "break" TLS before sending to a series of boxes in a cluster is a common architectural model), is that allowed?


Clearly "use TLS 1.2/1.3 for all network traffic that leaves your service's immediate network boundary" is apt.


> Encrypt all federal and sensitive information at rest


Using what? This section noted "approved cryptography" but where is that defined?


> Manage configuration centrally


What does this mean? What configuration are we referring to exactly? Infra config? App configs? Service configs (e.g. SSO configs)?


> Enforce system and component integrity through cryptographic means


Unclear what this means in practice. What is a "system"? What is a "component"?


> Use a key management capability to execute regular rotation of digital keys


How many keys? As-is this implies rotating a single key is sufficient to meet this requirement.


> Use a consistent, risk-informed approach for applying security patches


Security patches to what?


### Identity and Access Management


> Enforce phishing-resistant multi-factor authentication (MFA)


For whom? Folks in the orgs? Users of the service itself?


Also, for what? Everything?


> Enforce strong passwords


This seems very hard to automate evidence for, given passwords are rightfully assigned out-of-band often.


> Use secure API authentication methods via industry standard protocols


What protocols? "Industry standard" doesn't mean anything. At minimum we should point to NIST guidance or something.


> Use a least-privileged, role-based, and just-in-time security model


For whom does this apply? This will also be hard to validate effectively. If the expectation is that all identities have zero/minimal permissions, and must be granted just-in-time for any given operation, most orgs will probably just create a single "Admin" permission folks will be requesting all the time. This could easily become riskier than allowing more freedom for orgs to well-scope permissions and make tradeoffs in usability vs. security.


### Monitoring, Logging, and Auditing


> Operate a Security Information and Event Management (SIEM) system for
centralized, tamper-resistent event, activity, and change logging


What needs to be fed into this SIEM?


> Regularly review and audit logs


Does this imply a human needs to do this or is using/writing detection rules sufficient?


> Rapidly detect and remediate or mitigate vulnerabilities


Vulnerabilities in what? Is this referring to known vulnerabilities in supply chain components or does it also refer to architectural weaknesses or vulnerabilities?


What does rapidly mean?


> Perform authenticated vulnerability scanning on publicly accessible components


This is probably too general. Orgs could set up single-rule authenticated scans to meet this requirement but essentially test nothing of interest.


> Perform Infrastructure as Code (IaC) and configuration scanning


Scanning for what purpose?


> Centrally track and prioritize the remediation of identified vulnerabilities


This seems partially redundant with item 3 from this section. Also, which vulnerabilities is this referring to? Supply chain? Code? Infrastructure? Config? If all of them, why do they have to be centrally managed?


### Change Management


> Log and monitor system modifications


Would be nice to better define what kinds of modifications need to be logged?


> Execute changes though redeployment of version controlled immutable resources rather than direct modification wherever possible


"Wherever possible" language makes this a useless validation criteria.


> Evaluate the risk and potential impact of any change


This doesn't seem particularly apt to be automatable. It might be better to instead require evidence of a process.


### Policy and Inventory


> Have policies outlining their security objectives


What is "their" in this context? What's a "security objective"?


> Build security considerations into the Software Development Lifecycle (SDLC) and aligning with Secure By Design principles


This is very ambiguous. I'd suggest pointing to example standards and requiring SDLC docs or processes to reference those standards, which will make this more automatable.


> Document methods used to automatically evaluate implementations


Implementations of what?


> Have a dedicated staff and budget for security


Is one intern and a $10 budget sufficient?




### Third Party Information Resources


> Regularly confirm that services storing Federal information are all FedRAMP authorized and securely configured


What does "securely configured" mean?


> Identify and prioritize potential supply chain risks


How? Is there a standard we can point to?


> Obtain a Software Bill of Materials (SBOM) for third party commercial software components


Why limit this to commercial components? Also, does this refer purely to third-party commercial software we use by deploying a "binary"-esque package or does it include services we interact with over HTTP, for example?


> Implement zero trust design principles


Much of this is already covered in other parts of this KSI RFC. I propose removing this since it's so ambiguous and there's no real standard for it as far as I can tell. Also, unclear how it relates to third party services specifically.


### Cybersecurity Education


> Require role-specific training for high risk roles


What's a high-risk role?




### Incident Response


> Maintain a log of incidents and periodically review past incidents for patterns or vulnerabilities


I suggest separating "maintaining" a log (easy to obtain evidence for) from "review past" incidents which is necessarily a manual step.



### Replies



#### Reply 1

author: [github.com/aburroughs](https://github.com/aburroughs)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13224888](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13224888)

created: 2025-05-21T20:13:53Z

id: DC_kwDOOxfoic4Aycu4

 As someone leading both security operations and compliance strategy within a live 20x pilot, I read your perspective with deep appreciation—and also with a recognition of where this new model intentionally diverges from the assumptions we’ve long held in the FedRAMP community - at least in my experience. 

**Security Is a Paradox**

Cybersecurity isn't about technology - it's about risk. From a security-minded perspective, it’s important to acknowledge a fundamental truth: some of the most well-funded, tool-saturated organizations still suffer the most damaging breaches. Capital One, SolarWinds, Rockstar Games—the list goes on. If security were purely a function of technical posture, budgets, and checklists, we’d have solved this already. But we haven’t.

Why? Because complexity itself can and in a lot of cases becomes a threat vector.

When you overload a system with CSPMs, SIEMs, XDRs, audit trails, endpoint tools, custom rules, and manual exceptions, you don’t get clarity—you get noise. You get tool fatigue. And paradoxically, this breeds fragility. The attack surface grows inward, not outward.

Years of DefCon has taught many of us that attackers will always be ahead. The goal isn’t to prevent every incident—it’s to minimize blast radius when one occurs. FedRAMP 20x recognizes this and builds a posture that emphasizes impact reduction, trust boundaries, and resilience, not performative compliance.

**FedRAMP Has Always Been About Practical Tradeoffs**

If you go back and listen to Paramify’s interview with Dave Fairburn Jr., often regarded as the father of FedRAMP, you’ll hear how the original FISMA-based model was so heavy it became a paperweight. That was the real FedRAMP once—and it had to be reduced to become usable.

In many ways, 20x is doing for today what Dave did then: compressing the signal, cutting the noise, and introducing a path that balances realism with risk awareness. That’s not regression. That’s the DNA of FedRAMP continuing to evolve.

**Binary Doesn’t Mean Shallow — It Means Scalable**

You raised valid concerns about true/false assertions being too simplistic for a nuanced risk model. I agree in principle. But in practice, we’ve always made binary decisions:

    “Is TLS enabled?”

    “Are admin sessions scoped?”

    “Is outbound egress restricted?”

These binary KSIs aren't oversimplifications—they’re structurally scannable indicators. They're not asking how well you’ve implemented something—they're asking whether you've met the floor of risk-aligned readiness. That floor is essential to scale trust across agencies and providers alike, especially in the low-impact domain.

**The Goalpost Has Always Been Too High**

Anyone who has worked in FedRAMP knows the 18 NIST control families represent only the minimum required implementation. The truth? That “minimum” is often well beyond what most practical cloud-native systems can operationalize without massive overhead.

So in this pilot, we’re really only talking about Low systems, where:

    No PII is processed

    No high-risk functions exist

    No sensitive integrations are active

This is where we should be innovating—and 20x finally enables that by reducing scope, minimizing overhead, and allowing systems to demonstrate alignment through their architecture, not just their documentation. Moderate I assume will take lessons learned and apply the required deltas to meet the increased risk for the data processed, stored and transmitted at the moderate impact level as per FIPS-199. 

**Spirit > Letter — As It Always Has Been**

The spirit of the law as we all know is present in audits, supposes there are multiple ways to do a thing. That is exactly the lens  I think 20x is trying to actualize. And while many of your points (on ambiguity, clarity, auditability) are spot on—and I hope to see those addressed in future refinements—let’s not lose sight of the core innovation:

20x shifts us from “tell me how secure you are” to “show me the evidence your system was built securely.” (in whatever way you can).

That is a better model. It invites agility, automation, and honesty. Frankly it enables Security, DevOps, DevSecOps, SREs, etc to build their own evidence system as it suits them and the environment, resources etc available to them. For instance as a <50 person company we do not have a GRC team, or compliance analysts etc. The conformance type of testing model is precisely what made FedRAMP inaccessible to 80% of the cloud vendor market.

**Final Thought**

We’re early. This is still a pilot. But we’ve already seen in our deployment and others that you can build a Low-authorized system using entirely AWS-native services, Terraform IaC, and strict boundary definitions—without compromising security.

I believe that’s where 20x shines most: not in defining perfection, but in enabling **good-enough** (nails on chalkboard to SecOps I know) security with maximum architectural clarity and minimum complexity.

And if the community agrees that we still need clearer terminology, better auditor guidance, and tighter evidence definitions—I’m with you. I tell my SecOps guys it's just growing pains in a space that badly needs to grow.



## Comment 40

author: [github.com/drewforbes](https://github.com/drewforbes)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13225044](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13225044)

created: 2025-05-21T20:27:44Z

id: DC_kwDOOxfoic4AycxU

**3PAO’s role in the pilot: Will they validate ONLY the KSIs?**
•	If yes, does the 3PAO only validate the KSIs and NOT the NIST controls?
•	If yes, does the 3PAO generate a report attesting that they validated it?
•	What kind of submission(s) will be necessary from 3PAOs to be authorized?
**“To qualify…provide a machine readable package…for a significant portion of the FedRAMP Key Security Indicators (KSIs)…”**
•	What does the “package” consist of? Just evidence?
•	What if KSI evidence cannot be provided in machine-readable format? Rejected?
•	Will screenshots, tickets, SOC2 reports, etc. be accepted (not machine-readable)?
**New requirements/controls in RFC 0006 for Low baseline (e.g., AC-23, AT-6).**
•	Was that the intention?
**Is this “conditional authorization” a new type of ATO FedRAMP is rolling out?**
•	What happens to currently Low authorized CSPs?
o	Should they forgo their Low assessment and do the KSI model? OR
o	Should they continue with their Con Mon?
**RE: cloud native architecture**
•	What is the expectation of defense in depth to which a CSP must adhere?
•	Does the FedRAMP Subnetting Whitepaper still apply as guiding principle?
**New KSI states that vulnerability scans now target publicly accessible components.**
•	Previously, ALL assets were subject to authenticated vulnerability scanning- correct?
o	Unscanned internal components opens the door to significant security risk.
**Do SBOM principles apply to containerized images pulled into registries from external supply chain providers (e.g. RapidFort, Chainguard)?**
•	Many CSPs leverage this service as a central repository
•	CSPs would be burdened instead of the supply chain provider reporting SBOM status of all cataloged images provided to Federal customers as standard oversight practice.
**No Zero-Trust Architecture (ZTA) applied to IA:**
•	As a community we should be eliminating inherently unsafe VPN services.
**Wiz and AWS Audit Manager are already doing automated self-auditing**
•	“Close” to what 20x is looking for BUT these are fundamentally different systems.
o	Wiz output is DIFFERENT than AWS Audit Manager output.
•	What is the expected data model to follow and how will FedRAMP ingest results?
•	Right now, there is no standard or output expectations for automated systems.
•	Acceptance criteria for post-automation workflow package(s) and deliverables?
**KSI and Modernization**
•	Who is responsible for curating the standards and adapting to ecosystem changes?
**KSIs and Shared Service Model**
•	Should there be more focus on CSPs and supply chain(s) rather than CSP consumers?
•	ISC2’s CCSP focuses much of its content on understanding shared service model.
•	FedRAMP has yet to adopt this, impacting strength for evaluating security inheritance.
•	There is no KSI that focuses on the shared service model.
•	CSPs complain that FedRAMP is expensive. Understood- resulting from re-scrutinizing a subset of inherited controls and no due diligence pressure on the underlying CSP to fix.
o	Example: virtual hosts provided by underlying CSPs for container services.
o	Most underlying CSPs provide images that customers have no ability to edit.
o	ONLY customer responsibility is to ensure they are hitting “update” button on time
•	While aggressive scans are run on these nodes and instruction is given to fix issues or work with the CSP if no capability to edit exists, FedRAMP does not ensure suppliers fix.
•	Deeper suppliers providing secure images (e.g. RapidFort, Chainguard) are not FedRAMP accredited or audited; yet, can be the most fundamentally important contributor to the security of the ecosystem.
**3PAOs with Automation or GRC systems.**
•	KSIs can be met through an automated "SRTM"
o	Request for Information (RFI) front-end from 3PAOs allows for submission of implementation state and evidence (as applicable)
o	3PAO would evaluate the uploaded KSI(s) responses and artifacts
	Completed SRTM: machine-readable KSI report for FedRAMP 20x.
	Output results into GitHub as markup language
	Output of automation scripts is factored into the overall markup report
•	Reduces the need for external or zipped artifacts.
•	GitHub already used and understood by FedRAMP
•	Machine readable output in a format FedRAMP is using.
o	This process can accelerate the FedRAMP program exponentially and meets all the fundamental goals of the RFC.
o	Workload for FedRAMP is highly minimized.
	FedRAMP gets markup report (Github) with 3PAO evaluation with artifacts.
	FedRAMP ONLY needs to review the report and approve the report.
o	Github does everything you need.
	Preserves integrity of the reports (all changes are tracked)
	A bottomless repository
	Integrates with every automation known to man.
•	Scripts used can also be opened as a community pool.
o	Process can pre-reject packages if they fail KSIs so FedRAMP saves time.
	“Approve” button OR “Reject” button with some rationale input.
o	Visual dashboard showing FedRAMP what the queue looks like.
	FedRAMP can log in themselves, see dashboards, and mark certain CSPs as priority.
**KSI-Specific Questions:**
•	KSI-CNA, Part 2: Configure firewalls/proxy servers to limit inbound and outbound traffic.
o	Is there a priority to focus on internal traffic, external to internal traffic, or both?
•	KSI-IAM, Part 2: Enforce strong passwords.
o	Passkeys, biometrics, hardware security keys, SSO, and behavioral biometrics are replacing traditional passwords. Consider enforcing strong passwords by migrating beyond traditional passwords with modern authentication methods.
o	What are the parameters for “strong passwords” (upper/lower, alphanumeric, special character, length, etc.)?
•	For KSI-MLA, Part 2: Regularly review and audit logs.
o	What is the time frame meant by “regular”?
•	KSI-SC, Part 1: Harden and review network and system configurations.
o	Is there a specific standard required to be used (CIS, STIG, etc.)?
•	KSI-SC, Part 2: Encrypt all network traffic.
o	Difficult for internal-originating DNS queries as well as Certificate Revocation List distribution. Both of these common data flows are unencrypted.
	Cloud platforms (AWS, Azure, GCP) don't offer a cloud-native method for encrypting these data flows- only installing an on-prem solution such as BIND or a Windows Server running the DNS role.
	Encrypting these data flows isn't a new requirement- required by Executive Orders as well as NIST SP 800-207
•	Still not implemented by any FedRAMP CSP.
•	Numerous KSI’s – Encryption (FIPS 140)
o	Do the encryption requirements (FIPS not noted) need to be FIPS 140-2 and/or FIPS 140-3 (and no historical)?


### Replies



#### Reply 1

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13238116](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13238116)

created: 2025-05-22T18:43:07Z

id: DC_kwDOOxfoic4Ayf9k

For public clarification, questions that are seeking answers outside of the formal public comment process can be posted in FedRAMP's Community Working Groups, such as in the Automating Assessment group's [General Q&A for Participation and Submission in the 20x pilot](https://github.com/FedRAMP/automating-assessment-cwg/discussions/27) thread.



## Comment 41

author: [github.com/Leah-GovRAMP](https://github.com/Leah-GovRAMP)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13225219](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13225219)

created: 2025-05-21T20:50:33Z

id: DC_kwDOOxfoic4Ayc0D

GovRAMP  recommends a data-driven approach to formulating the KSIs. For example:

- Reassessing NIST 800-53 controls linked to each Key Security Indicator (KSI) to leverage the associated MITRE ATT&CK risk protection values. This enables a data-driven prioritization of the most impactful security measures.

- Applying a weighted scoring model to KSIs using the MITRE ATT&CK Framework to prioritize the most critical cyber threats and defenses.



### Replies



## Comment 42

author: [github.com/ajay-stratus](https://github.com/ajay-stratus)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13227973](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13227973)

created: 2025-05-22T01:44:58Z

id: DC_kwDOOxfoic4AydfF

In the RFC it says SOC2 or a Federal ATO a requirement, however, on the website it says there are no specific eligibility requirements. 

We do not have either but have gotten several CSPs through the FedRAMP ATO process and handle their ConMon and would like to participate.

### Replies



#### Reply 1

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13238117](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13238117)

created: 2025-05-22T18:43:19Z

id: DC_kwDOOxfoic4Ayf9l

For public clarification, questions that are seeking answers outside of the formal public comment process can be posted in FedRAMP's Community Working Groups, such as in the Automating Assessment group's [General Q&A for Participation and Submission in the 20x pilot](https://github.com/FedRAMP/automating-assessment-cwg/discussions/27) thread.



## Comment 43

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13238334](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13238334)

created: 2025-05-22T19:11:40Z

id: DC_kwDOOxfoic4AygA-

## Public comment received via email:

We commend GSA on the initial set of Key Security Indicators (KSIs) and the approach for continuous
monitoring as proposed in FedRAMP 20x. A key benefit of FedRAMP 20x will be increased transparency
and choice in the federal cloud services marketplace, as well as the expedited arrival of new market
solutions. The choice of viable solutions can be enhanced if vendors can meaningfully differentiate their
solutions for security and monitoring, thereby increasing competition, so that agencies can make risk-
informed authorization decisions tailored for their needs and environments.

Drawing from Deloitte’s experience throughout the progression of FedRAMP since inception (supporting
cloud service providers (CSPs), federal agencies, and as a third-party assessment organization or 3PAO), as
well as insights from implementation of outcomes-based approaches to security monitoring in the
commercial sector, we believe even greater flexibility in the KSIs will promote even more innovation and
security as FedRAMP 20x moves forward. To achieve this, we recommend the community build on the

FedRAMP 20x KSIs and monitoring approach by increasing the granularity of the KSIs and leveraging a non-
prescriptive, performance outcome-based framework such as the NIST Cybersecurity Framework (CSF) 2.0 to accelerate authorizations, transition away from potentially burdensome requirements, facilitate
automation, and consolidate performance reporting.

Discussion Point

While the proposed KSIs establish a strong foundation for outcomes-based, automation-enabled,
approaches to security authorization and monitoring, the specific validations proposed may be too binary,
and ultimately limit how both vendors and federal agencies implement requirements. The validations
provide only a one-size-fits-all approach based on risk tier (e.g., Phase 1: Low, Lite Software as a Services
(SaaS)) rather than allowing CSPs and agencies to tailor requirements to specific business needs. This
includes not being able to prioritize different ways to achieve the outcomes and related KSIs, or monitor
them differently based on an organization’s risk environment.

The refreshed FedRAMP 20x approach will greatly accelerate a CSP’s entry into the FedRAMP Marketplace
by streamlining the outcomes that must be demonstrated for FedRAMP. The currently drafted validations
will provide some degree of information to agencies and departments to make risk-informed authorization
decisions for a given cloud service. We believe that this innovative structure proposed in FedRAMP 20x can
be enhanced by providing more granularity in the validations to allow greater choice, flexibility, and risk
awareness.

Recommended Approach

We recommend that GSA prioritize use of flexible industry recognized frameworks, such as the NIST CSF
2.0, for CSPs and agencies to demonstrate requirements and perform monitoring. Through this approach,
GSA can allow vendors to present their own validations and capabilities for automated monitoring, instead
of standardizing those expectations as part of FedRAMP 20x. This may include using the NIST CSF 2.0 to
establish Community and Industry Profiles for government authorization of commercial cloud services,
which can be used by CSPs and agencies to use those profiles as the basis for implementing KSIs and
associated capabilities for monitoring. It would also enable CSPs and agencies to validate or assess KSIs
differently for purposes of initial FedRAMP authorization than for ongoing monitoring, improving efficiency
and customization based on agency needs.

Frameworks like the CSF have been successful in the commercial industry; can be aligned to federal and
other industry security requirements; and provide a common structure for outcomes-based, risk-informed
cybersecurity management. Specifically, it can:

• Accelerate Authorization. The CSF enables GSA to prioritize key security outcomes as a foundation
for FedRAMP 20x continuous monitoring and leave approaches for validation open -- without
having to restrict monitoring to a small set of key security metrics/validations. This can facilitate
greater tailoring and customization by CSPs and agencies based on their unique service offerings
and business needs, which will enable agencies to streamline authorizations to better fit their
environments.

• Promote Technology-Enabled Approaches and Automation. Using the CSF, industry can identify
critical security technologies (e.g., implementing Privileged Access Management) associated with
outcomes, which go beyond individual KSIs. This can help agencies make authorization decisions
based on common, shared security technologies to optimize cost and effectiveness by promoting
multi-cloud security solutions and shared services that accelerate CSP authorization.

• Enhance Efficiency. The CSF can help GSA to optimize assessment efficiency over the cloud
authorization lifecycle by enabling it to distinguish between expectations for initial authorization
and ongoing monitoring. By differentiating approaches for initial and ongoing assessment, GSA can
dramatically improve efficiency of authorizations. In many cases, monitoring to ensure previously
validated capabilities remain in place can achieve agency risk management objectives alone; it may
not be necessary regularly re-test the underlying capability—particularly for low-risk systems.

Importantly, these recommendations do not require GSA to change what has been developed so far for
FedRAMP 20x. It just enables CSPs and agencies to meet FedRAMP 20x through a broader, more
customizable framework. This can even help GSA to streamline the FedRAMP process further by limiting
the effort needed from GSA in later phases of the FedRAMP 20x development.

Deloitte appreciates the opportunity to provide comments and feedback to GSA on FedRAMP 20x.
We would be happy to discuss them in more detail at your convenience.

### Replies



## Comment 44

author: [github.com/jdettweiler](https://github.com/jdettweiler)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13238736](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13238736)

created: 2025-05-22T20:06:55Z

id: DC_kwDOOxfoic4AygHQ

I really must commend @JosiahOne on an absolutely spot-on comment. What a tremendous and thorough evaluation, I could not agree more. 

In general, it seems like the consensus in the comments is that the KSIs, as documented, are not specific enough to be actionable. I hate to ask this question, but:

```
What is the point of the KSIs?
```
In order to be actionable, a 3PAO is going to have to default to reviewing the `Related Controls` associated with the KSI, determining which control is related to which KSI subpart and then dusting off 800-53A as the criteria to `validate the KSI`. That seems like testing the controls with more steps. 

There are a total of **104** related controls in the KSIs as documented in the RFC (AT-6, and AC-23 aren't in any current baselines). So, the KSIs account for two-thirds of the **156** Low Baseline controls. I'm not sure that if gauging the security baseline of the system requires evaluating two-thirds of the required controls, the KSIs are really achieving the task they were designed to address. 

Would it not be easier to simply identify a subset of controls (maybe pair down the currently selected 104) that are considered to be indicative of a system's ability to implement all controls (e.g., strong change management, CI/CD pipelines, risk management, findings management, etc.), and develop methods to automatically report and validate those controls? Essentially, establish that an organization has the `ability to implement meaningful processes to predict that controls are implemented as intended` and use that as the security benchmark. 

Instead of trying to create novel systems that report on KSIs, which is essentially requiring many CSPs to rewrite the automation they've created for control reporting to align to KSIs, why don't we just report on the subset of controls we all agree are meaningful and indicative of overall system security? 

I do appreciate that these KSIs are seemingly pushing CSPs towards being able to report on the `state` of their system on a far more frequent basis, but there's no reason why that can't be achieved through the use of the 800-53 controls. With the rise of AI-based tooling (e.g., AI agents, MCP servers, etc.) the ability to pull data from as close the `source` as possible to represent actual system state and present that data on a continuous basis has never been greater. 

In addition, continuing to leverage controls will prevent CSPs from having to create multiple packages when going through agency authorizations. I don't know how many agencies are going to buy into the KSIs as an indicator of authorization readiness, but I can guarantee that some won't. As a CSP, that means I'll have to create tooling to address the KSIs and then maintain tooling that also supports NIST 800-53 controls so that I can generate one package for FedRAMP, and an entirely different package that needs to be submitted to the agency. If FedRAMP utilizes a subset of controls;

- 800-53 controls are already a known commodity that agencies are familiar with; and
- If they don't agree with the subset of controls, worse comes to worst they are just going to ask a CSP to provide coverage of additional controls, which will be easier to accomplish than having to completely switch frameworks. 

Again, I really like the push towards understanding system state that the KSIs seem to be driving towards, just not really seeing the point of establishing an entirely new framework to achieve the goal. 



### Replies



#### Reply 1

author: [github.com/jsantore-cgc](https://github.com/jsantore-cgc)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13238909](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13238909)

created: 2025-05-22T20:30:30Z

id: DC_kwDOOxfoic4AygJ9

and I must commend @jdettweiler for this statement because it gets to the heart of the point of KSIs.
> I do appreciate that these KSIs are seemingly pushing CSPs towards being able to report on the **state** of their system

(emphasis his, but slightly different formatting)

Are the KSIs designed to report state, or designed to **include supporting evidence directly**
I think there's some confusion on this.  Is the submittal supposed to be a validated dashboard, or raw evidence itself for review?  It seems like most of the draft proposals are focusing on state, and that's not necessarily bad, but I'm not sure it's universally clear that that's the intent (if in fact, that is the intent).






#### Reply 2

author: [github.com/pete-gov](https://github.com/pete-gov)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13239323](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13239323)

created: 2025-05-22T21:15:27Z

id: DC_kwDOOxfoic4AygQb

For public clarification, questions that are seeking answers outside of the formal public comment process can be posted in FedRAMP's Community Working Groups, such as in the Automating Assessment group's [General Q&A for Participation and Submission in the 20x pilot](https://github.com/FedRAMP/automating-assessment-cwg/discussions/27) thread.



## Comment 45

author: [github.com/faarshad](https://github.com/faarshad)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13248852](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13248852)

created: 2025-05-23T16:30:08Z

id: DC_kwDOOxfoic4AyilU

Thank you for drafting this RFC. My comments are inlined in _italics_
 

> ...These capabilities are designed to provide a concrete approach to evaluating cloud security risks that can often be automatically derived from technical configurations and resolved to true or false.

_A capability that aggregates multiple controls across assets should be considered not met (FALSE) as soon as any single control on any asset fails. For example, if you have ten assets and nine are encrypted but one is not, the overall Key Security Indicator (KSI) fails (should be FALSE)—regardless of the 90% success rate. This binary “all-or-nothing” approach aligns with the “weakest link” principle in security: a single security failure can compromise the entire system._

_Alternatively, you could apply a weighted or percentage-based model—treating some KSIs as strictly binary (pass/fail) and others on a graduated scale based on their criticality—but for clarity and simplicity (KISS principle), my recommendation is all-or-nothing method whenever possible._

> Cloud service providers MUST:

_For readers's clarity, I suggest to note somewhere in this RFC that the term “MUST” is  being used in this RFC as defined in [RFC 2119](https://datatracker.ietf.org/doc/html/rfc2119)._

> 3. Use immutable containers and serverless functions with strictly defined functionality and privileges

_Because containers run on VMs—and most IaaS platforms offer managed VM services—this wording misleadingly suggests that CSPs can ignore the VM’s security configurations and that they need to only focus on building container images or serverless functions. Maybe, we can say: "Use immutable infrastructure - any change requires rebuild/redeployment of the infrastructure component, be it a container/VM image or a function". This won't apply for the case where VMs are managed by Fedramp-authorized IaaS e.g. Fargate ECS or Fargate EKS in the AWS world._

> 2. Execute changes though redeployment of version controlled immutable resources  rather than direct modification wherever possible

_To stress the importance of immutability. I would suggest to change "direct modification" to "direct in-place modification"_
 

> 6. Have a dedicated staff and budget for security

_I’m not sure how this could be fully automated —perhaps by querying the number of employees in the security department. For smaller organizations that only have one or two dedicated security professionals, maybe define a minimum security-staff threshold to ensure adequate coverage._

> 3. Obtain a Software Bill of Materials (SBOM) for third party commercial software components

_The current phrasing implies that SBOMs are only required for third-party components (e.g., appliances from vendors etc). In reality, every piece of software you build depends on external libraries, so we should require a verifiable SBOM for all running components._

### Replies



## Comment 46

author: [github.com/iteuscher](https://github.com/iteuscher)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13250636](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13250636)

created: 2025-05-23T19:58:24Z

id: DC_kwDOOxfoic4AyjBM

Providing branding guidance on how to reference both the 20x process and KSIs would be helpful to ensure consistent use of the terms. For example 20x (lowercase) or 20X (capital)? For referencing a KSI validation should we use KSI-CNA-1 CNA-1, CNA.1, CNA 1 etc? 

Thanks,
Isaac Teuscher (Paramify)

### Replies



## Comment 47

author: [github.com/jkdean](https://github.com/jkdean)

url: [https://github.com/FedRAMP/community/discussions/3#discussioncomment-13257953](https://github.com/FedRAMP/community/discussions/3#discussioncomment-13257953)

created: 2025-05-24T16:21:32Z

id: DC_kwDOOxfoic4Aykzh

FedRAMP’s 20x vision of objective, real time, evidence driven oversight, is exactly what Cybersecurity Performance Management (CPM) was designed to deliver. First highlighted by Gartner® as a high benefit approach for dynamically reducing and communicating cyber risk, CPM complements, and scales with, established frameworks such as RMF, ISO 27001, NIST CSF, CMMC, CIS Controls, and CISA CPGs. It gives organizations a practical, performance centric layer that unifies those standards into a single, continuously managed picture of cyber readiness.

To operationalize CPM, TDI has developed a rich catalogue of Cybersecurity Performance Indicators (CPIs), quantitative, goal based metrics that stream telemetry from existing tools into actionable insight on risk, compliance, maturity, and ROI. CPIs can monitor any aspect of security; for the proposed KSI MLA they might track “% assets successfully sending logs to SIEM” or “% IaC repositories passing policy as code checks.” These metrics update automatically and trend over time, enabling continuous improvement instead of periodic fire drills.

Think of KSIs as the headline scores executives and regulators care about, and CPIs as the engine room gauges that feed those scores. CPM links the two, translating raw technical evidence into clear KSI health indicators and pinpointing exactly which control needs attention whenever a headline drifts. This keeps everyone, from the engineer to the SOC, to the C suite, working from the same data, proving outcomes and driving targeted fixes without guesswork.

GRC suites, built around document workflows, and rigid control mappings struggle to meet this real time mandate without costly retrofits. Automated CPM platforms like TDI’s CnSight are purpose built for FedRAMP’s new direction: they ingest API feeds from the tools industry already uses, compute CPIs continuously, and present tailored views for engineers, risk managers, and Authorizing Officials. 

As a bonus, CPIs can serve as a universal metrics layer across accreditation bodies such as FedRAMP, DoD (including the latest Software Fast Track (SWFT) initiative), and civilian agencies. Moreover, CPIs extend well beyond software assurance, tracking performance metrics across on-premises infrastructure, endpoints, and more. They effectively mirror NIST control families, CIS Critical Security Controls, and Zero Trust Pillars and Activities. This high level of interoperability delivers maximum visibility and trust, enabling true reciprocity across organizations and standards, paving the way for faster authorizations and continuous monitoring that maintains security readiness.

By adopting a CPM-style metric fabric, FedRAMP can move beyond paperwork and static attestations to real-time security insights, ultimately accelerating the approval of cloud products. This means cost effective and efficient delivery of secure, innovative solutions into the hands of federal government, to benefit the American people. 

### Replies

