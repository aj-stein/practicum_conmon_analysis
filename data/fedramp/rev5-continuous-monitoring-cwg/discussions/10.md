# Metadata

title:Proposal: Standardized ConMon Reporting via Automation Pipelines + OSCAL or JSON Templates

author: [github.com/rgutwein](https://github.com/rgutwein)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10)

created: 2025-03-31T13:39:35Z

id: D_kwDOOK0ax84AfFse



# Post

As FedRAMP shifts toward a more modern and scalable approach for continuous monitoring under Rev 5, I wanted to propose a framework that enables cloud service providers (CSPs) to automate and share standardized vulnerability posture reports, without requiring upload of raw scan logs to a centralized service.

### Proposal Overview

Instead of uploading raw scan data, CSPs would:

1. **Automate vulnerability scans** using their internal security tooling (e.g., Tenable, Prisma, Qualys, Trivy, Grype, AWS Inspector, etc).
2. **Convert the results** into a standard report format, such as:
   - **JSON Schema** with key metadata (e.g., severity, CVEs, age).
   - **OSCAL-based `AssessmentResults`** for deeper integration with agency tooling.
3. **Expose those reports** to agency customers via:
   - Existing partner/customer portals.
   - A simple REST API endpoint (OpenAPI spec).
   - Secure object storage (e.g., signed S3 URLs) with metadata manifest.

---

### Benefits

- Empowers CSPs to build ConMon directly into their CI/CD and compliance-as-code pipelines.
- Reduces FedRAMP PMO overhead and processing time.
- Enables agencies to consume posture data in a machine-readable, standardized way.
- Makes room for future enhancements like SBOM drift, patch velocity, and POA&M auto-linking.

---

### Potential Deliverables to Standardize

- Example **JSON schema** (e.g., vulnerability report with counts by severity, scan date, asset ID).
- **OSCAL-based `AssessmentResults`** stub that CSPs can populate.
- Sample **GitHub/GitLab pipeline** to auto-generate reports and publish them securely.
- Reference **dashboard templates** (e.g., Grafana or Looker Studio) for visualization.

---

Would love to hear thoughts on whether this fits into the direction of Rev5 ConMon, and whether others are interested in collaborating on some of these reference implementations.

Thanks,  
**Ryan**


# Comments




## Comment 1

author: [github.com/tashiscool](https://github.com/tashiscool)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12678278](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12678278)

created: 2025-03-31T15:31:36Z

id: DC_kwDOOK0ax84AwXSG

I have a comment on automating the inventory: IaaSs are best positioned to collect and report on inventory data. The IaaS should provide a service/tool to report on all inventory items in a machine readable format in a way that the CSP cannot tamper with. By having IaaS and PaaS providers push usage and inventory data for each dependent CSP directly to FedRAMP, the program could independently validate scan coverage against actual infrastructure deployed. The inventory reporting tool part should be the responsibility of the IaaS to ensure that there are no omissions (intentional or in error) from the CSP-- this is most advantageous to the Government.

### Replies



#### Reply 1

author: [github.com/wisecryptic](https://github.com/wisecryptic)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12755074](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12755074)

created: 2025-04-07T18:52:05Z

id: DC_kwDOOK0ax84AwqCC

I would argue for a modified approach for the following reasons
1. it is ultimately the CSPs responsibility to report on inventory. Agreed that the inventory would be more accurate/less hassle, but the CSP is the one taking responsibility for the inventory (And the consequent security of that inventory). So CSP should always be able to review/approve/modify.
2. this does not serve hybrid systems where partial assets are outside of a major cloud provider.
3. (minor) there would need to be additional thought put into how to classify certain types of components, and there would be some friction in managing vs reporting those components.

a modified approach is that the IaaS is responsible for the tools, but the csp uses them. an IaaS should provide a standard inventory tool to fedramp customers. 



#### Reply 2

author: [github.com/wisecryptic](https://github.com/wisecryptic)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12755086](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12755086)

created: 2025-04-07T18:52:46Z

id: DC_kwDOOK0ax84AwqCO

this allos for responsibility while also streamlining and separating labor of processes to who is best suited to execute them



#### Reply 3

author: [github.com/sunstonesecure-robert](https://github.com/sunstonesecure-robert)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12756845](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12756845)

created: 2025-04-07T22:17:58Z

id: DC_kwDOOK0ax84Awqdt

>  is ultimately the CSPs responsibility to report on inventory

100% agree - and it's relatively easy to do.

> this does not serve hybrid systems where partial assets are outside of a major cloud provider.

there are cloud services ATO'd that provide deployable control planes so you can manage your on-prem servers as if they were in-cloud.  Then there are enterprise tools to manage on-prem network inventories, app inventories, and container inventories for on-prem. if any thing there are too many options - leading to analysis paralysis for some CSPs. And many of those cross-integrate!

And then there is lots of open source tooling to do this in boundary.

(I would provide docs links but I think we want to keep this vendor/solution-agnostic? That said if anyone wants to discuss specific corner cases happy to do so offline on CNCF Slack or wherever is appropriate.)



## Comment 2

author: [github.com/sunstonesecure-robert](https://github.com/sunstonesecure-robert)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12679520](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12679520)

created: 2025-03-31T17:27:45Z

id: DC_kwDOOK0ax84AwXlg

I might break this into 2 separate ideas/deliverables: at the very least the artifact for ConMon should be OSCAL.  Let's discuss the pros (and possible cons, just to be unbiased) of just agreeing to the standard data format.

In parallel, the *how* that is delivered/exposed - API, pipelines, etc - could be multifaceted around authentication/Authorization, is that part of the package/SCR?  managing that with agency federated login or machine-machine credentials, etc etc.  All very good things to get out in the open and hash out - but - perhaps the agreement on using OSCAL artifacts(s) take X discussion whereas the delivery implementation takes 20x (pun intended). So I'd suggest to decouple.

### Replies



#### Reply 1

author: [github.com/kkettner](https://github.com/kkettner)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12680109](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12680109)

created: 2025-03-31T18:28:21Z

id: DC_kwDOOK0ax84AwXut

OSCAL covers the POAM but I am not sure it covers inventory or scans. Should scans be raw, unchanged from what is produced from the scanning tool? There could be a burden on the CSP to prove that data extracted from scans was not altered. 



#### Reply 2

author: [github.com/rgutwein](https://github.com/rgutwein)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12680192](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12680192)

created: 2025-03-31T18:38:47Z

id: DC_kwDOOK0ax84AwXwA

You are correct, OSCAL currently supports POA&M and assessment artifacts quite well, but inventory and scan results aren’t explicitly defined in the OSCAL schema yet. That said, there's growing interest in extending OSCAL with custom components or companion schemas to represent things like:

- Asset inventories (inventory.json)
- Vulnerability scan summaries (not raw data, but structured metrics)
- Observations tied to specific components or controls

On Raw vs. Structured Scan Data

- Requiring raw scan outputs (e.g., Tenable .nessus, Qualys .xml) has always been burdensome, and it’s what Rev5 is trying to move away from. However, I agree that CSPs asserting data without proof or traceability creates a risk.

One potential solution:

- CSPs submit a structured scan summary (JSON) derived from their internal tools

That summary includes a cryptographic hash or signature of the raw file (which could be held in escrow or made available upon request)

Metadata includes: scanner name, version, timestamp, asset ID, CVE ID, severity

This provides:

- Machine-readable summaries for automation
- Traceability back to unaltered raw data
- Optional spot-checking by the government without requiring the full dump every month



#### Reply 3

author: [github.com/shr0p](https://github.com/shr0p)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12690028](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12690028)

created: 2025-04-01T15:02:52Z

id: DC_kwDOOK0ax84AwaJs

Many 3PAOs have gotten involved in helping CSPs generate the monthly conmon artifacts using a number of different methods and solutions, and many CSPs build their own conmon process. If we can define a standard set of deliverables (perhaps beginning with the OSCAL based POAM template) the market can provide the solutions to deliver to the agencies. 

Question: Is it even necessary to require universal delivery of raw scan output? Part of annual 3PAO assessment, or setup of conmon by a 3PAO could be attesting to completeness and accuracy of conmon methods and resulting deliverables. Agencies could require raw output and spot check as desired. 



#### Reply 4

author: [github.com/wisecryptic](https://github.com/wisecryptic)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12756310](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12756310)

created: 2025-04-07T20:56:48Z

id: DC_kwDOOK0ax84AwqVW

thanks @shr0p I appreciate your thoughts on this and agree



#### Reply 5

author: [github.com/atfurman](https://github.com/atfurman)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12764529](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12764529)

created: 2025-04-08T12:58:56Z

id: DC_kwDOOK0ax84AwsVx

@shr0p I'm of the opinion that providing a package with the raw scan results alongside the compiled reports, analysis and KSIs is probably the best way to go- give a reviewer all the information they need to validate assertions if desired (even if they probably won't go that far most of the time, at least starting out). Insofar as it is possible to do so, deliver a testable reporting package. If I'm asserting that a resource was last scanned on 2025-04-08 then I should have no issue providing the raw scan that was used to inform that assertion. 

In my opinion, this extends to the POA&M and deviation requests- if we are wanting to move towards "continuous compliance" a CSP needs to be able to `show their work` at any arbitrary point in the process, not just during annual assessments. 



#### Reply 6

author: [github.com/sunstonesecure-robert](https://github.com/sunstonesecure-robert)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12809479](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12809479)

created: 2025-04-12T00:07:04Z

id: DC_kwDOOK0ax84Aw3UH

> inventory 

OSCAL has this: 

- [SSP model inventory-items
](https://pages.nist.gov/OSCAL-Reference/models/v1.1.3/system-security-plan/json-reference/#/system-security-plan/system-implementation/inventory-items)
- [SAP model inventory-items
](https://pages.nist.gov/OSCAL-Reference/models/v1.1.3/assessment-plan/json-reference/#/assessment-plan/local-definitions/inventory-items)



#### Reply 7

author: [github.com/sunstonesecure-robert](https://github.com/sunstonesecure-robert)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12809490](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12809490)

created: 2025-04-12T00:10:11Z

id: DC_kwDOOK0ax84Aw3US

@rgutwein 

honestly I find this:

> CSPs submit a structured scan summary (JSON) derived from their internal tools

harder than this:

> Requiring raw scan outputs (e.g., Tenable .nessus, Qualys .xml) 

since I get those exports (and APIs) "out of the box". But either way doesn't really matter what format it produces.

What is burdensome is then taking all my nice API generated files and having to manually login to Connect and upload to circa 1990 UI and upload one at a time waiting 5 seconds each time and the page refresh :)

so .... can't we just have an API endpoint where I can automatically pipeline these (signed, hashed, blockchained, etc) up to the Agency or Connect or the Den of the Secret 9?



#### Reply 8

author: [github.com/rgutwein](https://github.com/rgutwein)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12809544](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12809544)

created: 2025-04-12T00:24:04Z

id: DC_kwDOOK0ax84Aw3VI

@sunstonesecure-robert - In theory maybe, but in practice, the problem isn’t generating the JSON, it’s agreeing on the schema, field mappings, and the normalization process across tools like Tenable, Qualys, Prisma, Inspector, etc. Every CSP implements things slightly differently (some even across internal orgs), and raw data dumps are only easier because no one has to agree on what they mean.

“Can’t we just push it all through an API?”

We should have APIs for scan ingestion, but we also need:
- A normalized structure (OSCAL validation schema helps, but doesn’t solve everything),
- A trust framework (signature chaining/blockchain sounds nice but isn’t being used by most CSPs),
- And a governance layer to track scan frequency, scope, false positives, suppression justifications, etc.

Also worth flagging: Just because OSCAL has an inventory model doesn’t mean it’s being used effectively today. Too many SSPs list what the SSP writer thinks the inventory should be, not what’s live in the environment. If we want real-time inventory assurance, we need CSPs pushing live telemetry into validated inventory sources.

TL;DR — Agree with the spirit of automation. But getting this right means more structure, not just less friction. Happy to collaborate on a test schema + ingestion model if others are game.



#### Reply 9

author: [github.com/sunstonesecure-robert](https://github.com/sunstonesecure-robert)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12857700](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12857700)

created: 2025-04-16T17:07:12Z

id: DC_kwDOOK0ax84AxDFk

@rgutwein thanks for calling out the need for ACTUAL code vs theoretical code - LOC speak louder than Jira cards :)

So in the 5 minutes I was waiting for the WG call to start today ... I created 2 example ACME vuln files (attached) 
[tenable_acme.csv](https://github.com/user-attachments/files/19781439/tenable_acme.csv)
[qualys_acme.csv](https://github.com/user-attachments/files/19781440/qualys_acme.csv)
using the CSV cols from a Qualys and Tenable export. I ran it through LLM to [generate this Colab notebook.](https://colab.research.google.com/gist/sunstonesecure-robert/5c82114aef285fd2627b9682219ced6e/vulns-2-oscal-ar.ipynb)  I did *not* in this 5 minutes test if it is valid OSCAL, correlate it to the inventory model, run NIST validations, etc etc. - but - I hope you would agree - we HAVE a standard format in OSCAL. We can perefect it over time, but we have a way to do all the things you note that are very important, I agree. 

Send me some CVS cols for these other tools and I'll add that code, too!! Come to the CNCF Compliance WG and load us up with feature requests and use cases and we can live code together!

Free open source code - that's the solution. But DO keep challenging and asking for proof via code. We can do this!!



## Comment 3

author: [github.com/cybersechawk](https://github.com/cybersechawk)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12691839](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12691839)

created: 2025-04-01T18:03:36Z

id: DC_kwDOOK0ax84Awal_

Copying here for viz...  hey @rgutwein and community team ,  I think there is interest in forming a community around an open source implementation.   The challenge will be to find people who can dedicate time after work or whose company would allow for contribution as part of their job.   I work full time for a CSP on the FedRAMP path, but would love to help as I can after-hours.   In order to take an incremental approach, I outlined a [possible first incremental step](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/17) towards a more comprehensive solution as you outlined above in separate thread with a focus just on inventory

### Replies



#### Reply 1

author: [github.com/sunstonesecure-robert](https://github.com/sunstonesecure-robert)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12857709](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12857709)

created: 2025-04-16T17:08:53Z

id: DC_kwDOOK0ax84AxDFt

I agree. That said we do have a WG @ CNCF for this exact sort of thing - but - I totally understand if folks want a more FedRAMP "branded" WG. Happy to help!



## Comment 4

author: [github.com/austinsonger](https://github.com/austinsonger)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12707877](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12707877)

created: 2025-04-03T01:37:18Z

id: DC_kwDOOK0ax84Awegl

@rgutwein @tashiscool @shr0p @kkettner @sunstonesecure-robert @cybersechawk  


#### **1. Defining Standard Deliverables with OSCAL and JSON Templates**  

- **Adopt OSCAL for ConMon Artifacts:** Utilize OSCAL's existing schema for POA&M and assessment artifacts, but extend it with custom schemas for inventory and scan summaries.  
- **Standard JSON Schemas for Scan Summaries:** Develop clear, structured schemas that include essential metadata:  
  - **Scanner Type and Version:** (e.g., Tenable, Trivy, AWS Inspector)  
  - **Asset Identifiers:** IP addresses, container IDs, VM names, etc.  
  - **Severity Levels:** Categorized into Critical, High, Medium, Low  
  - **CVE IDs:** A list of identified vulnerabilities  
  - **Scan Timestamp:** The exact date and time of the scan  
  - **Cryptographic Hashes:** To provide traceability to raw data if necessary.  

---

#### **2. Leveraging Cryptographic Hashing for Traceability**  

- **Signed Scan Summaries:** By including cryptographic hashes of raw scan files in structured reports, CSPs can provide evidence of integrity without requiring the submission of raw data.  
- **Spot-Check Capability:** Agencies can request raw scan files if necessary, but only in cases where further scrutiny is required.  

---

#### **3. API-Driven Reporting Framework**  

- **Standardized API Specifications:** Define REST API standards for agencies to consume ConMon reports. This could be based on OpenAPI specifications, ensuring consistent integration across different CSPs.  
- **OSCAL and JSON Report Submission:** Allow submission of ConMon artifacts via API endpoints to eliminate manual uploads and improve consistency.  

---

#### **4. Simplifying Compliance for CSPs**  

- **Reference Implementations:** Provide sample GitHub Actions/GitLab CI pipelines that demonstrate:  
  - Automated scan execution  
  - Conversion of raw data to standardized JSON/OSCAL reports  
  - Publishing reports securely (e.g., signed S3 URLs)  
- **Visualization Dashboards:** Create reference templates for visualization using Grafana, Looker Studio, or other platforms to enable agencies to easily consume reports.  

---

#### **5. Extending OSCAL to Cover Inventory and Scan Summaries**  

- While OSCAL currently supports POA&M and assessment artifacts, we need a formal schema for inventory and scan summaries.  
- Propose adding new elements to OSCAL for:  
  - **Inventory Artifacts:** Providing structured descriptions of assets and their configurations.  
  - **Vulnerability Summaries:** Aggregated findings from various scanning tools.  
  - **Control Mappings:** Linking findings directly to applicable NIST 800-53 controls.  

---

#### **6. Incremental Approach Towards Standardization**  

- Start by formalizing the JSON schema for scan summaries.  
- Define minimum metadata requirements for ConMon submissions.  
- Allow CSPs to adopt this approach incrementally, providing flexibility to integrate with their existing tooling.  

### Replies



#### Reply 1

author: [github.com/Telos-sa](https://github.com/Telos-sa)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12752377](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12752377)

created: 2025-04-07T14:42:27Z

id: DC_kwDOOK0ax84AwpX5

@austinsonger I think a great approach would be to "unlock" the SSP model, so that the top level elements become optional.  This would meet your point 5 and 6 very nicely without the added burden of creating new standards, since the standards already exist in OSCAL, and can be met.  Dont forget OSCAL does support a json structure.  

The SSP model already has an inventory, and detailed component layer.  The POAM model aloows for vulnearbility summaries, and control mapping. 
Leveraging them together allows us to associated the vulnerabilities back to their details in the SSP, making for a robust reporting mechanism that crosses the different models.  
If you check out my comment under [Assessing Monitoring Over Time (KSI Approach)](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/12#discussioncomment-12690088) I provide a detailed breakdown of the structure for inventory reporting, taking into account how we can report on components as well.  

Alternatives to OSCAL, or a candidate for translation to standardized OSCAL, would be the XCCDF format.  This is what STIGs are already in, so it makes sense if we can communicate in OSCAL and XCCDF already, and various scanners already support the XCCDF export.  The challenge here would be maintaining the repository of CCI's from DISA to be able to accurately measure control compliance at the Assessment objective.  



#### Reply 2

author: [github.com/aj-stein-gsa](https://github.com/aj-stein-gsa)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12753382](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12753382)

created: 2025-04-07T16:06:24Z

id: DC_kwDOOK0ax84Awpnm

> Alternatives to OSCAL, or a candidate for translation to standardized OSCAL, would be the XCCDF format. This is what STIGs are already in, so it makes sense if we can communicate in OSCAL and XCCDF already, and various scanners already support the XCCDF export. The challenge here would be maintaining the repository of CCI's from DISA to be able to accurately measure control compliance at the Assessment objective.

Have you seen sustained or increased adoption of XCCDF and use of the SCAP standards in cloud-native deployments? How do you see it working more comprehensively for cloud-native services? Most all of DoD-made XCCDF checklists around operating systems and sometimes dedicated OSes for network equipment (I think some OCI container orchestrators and some flavors of Kubernetes are the outlier). Do you know of others not maintained by DISA in XCCDF format for DoD? [The cloud security list on cyber.mil](https://public.cyber.mil/stigs/downloads/?_dl_facet_stigs=cloud-security-stigs) is very short.

I ask because it appears SCAP has fizzled out, aside from sustained use by the core DoD groups, SCAP 1.3 never materialized, and there are now many proprietary and commercial tools, along with different formats, that have spread across the cloud security space. I am really curious how you see the landscape, and if you see it differently.




#### Reply 3

author: [github.com/rgutwein](https://github.com/rgutwein)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12753813](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12753813)

created: 2025-04-07T16:43:23Z

id: DC_kwDOOK0ax84AwpuV

From what I’ve seen, many CSPs and container publishers (like Iron Bank) still leverage OpenSCAP directly in their CI/CD pipelines to generate XCCDF and ARF outputs for container-based images. For example, Iron Bank documents how to locally scan containers using OpenSCAP here: [Iron Bank OpenSCAP Testing Guide](https://docs-ironbank.dso.mil/tutorials/local-openscap-testing/). This is commonly used to ensure STIG alignment early in the pipeline before promotion.

At the OS level, Amazon, for example provides STIG-hardened AMIs that are validated using SCAP-based tooling, including XCCDF benchmarks. These AMIs are particularly useful for customers in regulated environments who need DISA-compliant baselines out of the box. So while SCAP tooling itself may not be visible at the higher abstraction layers (like Kubernetes), it’s still quite active at the image and instance level.

That said, you’re right that the broader tooling ecosystem has evolved, we’re now seeing more policy-as-code implementations (e.g., OPA, InSpec) and compliance reporting frameworks (like OSCAL) gaining traction. SCAP 1.3 never quite got the lift-off needed, and many vendors are focusing on CNAPP and SBOM-native approaches instead.

The challenge remains: DISA’s XCCDF checklist coverage is still largely OS- and device-focused. There’s a real opportunity for the community to create more cloud-native XCCDF content, maybe even a GitHub-driven model similar to what Red Hat does with [ComplianceAsCode](https://github.com/ComplianceAsCode/content).



#### Reply 4

author: [github.com/sunstonesecure-robert](https://github.com/sunstonesecure-robert)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12756735](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12756735)

created: 2025-04-07T21:53:54Z

id: DC_kwDOOK0ax84Awqb_

> [ComplianceAsCode](https://github.com/ComplianceAsCode/content).

which is also OSCAL integrated!



## Comment 5

author: [github.com/dljenkins](https://github.com/dljenkins)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12713988](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12713988)

created: 2025-04-03T13:34:20Z

id: DC_kwDOOK0ax84AwgAE

ConMon should be just that, Continuous Monitoring. We need to get away from generating monthly reports and enable dynamic retrieval of the current security posture of the system. OSCAL should be used but not as a reporting format. Instead, OSCAL should provide Monitoring Status as Code enabling authorized personnel to retrieve the current status on-demand. This should be status, metrics, KPIs and not the details behind that status.

For example, does an Agency really need to see the full inventory of a system? Would they know what they are looking at if they did have that, I suggest not. Instead an Agency needs to know that the CSP has control of their inventory, that the CSP detects new inventory and validates it is approved per change control or not approved and thereby removed. The Agency just needs to see the metrics on how the CSP is performing with relation to managing their inventory.

### Replies



#### Reply 1

author: [github.com/rgutwein](https://github.com/rgutwein)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12714695](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12714695)

created: 2025-04-03T14:36:49Z

id: DC_kwDOOK0ax84AwgLH

Thanks for the response @dljenkins - I agree that the future of ConMon should support dynamic, on-demand retrieval of security posture — moving away from static monthly reporting. That said, most agencies today still rely on well-defined ConMon Plans that call for regular reporting of specific metrics, many of which are sourced from:

- **SIEMs/log event tools** for control activity verification (e.g., AC, AU, IR),
- **Vulnerability scanners** for counts by severity across OS, containers, DBs, and web apps,
- **Manual assessments** identifying control deficiencies,
- **POA&M tracking tools** (often manually maintained or exported from GRC platforms).

My intent behind suggesting JSON and OSCAL-based standardization is to structure these common, recurring data points in a machine-readable way — not to create an entirely new reporting burden. Ideally, it sets the stage for:

- Monitoring as Code, as you mentioned, where authorized stakeholders can retrieve posture data (e.g., open POA&Ms, patch velocity, SBOM drift) through a simple API,
- More automated and real-time ingestion into agency dashboards and compliance tooling,
- Reduced manual friction for both CSPs and agencies through standardized templates and report stubs (e.g., OSCAL `AssessmentResults`).

Would love to explore how we can merge these ideas, dynamic status retrieval *and* a practical path forward for CSPs and agencies still operating under legacy ConMon Plans.





#### Reply 2

author: [github.com/austinsonger](https://github.com/austinsonger)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12720622](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12720622)

created: 2025-04-04T02:56:26Z

id: DC_kwDOOK0ax84Awhnu

> nd. This should be status, metrics, KPIs and not the details behind that status.

I worked for the Navy before as well as the Veteran Affairs. And if its not documented then it doesn't exist or it never happened. So getting away from providing a full inventory probably will not happen.



#### Reply 3

author: [github.com/dljenkins](https://github.com/dljenkins)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12725118](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12725118)

created: 2025-04-04T11:29:45Z

id: DC_kwDOOK0ax84Awit-

The details can be made available for sure, but the on-demand status should be focused on metrics & KPIs. It's certainly not about hiding anything from the client. It's more about making it readily and dynamically available with layers of information. If clients see the metrics & KPIs, have the ability to view the details behind it, then eventually they learn to trust the metrics & KPIs and only occasionally check the details. I don't believe every client is reviewing every single inventory item every month. I suspect there maybe a few, but mostly not.



#### Reply 4

author: [github.com/rgutwein](https://github.com/rgutwein)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12725210](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12725210)

created: 2025-04-04T11:37:22Z

id: DC_kwDOOK0ax84Awiva

Appreciate both of your perspectives here, and I agree that metrics and KPIs are the ideal interface for executive stakeholders. But from a FedRAMP compliance and ConMon standpoint, **providing a monthly integrated inventory is a required deliverable**, and it’s not just a formality.

Agencies *do* analyze and examine inventory data — especially to:
- Confirm coverage of vulnerability scans,
- Validate changes in system boundary or component composition,
- Track asset lifecycle, ownership, or categorization for impact levels,
- Correlate assets to POA&Ms or scan findings.

The good news is: **this doesn’t have to be manual or static anymore**. Inventories can (and should) be generated automatically using:
- AWS Config / Azure Resource Graph / GCP Asset Inventory,
- CSPM tools like Prisma, Wiz, or Defender for Cloud,
- Export APIs from CMDBs or agent-based inventory systems.

We’re trying to move *away* from uploading spreadsheets to email or eMASS/OMB MAX, etc and instead toward **real-time API exposure of current inventory**, with metrics + metadata at the top layer, and full detail retrievable via drill-down.

This creates an elegant structure:
- **Metrics/KPIs at the top** (e.g., inventory drift, asset count, asset types added/removed),
- **Linked detail beneath** for anyone who needs to dive deeper.

Thanks again — I think we’re all aiming for the same outcome: actionable, trustworthy reporting with automation and layered insight.



#### Reply 5

author: [github.com/sunstonesecure-robert](https://github.com/sunstonesecure-robert)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12756766](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12756766)

created: 2025-04-07T22:00:09Z

id: DC_kwDOOK0ax84Awqce

> Agencies do analyze and examine inventory data

I agree - but this is a pro and a con.  Pros: 

CSPs are very sloppy and hand wavy about what a control does. 3PAOs often accept 1 example and ignore the 100 other corner cases.  Not having a check for each and every resource in scope means *something* is not compliant.  And it's not because CSPs don't care - often even with automation, changes come so fast and furious it's impossible for any human team to keep up.  

Cons:

Basing *any* review on a static point in time inventory that is already obsolete by the time it's produced is a poor substitute for having automated checks that systematically read in from pipelines or APIs the full inventory and runs tests against each and every resource in boundary.  In modern micro-service CSOs the inventory changes multiple times per day.  The bad guys aren't going to rely on a spreadsheet - they are going to phish your admins, get real-time API intel on what you have in boundary and kick butt and chew bubble gum. Why wouldn't we do the same on the defensive side?

