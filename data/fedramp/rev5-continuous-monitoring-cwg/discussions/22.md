# Metadata

title:Simplified Secure Configurations (CM-6)

author: [github.com/cybersechawk](https://github.com/cybersechawk)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/22](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/22)

created: 2025-04-04T13:36:13Z

id: D_kwDOOK0ax84AfJ1S



# Post

With the new requirement for STIG / CIS L2, this one control is within the top ten for implementation time.   When you break down the requirement for secure configuration, it requires most CSP's to focus on securing configurations at multiple-levels within their infrastructure:
* Cloud Service Level 
* OS Level
* Container Level
* Database Level
* Kubernetes Cluster Level
* Application Level
  
I propose that as part of this thread, we collect ideas as to how best to automate or save time on secure configuration for the most common technology stack choices, how best to programmatically verify secure configuration for monthly ConMon summarized report and identify where there are gaps that are time consuming and/or expensive for CSPs to address.   I think if we map this out, we will see a lot of very time consuming and expensive gaps for CSPs today, a lot of areas that need more clarity as to how to handle and a lot of room for us, as a community, to improve this important area.



# Comments




## Comment 1

author: [github.com/ryangmsi](https://github.com/ryangmsi)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/22#discussioncomment-12729121](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/22#discussioncomment-12729121)

created: 2025-04-04T17:54:08Z

id: DC_kwDOOK0ax84Awjsh

I will get the ball rolling:

# Simplified Secure Configurations (CM-6)

## Overview

This initiative aims to address FedRAMP/StateRAMP Control CM-6: "Configuration Settings" by simplifying and automating secure configuration across all major layers of a CSP's technology stack. With the implementation of STIG / CIS L2 baselines now being prioritized, CM-6 ranks in the top ten for implementation effort and complexity.

Most CSPs must configure and maintain secure baselines across:

- Cloud Service Level (e.g., AWS, Azure, GCP)
- OS Level (e.g., Windows, Linux)
- Container Level (e.g., Docker, containerd)
- Database Level (e.g., PostgreSQL, MySQL, SQL Server)
- Kubernetes Cluster Level (e.g., kube-apiserver, kubelet, etcd)
- Application Level (custom code and COTS configurations)

## Objective

The goal of this community-driven effort is to:

1. **Map out common gaps** in secure configuration across the stack that are:
   - Time consuming
   - Costly
   - Ambiguous in guidance

2. **Propose automation** for secure configuration wherever possible.

3. **Develop tooling, scripts, and checklists** that help CSPs:
   - Programmatically verify secure configuration
   - Integrate checks into ConMon / Continuous Monitoring processes
   - Summarize secure configuration status in monthly reports

---

## Notional Solution: "SecureConfigStack" Microframework

To kick off discussion, here's a proposed solution that we can evolve together:

### Concept
A lightweight, modular microframework called `SecureConfigStack` that integrates with CSP pipelines to continuously verify baseline configuration at each infrastructure level and outputs a monthly summary formatted for FedRAMP ConMon reports.

### Core Components
| Layer                  | Tooling Stack                                         | Automation Examples                                         |
|------------------------|--------------------------------------------------------|-------------------------------------------------------------|
| Cloud Service Level    | AWS Config / Azure Policy / GCP SCC                   | Automated rule checks via Terraform Validator, OPA Rego     |
| OS Level               | OpenSCAP / Lynis / Ansible STIG Roles                 | Ansible playbooks with nightly cron runs                    |
| Container Level        | Trivy / Docker Bench Security                         | GitLab CI scan job & block on high severity                 |
| Database Level         | CIS DB Benchmarks via custom Bash or SQL scripts      | Nightly DB hardening verification + audit logging           |
| Kubernetes Cluster     | kube-bench / kube-hunter / Polaris                    | Admission controller enforcing baseline (e.g., OPA/Gatekeeper) |
| Application Level      | AppArmor / Snyk / custom config linters               | Validate logging, authentication, and port lockdown         |

### Outputs
- Monthly `secure-config-summary.json` (machine-readable)
- FedRAMP/StateRAMP-ready PDF snapshot of configuration posture
- Alerts for drift from secure baselines
- Evidence package builder for ConMon

### Use Case
A CSP integrates `SecureConfigStack` into their CI/CD pipeline and cron jobs. The framework runs checks, reports status to a dashboard, and generates a FedRAMP/StateRAMP-compliant report bundle every 30 days—making CM-6 a maintainable, automated, and reportable process.

---

## Deliverables

We aim to build:

-  A matrix of secure configuration controls vs. implementation layers
-  Sample scripts and Ansible/Helm modules for automated hardening
-  Configuration check utilities (e.g., OpenSCAP, kube-bench, Trivy)
-  ConMon-ready secure config summary templates
-  GitHub Actions or GitLab CI/CD pipelines for automated validation
-  Reference guides and lessons learned from CSPs

---

## How to Contribute

- Suggest known pain points or gaps in secure configuration
- Submit existing tooling you’ve used or developed
- Propose ideas for automation or reporting
- Review and test automation scripts
- Share feedback on how to streamline ConMon evidence collection

---

## Discussion Prompt

To get the ball rolling, please respond with:
- Which configuration layer is most painful or redundant for you?
- What secure configuration practices or tooling have saved you time?
- Would you find value in a unified automation framework like `SecureConfigStack`?

---

## Long-Term Vision

A reusable, pluggable framework that allows CSPs to:
- Reduce time-to-compliance for CM-6
- Automatically detect and report secure config drift
- Standardize ConMon outputs for reviewer consumption





### Replies



## Comment 2

author: [github.com/kamamanh](https://github.com/kamamanh)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/22#discussioncomment-12729697](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/22#discussioncomment-12729697)

created: 2025-04-04T19:00:31Z

id: DC_kwDOOK0ax84Awj1h

Most painful config layer is a toss up between DB and OS.  DB because there are so many manual or "additional configuration needed" checks, such as ensuring only "allowed" users/roles/etc have certain permissions. The "allowed" part is what requires extra work, because how does the check ensure that a thing is allowed?   On the OS side, it's just the sheer number of false positives that come with running a SCAP.   

We have found that creating custom checks in our tooling to check for what we consider the correct configuration has been helpful, as we use that alongside our False Positives to be able to accept/ignore the FP checks within our tool and focus on a truer version of when we are actually failing a compliance item. For example, if I am using a fancy 3rd party tool for FIM, I'll fail the linux checks that are written to look for aide. I am meeting the control, but not in the way the SCAP has been written.  If I have a custom check for that 3rd party FIM, then I can mark the aide checks to ignore, and sub in my own FIM checks.  The difficulty here is when auditors, agencies, etc, expect results against a pristine SCAP. We provide that, but then also utilize our custom checks as part of our FP justification. Internally those custom checks allow us to get alerts when we are legitimately out of compliance. 

Not sure if we would find value in something like the proposed framework, as we currently utilize a 3rd party tool for most of our compliance scanning. I think the trickiness with the idea of your framework is having the centralized dashboard tool/system that the SecureConfigStack would report to - both in the sense that there needs to be a something that someone hosts and maintains (is this on the CSP? is this a SaaS service? If so, why not just use one of the existing SaaS providers that do compliance scans?), and also that CSPs are going to want to have that compliance data in a place that their teams can do workflow off of (scheduling remediation tasks with internal teams, etc). 

That all said, compliance scanning as it relates to containerized environments seems to be a big ball of confusion from people I've spoken to. Clarifying a bit more, and in very concise language, what exactly needs to be scanned for my helloworld container instance running in AWS Fargate or GCP GKE, along with the expectations on how I handle all the things which are not within the scope of the CSP to remediate, or which do not make technical sense in a containerized OS, would do wonders for easing the process.  

### Replies



#### Reply 1

author: [github.com/ryangmsi](https://github.com/ryangmsi)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/22#discussioncomment-12729998](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/22#discussioncomment-12729998)

created: 2025-04-04T19:39:46Z

id: DC_kwDOOK0ax84Awj6O

## @kamamanh – 

Thank you for the deep and insightful response. You surfaced several key pain points, db/OS config ambiguity, SCAP rigidity, FP management, container clarity, and dashboard ownership. Based on your feedback, here’s a refined roadmap to evolve the `SecureConfigStack` idea:

---

### Focus Area 1: OS & DB Layers First

**OS Layer**  
- FP Justification Layer (`custom_rules.yml` with `justification`, `evidence_link`)  
- Custom Profile Support for OpenSCAP + override validation  
- FIM integration mapping (e.g., Wazuh, OSSEC)

**DB Layer**  
- "Allowed Roles" DSL (`only_roles: ['admin', 'readonly']`)  
- SQL-driven checks per engine (Postgres, MySQL, SQL Server)  
- Baseline packs mapped to CIS/STIG

---

### Plugin-Based Custom Checks

Support custom check injection:
- YAML/JSON rule packs  
- Bash/Python/SQL scripts  
- Unified output schema (`check_id`, `status`, `notes`, etc.)

Use for internal controls + justification in audits.

---

### Deployment Options

| Mode                | Purpose                                  |
|---------------------|-------------------------------------------|
| CLI Agent           | Self-hosted scans (cron, manual, pipeline) |
| CI/CD Modules       | GitHub/GitLab pipelines                  |
| Optional Dashboard  | OSS UI + SaaS (for drift tracking, team workflows) |
| eMASS Exporter      | `conmon.zip` + `poam-import.csv` generator |

---

### Container/K8s Scoping Clarity

- Shared Responsibility Matrix for Fargate/GKE/EKS  
- Clarify what *can* be controlled vs. what’s CSP-owned  
- Policy packs for image scanning, runtime configs, admission controllers

---

### Roadmap (Short Version)

- **M1** – Community-sourced config drift matrix  
- **M2** – OS/db check modules + custom override support  
- **M3** – ConMon-ready outputs (PDF, JSON, ZIP)  
- **M4** – CI/CD pipeline integrations  
- **M5** – Optional dashboard UI  
- **M6+** – Container/K8s & App-level configs

---

### Follow-Up

Would love your take on:
- Preferred format for FP overrides?  
- Ideal output format for ConMon snapshots?





#### Reply 2

author: [github.com/kamamanh](https://github.com/kamamanh)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/22#discussioncomment-12781972](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/22#discussioncomment-12781972)

created: 2025-04-09T18:02:03Z

id: DC_kwDOOK0ax84AwwmU

I think M0 needs to be getting clarity on the scoping.  

As far as ConMon snapshots, I think a basic chart/graph per type with pass/fall count per check severity (DISA severity, because some 3rd party tools come up with their own) in a PDF would be helpful.  We also have to realistically expect that many agencies are still going to want to get raw scans data if they have been doing so in the past and that they will lag behind CSPs in adoption of any programmatic approach. 

