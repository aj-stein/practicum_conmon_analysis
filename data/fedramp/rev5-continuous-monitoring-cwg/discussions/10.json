{
  "id": "D_kwDOOK0ax84AfFse",
  "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10",
  "title": "Proposal: Standardized ConMon Reporting via Automation Pipelines + OSCAL or JSON Templates",
  "body": "As FedRAMP shifts toward a more modern and scalable approach for continuous monitoring under Rev 5, I wanted to propose a framework that enables cloud service providers (CSPs) to automate and share standardized vulnerability posture reports, without requiring upload of raw scan logs to a centralized service.\r\n\r\n### Proposal Overview\r\n\r\nInstead of uploading raw scan data, CSPs would:\r\n\r\n1. **Automate vulnerability scans** using their internal security tooling (e.g., Tenable, Prisma, Qualys, Trivy, Grype, AWS Inspector, etc).\r\n2. **Convert the results** into a standard report format, such as:\r\n   - **JSON Schema** with key metadata (e.g., severity, CVEs, age).\r\n   - **OSCAL-based `AssessmentResults`** for deeper integration with agency tooling.\r\n3. **Expose those reports** to agency customers via:\r\n   - Existing partner/customer portals.\r\n   - A simple REST API endpoint (OpenAPI spec).\r\n   - Secure object storage (e.g., signed S3 URLs) with metadata manifest.\r\n\r\n---\r\n\r\n### Benefits\r\n\r\n- Empowers CSPs to build ConMon directly into their CI/CD and compliance-as-code pipelines.\r\n- Reduces FedRAMP PMO overhead and processing time.\r\n- Enables agencies to consume posture data in a machine-readable, standardized way.\r\n- Makes room for future enhancements like SBOM drift, patch velocity, and POA&M auto-linking.\r\n\r\n---\r\n\r\n### Potential Deliverables to Standardize\r\n\r\n- Example **JSON schema** (e.g., vulnerability report with counts by severity, scan date, asset ID).\r\n- **OSCAL-based `AssessmentResults`** stub that CSPs can populate.\r\n- Sample **GitHub/GitLab pipeline** to auto-generate reports and publish them securely.\r\n- Reference **dashboard templates** (e.g., Grafana or Looker Studio) for visualization.\r\n\r\n---\r\n\r\nWould love to hear thoughts on whether this fits into the direction of Rev5 ConMon, and whether others are interested in collaborating on some of these reference implementations.\r\n\r\nThanks,  \r\n**Ryan**\r\n",
  "author": "rgutwein",
  "created_at": "2025-03-31T13:39:35Z",
  "comments": [
    {
      "id": "DC_kwDOOK0ax84AwXSG",
      "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12678278",
      "body": "I have a comment on automating the inventory: IaaSs are best positioned to collect and report on inventory data. The IaaS should provide a service/tool to report on all inventory items in a machine readable format in a way that the CSP cannot tamper with. By having IaaS and PaaS providers push usage and inventory data for each dependent CSP directly to FedRAMP, the program could independently validate scan coverage against actual infrastructure deployed. The inventory reporting tool part should be the responsibility of the IaaS to ensure that there are no omissions (intentional or in error) from the CSP-- this is most advantageous to the Government.",
      "author": "tashiscool",
      "created_at": "2025-03-31T15:31:36Z",
      "replies": [
        {
          "id": "DC_kwDOOK0ax84AwqCC",
          "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12755074",
          "body": "I would argue for a modified approach for the following reasons\r\n1. it is ultimately the CSPs responsibility to report on inventory. Agreed that the inventory would be more accurate/less hassle, but the CSP is the one taking responsibility for the inventory (And the consequent security of that inventory). So CSP should always be able to review/approve/modify.\r\n2. this does not serve hybrid systems where partial assets are outside of a major cloud provider.\r\n3. (minor) there would need to be additional thought put into how to classify certain types of components, and there would be some friction in managing vs reporting those components.\r\n\r\na modified approach is that the IaaS is responsible for the tools, but the csp uses them. an IaaS should provide a standard inventory tool to fedramp customers. ",
          "author": "wisecryptic",
          "created_at": "2025-04-07T18:52:05Z"
        },
        {
          "id": "DC_kwDOOK0ax84AwqCO",
          "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12755086",
          "body": "this allos for responsibility while also streamlining and separating labor of processes to who is best suited to execute them",
          "author": "wisecryptic",
          "created_at": "2025-04-07T18:52:46Z"
        },
        {
          "id": "DC_kwDOOK0ax84Awqdt",
          "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12756845",
          "body": ">  is ultimately the CSPs responsibility to report on inventory\r\n\r\n100% agree - and it's relatively easy to do.\r\n\r\n> this does not serve hybrid systems where partial assets are outside of a major cloud provider.\r\n\r\nthere are cloud services ATO'd that provide deployable control planes so you can manage your on-prem servers as if they were in-cloud.  Then there are enterprise tools to manage on-prem network inventories, app inventories, and container inventories for on-prem. if any thing there are too many options - leading to analysis paralysis for some CSPs. And many of those cross-integrate!\r\n\r\nAnd then there is lots of open source tooling to do this in boundary.\r\n\r\n(I would provide docs links but I think we want to keep this vendor/solution-agnostic? That said if anyone wants to discuss specific corner cases happy to do so offline on CNCF Slack or wherever is appropriate.)",
          "author": "sunstonesecure-robert",
          "created_at": "2025-04-07T22:17:58Z"
        }
      ]
    },
    {
      "id": "DC_kwDOOK0ax84AwXlg",
      "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12679520",
      "body": "I might break this into 2 separate ideas/deliverables: at the very least the artifact for ConMon should be OSCAL.  Let's discuss the pros (and possible cons, just to be unbiased) of just agreeing to the standard data format.\r\n\r\nIn parallel, the *how* that is delivered/exposed - API, pipelines, etc - could be multifaceted around authentication/Authorization, is that part of the package/SCR?  managing that with agency federated login or machine-machine credentials, etc etc.  All very good things to get out in the open and hash out - but - perhaps the agreement on using OSCAL artifacts(s) take X discussion whereas the delivery implementation takes 20x (pun intended). So I'd suggest to decouple.",
      "author": "sunstonesecure-robert",
      "created_at": "2025-03-31T17:27:45Z",
      "replies": [
        {
          "id": "DC_kwDOOK0ax84AwXut",
          "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12680109",
          "body": "OSCAL covers the POAM but I am not sure it covers inventory or scans. Should scans be raw, unchanged from what is produced from the scanning tool? There could be a burden on the CSP to prove that data extracted from scans was not altered. ",
          "author": "kkettner",
          "created_at": "2025-03-31T18:28:21Z"
        },
        {
          "id": "DC_kwDOOK0ax84AwXwA",
          "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12680192",
          "body": "You are correct, OSCAL currently supports POA&M and assessment artifacts quite well, but inventory and scan results aren\u2019t explicitly defined in the OSCAL schema yet. That said, there's growing interest in extending OSCAL with custom components or companion schemas to represent things like:\r\n\r\n- Asset inventories (inventory.json)\r\n- Vulnerability scan summaries (not raw data, but structured metrics)\r\n- Observations tied to specific components or controls\r\n\r\nOn Raw vs. Structured Scan Data\r\n\r\n- Requiring raw scan outputs (e.g., Tenable .nessus, Qualys .xml) has always been burdensome, and it\u2019s what Rev5 is trying to move away from. However, I agree that CSPs asserting data without proof or traceability creates a risk.\r\n\r\nOne potential solution:\r\n\r\n- CSPs submit a structured scan summary (JSON) derived from their internal tools\r\n\r\nThat summary includes a cryptographic hash or signature of the raw file (which could be held in escrow or made available upon request)\r\n\r\nMetadata includes: scanner name, version, timestamp, asset ID, CVE ID, severity\r\n\r\nThis provides:\r\n\r\n- Machine-readable summaries for automation\r\n- Traceability back to unaltered raw data\r\n- Optional spot-checking by the government without requiring the full dump every month",
          "author": "rgutwein",
          "created_at": "2025-03-31T18:38:47Z"
        },
        {
          "id": "DC_kwDOOK0ax84AwaJs",
          "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12690028",
          "body": "Many 3PAOs have gotten involved in helping CSPs generate the monthly conmon artifacts using a number of different methods and solutions, and many CSPs build their own conmon process. If we can define a standard set of deliverables (perhaps beginning with the OSCAL based POAM template) the market can provide the solutions to deliver to the agencies. \n\nQuestion: Is it even necessary to require universal delivery of raw scan output? Part of annual 3PAO assessment, or setup of conmon by a 3PAO could be attesting to completeness and accuracy of conmon methods and resulting deliverables. Agencies could require raw output and spot check as desired. ",
          "author": "shr0p",
          "created_at": "2025-04-01T15:02:52Z"
        },
        {
          "id": "DC_kwDOOK0ax84AwqVW",
          "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12756310",
          "body": "thanks @shr0p I appreciate your thoughts on this and agree",
          "author": "wisecryptic",
          "created_at": "2025-04-07T20:56:48Z"
        },
        {
          "id": "DC_kwDOOK0ax84AwsVx",
          "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12764529",
          "body": "@shr0p I'm of the opinion that providing a package with the raw scan results alongside the compiled reports, analysis and KSIs is probably the best way to go- give a reviewer all the information they need to validate assertions if desired (even if they probably won't go that far most of the time, at least starting out). Insofar as it is possible to do so, deliver a testable reporting package. If I'm asserting that a resource was last scanned on 2025-04-08 then I should have no issue providing the raw scan that was used to inform that assertion. \r\n\r\nIn my opinion, this extends to the POA&M and deviation requests- if we are wanting to move towards \"continuous compliance\" a CSP needs to be able to `show their work` at any arbitrary point in the process, not just during annual assessments. ",
          "author": "atfurman",
          "created_at": "2025-04-08T12:58:56Z"
        },
        {
          "id": "DC_kwDOOK0ax84Aw3UH",
          "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12809479",
          "body": "> inventory \r\n\r\nOSCAL has this: \r\n\r\n- [SSP model inventory-items\r\n](https://pages.nist.gov/OSCAL-Reference/models/v1.1.3/system-security-plan/json-reference/#/system-security-plan/system-implementation/inventory-items)\r\n- [SAP model inventory-items\r\n](https://pages.nist.gov/OSCAL-Reference/models/v1.1.3/assessment-plan/json-reference/#/assessment-plan/local-definitions/inventory-items)",
          "author": "sunstonesecure-robert",
          "created_at": "2025-04-12T00:07:04Z"
        },
        {
          "id": "DC_kwDOOK0ax84Aw3US",
          "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12809490",
          "body": "@rgutwein \r\n\r\nhonestly I find this:\r\n\r\n> CSPs submit a structured scan summary (JSON) derived from their internal tools\r\n\r\nharder than this:\r\n\r\n> Requiring raw scan outputs (e.g., Tenable .nessus, Qualys .xml) \r\n\r\nsince I get those exports (and APIs) \"out of the box\". But either way doesn't really matter what format it produces.\r\n\r\nWhat is burdensome is then taking all my nice API generated files and having to manually login to Connect and upload to circa 1990 UI and upload one at a time waiting 5 seconds each time and the page refresh :)\r\n\r\nso .... can't we just have an API endpoint where I can automatically pipeline these (signed, hashed, blockchained, etc) up to the Agency or Connect or the Den of the Secret 9?",
          "author": "sunstonesecure-robert",
          "created_at": "2025-04-12T00:10:11Z"
        },
        {
          "id": "DC_kwDOOK0ax84Aw3VI",
          "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12809544",
          "body": "@sunstonesecure-robert - In theory maybe, but in practice, the problem isn\u2019t generating the JSON, it\u2019s agreeing on the schema, field mappings, and the normalization process across tools like Tenable, Qualys, Prisma, Inspector, etc. Every CSP implements things slightly differently (some even across internal orgs), and raw data dumps are only easier because no one has to agree on what they mean.\n\n\u201cCan\u2019t we just push it all through an API?\u201d\n\nWe should have APIs for scan ingestion, but we also need:\n- A normalized structure (OSCAL validation schema helps, but doesn\u2019t solve everything),\n- A trust framework (signature chaining/blockchain sounds nice but isn\u2019t being used by most CSPs),\n- And a governance layer to track scan frequency, scope, false positives, suppression justifications, etc.\n\nAlso worth flagging: Just because OSCAL has an inventory model doesn\u2019t mean it\u2019s being used effectively today. Too many SSPs list what the SSP writer thinks the inventory should be, not what\u2019s live in the environment. If we want real-time inventory assurance, we need CSPs pushing live telemetry into validated inventory sources.\n\nTL;DR \u2014 Agree with the spirit of automation. But getting this right means more structure, not just less friction. Happy to collaborate on a test schema + ingestion model if others are game.",
          "author": "rgutwein",
          "created_at": "2025-04-12T00:24:04Z"
        },
        {
          "id": "DC_kwDOOK0ax84AxDFk",
          "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12857700",
          "body": "@rgutwein thanks for calling out the need for ACTUAL code vs theoretical code - LOC speak louder than Jira cards :)\r\n\r\nSo in the 5 minutes I was waiting for the WG call to start today ... I created 2 example ACME vuln files (attached) \r\n[tenable_acme.csv](https://github.com/user-attachments/files/19781439/tenable_acme.csv)\r\n[qualys_acme.csv](https://github.com/user-attachments/files/19781440/qualys_acme.csv)\r\nusing the CSV cols from a Qualys and Tenable export. I ran it through LLM to [generate this Colab notebook.](https://colab.research.google.com/gist/sunstonesecure-robert/5c82114aef285fd2627b9682219ced6e/vulns-2-oscal-ar.ipynb)  I did *not* in this 5 minutes test if it is valid OSCAL, correlate it to the inventory model, run NIST validations, etc etc. - but - I hope you would agree - we HAVE a standard format in OSCAL. We can perefect it over time, but we have a way to do all the things you note that are very important, I agree. \r\n\r\nSend me some CVS cols for these other tools and I'll add that code, too!! Come to the CNCF Compliance WG and load us up with feature requests and use cases and we can live code together!\r\n\r\nFree open source code - that's the solution. But DO keep challenging and asking for proof via code. We can do this!!",
          "author": "sunstonesecure-robert",
          "created_at": "2025-04-16T17:07:12Z"
        }
      ]
    },
    {
      "id": "DC_kwDOOK0ax84Awal_",
      "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12691839",
      "body": "Copying here for viz...  hey @rgutwein and community team ,  I think there is interest in forming a community around an open source implementation.   The challenge will be to find people who can dedicate time after work or whose company would allow for contribution as part of their job.   I work full time for a CSP on the FedRAMP path, but would love to help as I can after-hours.   In order to take an incremental approach, I outlined a [possible first incremental step](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/17) towards a more comprehensive solution as you outlined above in separate thread with a focus just on inventory",
      "author": "cybersechawk",
      "created_at": "2025-04-01T18:03:36Z",
      "replies": [
        {
          "id": "DC_kwDOOK0ax84AxDFt",
          "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12857709",
          "body": "I agree. That said we do have a WG @ CNCF for this exact sort of thing - but - I totally understand if folks want a more FedRAMP \"branded\" WG. Happy to help!",
          "author": "sunstonesecure-robert",
          "created_at": "2025-04-16T17:08:53Z"
        }
      ]
    },
    {
      "id": "DC_kwDOOK0ax84Awegl",
      "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12707877",
      "body": "@rgutwein @tashiscool @shr0p @kkettner @sunstonesecure-robert @cybersechawk  \r\n\r\n\r\n#### **1. Defining Standard Deliverables with OSCAL and JSON Templates**  \r\n\r\n- **Adopt OSCAL for ConMon Artifacts:** Utilize OSCAL's existing schema for POA&M and assessment artifacts, but extend it with custom schemas for inventory and scan summaries.  \r\n- **Standard JSON Schemas for Scan Summaries:** Develop clear, structured schemas that include essential metadata:  \r\n  - **Scanner Type and Version:** (e.g., Tenable, Trivy, AWS Inspector)  \r\n  - **Asset Identifiers:** IP addresses, container IDs, VM names, etc.  \r\n  - **Severity Levels:** Categorized into Critical, High, Medium, Low  \r\n  - **CVE IDs:** A list of identified vulnerabilities  \r\n  - **Scan Timestamp:** The exact date and time of the scan  \r\n  - **Cryptographic Hashes:** To provide traceability to raw data if necessary.  \r\n\r\n---\r\n\r\n#### **2. Leveraging Cryptographic Hashing for Traceability**  \r\n\r\n- **Signed Scan Summaries:** By including cryptographic hashes of raw scan files in structured reports, CSPs can provide evidence of integrity without requiring the submission of raw data.  \r\n- **Spot-Check Capability:** Agencies can request raw scan files if necessary, but only in cases where further scrutiny is required.  \r\n\r\n---\r\n\r\n#### **3. API-Driven Reporting Framework**  \r\n\r\n- **Standardized API Specifications:** Define REST API standards for agencies to consume ConMon reports. This could be based on OpenAPI specifications, ensuring consistent integration across different CSPs.  \r\n- **OSCAL and JSON Report Submission:** Allow submission of ConMon artifacts via API endpoints to eliminate manual uploads and improve consistency.  \r\n\r\n---\r\n\r\n#### **4. Simplifying Compliance for CSPs**  \r\n\r\n- **Reference Implementations:** Provide sample GitHub Actions/GitLab CI pipelines that demonstrate:  \r\n  - Automated scan execution  \r\n  - Conversion of raw data to standardized JSON/OSCAL reports  \r\n  - Publishing reports securely (e.g., signed S3 URLs)  \r\n- **Visualization Dashboards:** Create reference templates for visualization using Grafana, Looker Studio, or other platforms to enable agencies to easily consume reports.  \r\n\r\n---\r\n\r\n#### **5. Extending OSCAL to Cover Inventory and Scan Summaries**  \r\n\r\n- While OSCAL currently supports POA&M and assessment artifacts, we need a formal schema for inventory and scan summaries.  \r\n- Propose adding new elements to OSCAL for:  \r\n  - **Inventory Artifacts:** Providing structured descriptions of assets and their configurations.  \r\n  - **Vulnerability Summaries:** Aggregated findings from various scanning tools.  \r\n  - **Control Mappings:** Linking findings directly to applicable NIST 800-53 controls.  \r\n\r\n---\r\n\r\n#### **6. Incremental Approach Towards Standardization**  \r\n\r\n- Start by formalizing the JSON schema for scan summaries.  \r\n- Define minimum metadata requirements for ConMon submissions.  \r\n- Allow CSPs to adopt this approach incrementally, providing flexibility to integrate with their existing tooling.  ",
      "author": "austinsonger",
      "created_at": "2025-04-03T01:37:18Z",
      "replies": [
        {
          "id": "DC_kwDOOK0ax84AwpX5",
          "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12752377",
          "body": "@austinsonger I think a great approach would be to \"unlock\" the SSP model, so that the top level elements become optional.  This would meet your point 5 and 6 very nicely without the added burden of creating new standards, since the standards already exist in OSCAL, and can be met.  Dont forget OSCAL does support a json structure.  \r\n\r\nThe SSP model already has an inventory, and detailed component layer.  The POAM model aloows for vulnearbility summaries, and control mapping. \r\nLeveraging them together allows us to associated the vulnerabilities back to their details in the SSP, making for a robust reporting mechanism that crosses the different models.  \r\nIf you check out my comment under [Assessing Monitoring Over Time (KSI Approach)](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/12#discussioncomment-12690088) I provide a detailed breakdown of the structure for inventory reporting, taking into account how we can report on components as well.  \r\n\r\nAlternatives to OSCAL, or a candidate for translation to standardized OSCAL, would be the XCCDF format.  This is what STIGs are already in, so it makes sense if we can communicate in OSCAL and XCCDF already, and various scanners already support the XCCDF export.  The challenge here would be maintaining the repository of CCI's from DISA to be able to accurately measure control compliance at the Assessment objective.  ",
          "author": "Telos-sa",
          "created_at": "2025-04-07T14:42:27Z"
        },
        {
          "id": "DC_kwDOOK0ax84Awpnm",
          "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12753382",
          "body": "> Alternatives to OSCAL, or a candidate for translation to standardized OSCAL, would be the XCCDF format. This is what STIGs are already in, so it makes sense if we can communicate in OSCAL and XCCDF already, and various scanners already support the XCCDF export. The challenge here would be maintaining the repository of CCI's from DISA to be able to accurately measure control compliance at the Assessment objective.\r\n\r\nHave you seen sustained or increased adoption of XCCDF and use of the SCAP standards in cloud-native deployments? How do you see it working more comprehensively for cloud-native services? Most all of DoD-made XCCDF checklists around operating systems and sometimes dedicated OSes for network equipment (I think some OCI container orchestrators and some flavors of Kubernetes are the outlier). Do you know of others not maintained by DISA in XCCDF format for DoD? [The cloud security list on cyber.mil](https://public.cyber.mil/stigs/downloads/?_dl_facet_stigs=cloud-security-stigs) is very short.\r\n\r\nI ask because it appears SCAP has fizzled out, aside from sustained use by the core DoD groups, SCAP 1.3 never materialized, and there are now many proprietary and commercial tools, along with different formats, that have spread across the cloud security space. I am really curious how you see the landscape, and if you see it differently.\r\n",
          "author": "aj-stein-gsa",
          "created_at": "2025-04-07T16:06:24Z"
        },
        {
          "id": "DC_kwDOOK0ax84AwpuV",
          "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12753813",
          "body": "From what I\u2019ve seen, many CSPs and container publishers (like Iron Bank) still leverage OpenSCAP directly in their CI/CD pipelines to generate XCCDF and ARF outputs for container-based images. For example, Iron Bank documents how to locally scan containers using OpenSCAP here: [Iron Bank OpenSCAP Testing Guide](https://docs-ironbank.dso.mil/tutorials/local-openscap-testing/). This is commonly used to ensure STIG alignment early in the pipeline before promotion.\r\n\r\nAt the OS level, Amazon, for example provides STIG-hardened AMIs that are validated using SCAP-based tooling, including XCCDF benchmarks. These AMIs are particularly useful for customers in regulated environments who need DISA-compliant baselines out of the box. So while SCAP tooling itself may not be visible at the higher abstraction layers (like Kubernetes), it\u2019s still quite active at the image and instance level.\r\n\r\nThat said, you\u2019re right that the broader tooling ecosystem has evolved, we\u2019re now seeing more policy-as-code implementations (e.g., OPA, InSpec) and compliance reporting frameworks (like OSCAL) gaining traction. SCAP 1.3 never quite got the lift-off needed, and many vendors are focusing on CNAPP and SBOM-native approaches instead.\r\n\r\nThe challenge remains: DISA\u2019s XCCDF checklist coverage is still largely OS- and device-focused. There\u2019s a real opportunity for the community to create more cloud-native XCCDF content, maybe even a GitHub-driven model similar to what Red Hat does with [ComplianceAsCode](https://github.com/ComplianceAsCode/content).",
          "author": "rgutwein",
          "created_at": "2025-04-07T16:43:23Z"
        },
        {
          "id": "DC_kwDOOK0ax84Awqb_",
          "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12756735",
          "body": "> [ComplianceAsCode](https://github.com/ComplianceAsCode/content).\r\n\r\nwhich is also OSCAL integrated!",
          "author": "sunstonesecure-robert",
          "created_at": "2025-04-07T21:53:54Z"
        }
      ]
    },
    {
      "id": "DC_kwDOOK0ax84AwgAE",
      "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12713988",
      "body": "ConMon should be just that, Continuous Monitoring. We need to get away from generating monthly reports and enable dynamic retrieval of the current security posture of the system. OSCAL should be used but not as a reporting format. Instead, OSCAL should provide Monitoring Status as Code enabling authorized personnel to retrieve the current status on-demand. This should be status, metrics, KPIs and not the details behind that status.\r\n\r\nFor example, does an Agency really need to see the full inventory of a system? Would they know what they are looking at if they did have that, I suggest not. Instead an Agency needs to know that the CSP has control of their inventory, that the CSP detects new inventory and validates it is approved per change control or not approved and thereby removed. The Agency just needs to see the metrics on how the CSP is performing with relation to managing their inventory.",
      "author": "dljenkins",
      "created_at": "2025-04-03T13:34:20Z",
      "replies": [
        {
          "id": "DC_kwDOOK0ax84AwgLH",
          "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12714695",
          "body": "Thanks for the response @dljenkins - I agree that the future of ConMon should support dynamic, on-demand retrieval of security posture \u2014 moving away from static monthly reporting. That said, most agencies today still rely on well-defined ConMon Plans that call for regular reporting of specific metrics, many of which are sourced from:\r\n\r\n- **SIEMs/log event tools** for control activity verification (e.g., AC, AU, IR),\r\n- **Vulnerability scanners** for counts by severity across OS, containers, DBs, and web apps,\r\n- **Manual assessments** identifying control deficiencies,\r\n- **POA&M tracking tools** (often manually maintained or exported from GRC platforms).\r\n\r\nMy intent behind suggesting JSON and OSCAL-based standardization is to structure these common, recurring data points in a machine-readable way \u2014 not to create an entirely new reporting burden. Ideally, it sets the stage for:\r\n\r\n- Monitoring as Code, as you mentioned, where authorized stakeholders can retrieve posture data (e.g., open POA&Ms, patch velocity, SBOM drift) through a simple API,\r\n- More automated and real-time ingestion into agency dashboards and compliance tooling,\r\n- Reduced manual friction for both CSPs and agencies through standardized templates and report stubs (e.g., OSCAL `AssessmentResults`).\r\n\r\nWould love to explore how we can merge these ideas, dynamic status retrieval *and* a practical path forward for CSPs and agencies still operating under legacy ConMon Plans.\r\n\r\n",
          "author": "rgutwein",
          "created_at": "2025-04-03T14:36:49Z"
        },
        {
          "id": "DC_kwDOOK0ax84Awhnu",
          "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12720622",
          "body": "> nd. This should be status, metrics, KPIs and not the details behind that status.\r\n\r\nI worked for the Navy before as well as the Veteran Affairs. And if its not documented then it doesn't exist or it never happened. So getting away from providing a full inventory probably will not happen.",
          "author": "austinsonger",
          "created_at": "2025-04-04T02:56:26Z"
        },
        {
          "id": "DC_kwDOOK0ax84Awit-",
          "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12725118",
          "body": "The details can be made available for sure, but the on-demand status should be focused on metrics & KPIs. It's certainly not about hiding anything from the client. It's more about making it readily and dynamically available with layers of information. If clients see the metrics & KPIs, have the ability to view the details behind it, then eventually they learn to trust the metrics & KPIs and only occasionally check the details. I don't believe every client is reviewing every single inventory item every month. I suspect there maybe a few, but mostly not.",
          "author": "dljenkins",
          "created_at": "2025-04-04T11:29:45Z"
        },
        {
          "id": "DC_kwDOOK0ax84Awiva",
          "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12725210",
          "body": "Appreciate both of your perspectives here, and I agree that metrics and KPIs are the ideal interface for executive stakeholders. But from a FedRAMP compliance and ConMon standpoint, **providing a monthly integrated inventory is a required deliverable**, and it\u2019s not just a formality.\n\nAgencies *do* analyze and examine inventory data \u2014 especially to:\n- Confirm coverage of vulnerability scans,\n- Validate changes in system boundary or component composition,\n- Track asset lifecycle, ownership, or categorization for impact levels,\n- Correlate assets to POA&Ms or scan findings.\n\nThe good news is: **this doesn\u2019t have to be manual or static anymore**. Inventories can (and should) be generated automatically using:\n- AWS Config / Azure Resource Graph / GCP Asset Inventory,\n- CSPM tools like Prisma, Wiz, or Defender for Cloud,\n- Export APIs from CMDBs or agent-based inventory systems.\n\nWe\u2019re trying to move *away* from uploading spreadsheets to email or eMASS/OMB MAX, etc and instead toward **real-time API exposure of current inventory**, with metrics + metadata at the top layer, and full detail retrievable via drill-down.\n\nThis creates an elegant structure:\n- **Metrics/KPIs at the top** (e.g., inventory drift, asset count, asset types added/removed),\n- **Linked detail beneath** for anyone who needs to dive deeper.\n\nThanks again \u2014 I think we\u2019re all aiming for the same outcome: actionable, trustworthy reporting with automation and layered insight.",
          "author": "rgutwein",
          "created_at": "2025-04-04T11:37:22Z"
        },
        {
          "id": "DC_kwDOOK0ax84Awqce",
          "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/10#discussioncomment-12756766",
          "body": "> Agencies do analyze and examine inventory data\r\n\r\nI agree - but this is a pro and a con.  Pros: \r\n\r\nCSPs are very sloppy and hand wavy about what a control does. 3PAOs often accept 1 example and ignore the 100 other corner cases.  Not having a check for each and every resource in scope means *something* is not compliant.  And it's not because CSPs don't care - often even with automation, changes come so fast and furious it's impossible for any human team to keep up.  \r\n\r\nCons:\r\n\r\nBasing *any* review on a static point in time inventory that is already obsolete by the time it's produced is a poor substitute for having automated checks that systematically read in from pipelines or APIs the full inventory and runs tests against each and every resource in boundary.  In modern micro-service CSOs the inventory changes multiple times per day.  The bad guys aren't going to rely on a spreadsheet - they are going to phish your admins, get real-time API intel on what you have in boundary and kick butt and chew bubble gum. Why wouldn't we do the same on the defensive side?",
          "author": "sunstonesecure-robert",
          "created_at": "2025-04-07T22:00:09Z"
        }
      ]
    }
  ]
}