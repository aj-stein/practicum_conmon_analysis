# Metadata

title:What, specifically, is in scope for component inventory, and what is the intended mechanism to validate against actual state?

author: [github.com/atfurman](https://github.com/atfurman)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/15](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/15)

created: 2025-03-31T19:14:48Z

id: D_kwDOOK0ax84AfF_R



# Post

# Overview

The draft guidance in https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/blob/main/conmon_ksi_report.md#inventory-data states:
```
Inventory entries reflect each component within the authorization boundary, encompassing the data plane, management plane, and control plane. 
```

This is a grand assertion, but does not accurately describe the FedRAMP inventory as I have experienced it during my career thus far. 

# The Perceived Problems
## Problem 1
The draft guidance does not address _what actually is in scope for inventory_.

Traditionally this has been considered to be VMs (e.g. GCP compute instances, AWS EC2 instances, etc), managed databases (AWS RDS, GCP Cloud SQL, etc), persistent object stores (S3 and GCS buckets, etc). Based on my experience, this may or may not include components such as managed load balancers, managed filestores, or other infrastructure components.

However, this view is somewhat myopic, as modern systems include many components which appear to be blind spots from the perspective of the system inventory as it stands today, and the inventory does not really appear to handle ephemeral resources well at all.

For example, the current inventory does not include serverless compute such as lambda functions or cloud functions- we have included them in the past and were directly instructed to remove them as not relevant, despite the fact that many systems utilize serverless compute, and some utilize little _but_ serverless compute. We viewed this at the time as an astonishingly bad call, and still view it as such, but a directive is a directive.

It appears at current time that substantially more robust guidance regarding what specific resource types need to be reflected within the inventory is required, and serious reconsideration may need to be given to what is considered to be a valid identifier for each type. For example, using an IP address as an identifier is not particularly useful if one is scanning container hosts or VMs in an ASG- VM lifetimes may be measured in minutes to hours instead of days, weeks, or months. 

## Problem 2
Assuming problem 1 gets addressed and consistently structured and identified inventories can be generated for arbitrary systems hosted in AWS, Azure, or GCP, there is still a considerable (I'd possibly even say fundamental) problem- what confidence level is there that the inventory _actually reflects system state_?

How can a ConMon reviewer have a reasonable level of confidence that the state of the system as reported by the inventory is actually accurate? 

While there are scans, the general implementation of scans is `Authenticated scanning for monthly continuous monitoring should consists of targeted scans rather than simply directing a scan tool at subnets`. In many cases agent based scans will be used instead of direct authentication. 

Regardless of whether direct authentication or agent based scans are used. How does one have a sufficient degree of confidence that all resources which should have been scanned by a given scan were, in fact, scanned? 

Or to put it another way, _what confidence can a reviewer have that there is not an arbitrary set of resources which are not reflected on scans **and** not reflected on the inventory_?

In fact, if KSIs are being used to score systems, there is what I view as a perverse incentive to keep the population of scanned and inventoried resources as small as possible, which runs directly counter to the intentions of this approach as I understand them. 

# Context

These aren't new problems, but I believe that the push to standardize and automate ConMon throws them into sharp contrast, and I am not really sure that this approach can work without controlling for them.

# Proposal
I believe that a serious reconsideration of the inventory is in order. From my perspective, an inventory which cannot be validated to accurately represent system state **as it is** cannot be used to meaningfully assess system risk, and is of limited usefulness when comparing against scans.

The inventory needs to accurately reflect system infrastructure state.
There are means to accomplish this in a relatively direct fashion- tools such as [steampipe](https://steampipe.io/) are useful abstractions on cloud infrastructure, and allow inventories to be expressed as sets of queries targeted at specific resource types. An example query for dynamoDB which we use to generate data for inventory records:

```sql
select 
    arn as inv_asset_id,
    'TRUE' as inv_is_virtual,
    'Internally authenticated access only' as inv_is_public,
    'AWS' as inv_software_database_vendor,
    'DynamoDB' as inv_software_database_version,
    'No - Inherited from AWS' as inv_in_latest_scan,
    case
      when tags['DiagramLabel'] is not null then tags['DiagramLabel']
      else '"DynamoDB"'
    end as inv_diagram_label,
    tags['InformationImpactLevel'] as inv_comments,
    tags['SystemAdministrator'] as inv_system_administrator,
    tags['Function'] as inv_function,
    tags['EndOfLife'] as inv_end_of_life,
    'securityhub' as inv_scanner
from aws_dynamodb_table;
```

To trust the answer to the above query however one must first ask additional questions:

1. What AWS accounts am I querying against? (same general logic applies for GCP projects/Azure subscriptions)
2. Did I have sufficient permissions to query against each account?
3. Are the accounts I am querying against the full set of accounts for the system?

If we can prove the answer to 1 and answer `yes` to questions 2 and 3, then I believe we can assert with a sufficient degree of confidence that we are accurately representing **this specific resource type** in the system inventory. 

If we then skip forward a few (hundred) steps and specify the following, I think that we could have a relatively sound foundation upon which to build the inventory and meaningfully compare against scan results:
1. What cloud resources types should be considered in scope for each of the major clouds
2. The rules for uniquely identifying them
3. The metadata to collect, how to represent in inventory, and how to reconcile with different scan types (this will vary by resource type and scanner/scanner config)





# Comments




## Comment 1

author: [github.com/austinsonger](https://github.com/austinsonger)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/15#discussioncomment-12707935](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/15#discussioncomment-12707935)

created: 2025-04-03T01:45:45Z

id: DC_kwDOOK0ax84Awehf

@atfurman

### **Response: What, specifically, is in scope for component inventory, and what is the intended mechanism to validate against actual state?**

You’ve raised some critical points that highlight the need for clarity and consistency in inventory reporting. I’d like to build upon your observations and propose a framework for defining scope, validating inventories, and ensuring consistency across scans and reports.

Additionally, I have been developing an open-source project called [**RampScout**](https://github.com/Elevated-Standards/RampScout), which aims to provide a standardized, automated, and scalable solution for inventory collection, validation, and reporting across multi-cloud environments. This tool can be directly applied to the problems you've identified.

---

#### **1. Defining Scope: What Should Be Included in Inventory?**
The current guidance lacks specificity on which resources must be inventoried, which results in inconsistent reporting and scanning coverage. I propose the following categories for inclusion:  

##### **Core Categories for Inventory Reporting:**  
1. **Compute Resources:**  
   - VMs (EC2, GCP Compute Instances, Azure VMs)  
   - Containers (Kubernetes Pods, ECS Tasks, Azure Containers)  
   - Serverless Compute (AWS Lambda, Azure Functions, GCP Cloud Functions) - *Should be included, especially when they are integral to CSPs' operational architecture.*  
   - Autoscaling Groups - Track the instance IDs within these groups.  

2. **Data Storage & Management:**  
   - Persistent Object Stores (S3, GCS, Azure Blob Storage)  
   - Managed Databases (RDS, Cloud SQL, Azure SQL)  
   - Caches (Elasticache, Redis, Memcached)  
   - Data Pipelines (AWS Glue, GCP Dataflow, Azure Data Factory)  

3. **Network Infrastructure:**  
   - Load Balancers (ALBs, NLBs, GCP LBs)  
   - API Gateways (AWS API Gateway, Azure API Management, GCP API Gateway)  
   - VPCs, Subnets, Security Groups, Network ACLs  

4. **Infrastructure as Code (IaC) Components:**  
   - Terraform, CloudFormation, ARM Templates - These define infrastructure state and can be used to validate what exists vs. what is intended to exist.  

5. **Control Plane Resources:**  
   - Identity Providers, Authentication Configurations (e.g., AWS IAM, Azure AD)  
   - Service Meshes (Istio, AWS App Mesh)  
   - CI/CD Pipelines - To validate deployments and code integration practices.  

---

#### **2. Mechanism for Validating Against Actual State**
Achieving high confidence in inventory accuracy requires ensuring that all resources intended to be scanned are captured within the inventory. I propose a multi-step approach:  

##### **a. Automated Inventory Generation**  
- Utilize tools like Steampipe, AWS Config, Azure Resource Graph, and GCP Asset Inventory to generate inventories programmatically.  
- Enforce metadata tagging policies (e.g., `Inventory: True`) to mark resources intended for inventory.  
- Leverage IaC definitions to ensure infrastructure matches the intended state.  

My project, [**RampScout**](https://github.com/Elevated-Standards/RampScout), is designed to automate inventory generation by querying cloud APIs and validating resource states across AWS, Azure, and GCP. It aims to standardize inventory collection through predefined templates and schemas, providing a consistent, auditable source of truth.

##### **b. Validation through Continuous Monitoring APIs**  
- Provide CSPs with a structured API endpoint (e.g., `/inventory/validate`) to expose real-time inventory data.  
- Require CSPs to submit inventory signatures (hashes) along with reports to validate accuracy.  

##### **c. Reconciliation Against Scan Data**  
- Compare inventory data against scan outputs. Identify gaps where resources are missing from scans or scans are incomplete.  
- Implement rules for reconciliation:  
  - **“Present in Inventory but Missing in Scans”** – Trigger alerts and require investigation.  
  - **“Present in Scans but Missing in Inventory”** – Potentially unauthorized resources requiring immediate attention.  

---

#### **3. Mechanism for Establishing Confidence in Inventory Accuracy**
FedRAMP's approach to ConMon needs to directly address how confidence is established. I propose the following framework:  

##### **a. Inventory Validation Schema (IVS)**  
- Define a JSON/OSCAL schema for inventory submissions that includes:  
  - **Resource Type** (e.g., VM, Lambda Function, Container)  
  - **Unique Identifier** (ARN, Instance ID, etc.)  
  - **Metadata Tags** (e.g., Project, Owner, Environment, Criticality)  
  - **Source of Truth** (IaC, API Query, Manual Entry)  

##### **b. Multi-Cloud Inventory Reconciliation**  
- Establish guidelines for inventorying resources across AWS, Azure, GCP, and other platforms.  
- Require CSPs to provide proof of completeness by generating inventory records for each account, subscription, or project.  

##### **c. Periodic Revalidation**  
- Implement periodic revalidation checks to ensure that CSPs are maintaining accurate inventory.  
- These checks can be automated via API calls or batch submissions, but should be verifiable against raw scan outputs when required.  

---

#### **4. Avoiding Perverse Incentives**
You raise a valid point about the risk of CSPs underreporting resources to maintain higher Key Security Indicator (KSI) scores. To address this:  

- **Standardized Definitions:** Clearly define which resources must be included in the inventory.  
- **Cross-Referencing:** Require inventories to be validated against independent sources (e.g., CloudTrail logs, Azure Monitor logs).  
- **Incentivize Accuracy:** Provide positive scoring for complete inventories and transparent reporting rather than focusing only on vulnerability counts.  

---

#### **5. Recommendations**
- **Create a Consistent Inventory Framework:** Adopt a standardized approach for inventory generation and submission across CSPs.  
- **Enable API-Based Validations:** Ensure CSPs can expose real-time inventory data through structured APIs.  
- **Establish Cross-Cloud Standards:** Define rules for inventorying resources across all major cloud providers.  
- **Incorporate IaC Definitions:** Treat IaC files as an authoritative source of truth for inventory validation.  
- **Integrate Open-Source Tools:** Continue enhancing projects like [**RampScout**](https://github.com/Elevated-Standards/RampScout) to provide streamlined, automated, and auditable inventory generation and validation.  

### Replies



#### Reply 1

author: [github.com/kamamanh](https://github.com/kamamanh)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/15#discussioncomment-12768363](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/15#discussioncomment-12768363)

created: 2025-04-08T17:57:43Z

id: DC_kwDOOK0ax84AwtRr

A small point, I think the Data Storage & Management section should also include inventory of non-managed databases. While the managed DBs are the likely the vast majority, the current listing leaves space for me to build a DB-on-a-VM and not mention the DB itself as an inventory component.



## Comment 2

author: [github.com/sam-aydlette](https://github.com/sam-aydlette)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/15#discussioncomment-12769557](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/15#discussioncomment-12769557)

created: 2025-04-08T19:51:32Z

id: DC_kwDOOK0ax84AwtkV

 > To trust the answer to the above query however one must first ask additional questions:
> 
> 1. What AWS accounts am I querying against? (same general logic applies for GCP projects/Azure subscriptions)
> 2. Did I have sufficient permissions to query against each account?
> 3. Are the accounts I am querying against the full set of accounts for the system?
> 
> If we can prove the answer to 1 and answer `yes` to questions 2 and 3, then I believe we can assert with a sufficient degree of confidence that we are accurately representing **this specific resource type** in the system inventory.
> 
> If we then skip forward a few (hundred) steps and specify the following, I think that we could have a relatively sound foundation upon which to build the inventory and meaningfully compare against scan results:
> 
> 1. What cloud resources types should be considered in scope for each of the major clouds
> 2. The rules for uniquely identifying them
> 3. The metadata to collect, how to represent in inventory, and how to reconcile with different scan types (this will vary by resource type and scanner/scanner config)

@atfurman or others what overall approach do you think would be most effective in defining inventory scope? Examples:
1. First principles approach, i.e., "components storing or transmitting federal data, or components with privileged access into those components." Something like this is straightforward, but subject to interpretation, which gets very squishy.
2. Use case examples approach, i.e., "this stack is built in AWS/Azure/GCP using these services and these third party tools configured like this." This is very concrete, but limited because it would be impossible to cover every use case.
3. Data-centric approach, i.e., "these types of metadata are considered sensitive, and any components storing or processing them must be tracked as inventory components." This gets challenging because metadata is very context specific. Are helm charts inherently "in the boundary" because they store metadata policy? The scope can sprawl to ridiculous proportions and a lot of metadata can be sussed out via OSINT methods pretty easily.

Are there any other approaches that might work better, or tweaks to the above approaches that may make them more effective?

EDIT: I want to address your specific comments to add context to my question. 

> Based on my experience, this may or may not include components such as managed load balancers, managed filestores, or other infrastructure components.

...

> the current inventory does not include serverless compute such as lambda functions or cloud functions- we have included them in the past and were directly instructed to remove them as not relevant, despite the fact that many systems utilize serverless compute, and some utilize little but serverless compute. We viewed this at the time as an astonishingly bad call, and still view it as such, but a directive is a directive.

and also ...

> While there are scans, the general implementation of scans is Authenticated scanning for monthly continuous monitoring should consists of targeted scans rather than simply directing a scan tool at subnets. In many cases agent based scans will be used instead of direct authentication.

First off, thank you for sharing your experiences candidly. To your point, I wanted to note that the [Vulnerability Scanning KBA](https://help.fedramp.gov/hc/en-us/articles/29975368259867-Vulnerability-Scanning), while solely a set of best practices and not explicit requirements, specifically advocates for the inclusion of network components, web interfaces, etc. So I am surprised to hear that you received the guidance to exclude networking and serverless compute resources from the inventory. The KBA also specifically recommends performing discovery scans on entire subnet ranges on top of agent-based or targeted scans as a best practice. 

Based on that context, what do you (or others) think is the best way to go about defining inventory requirements in such a way that it ensures the full scope of what *ought* to be in the inventory without being too broad or narrow. 

FWIW, your recommendations on core "types" of inventory components is noted, and thank you for that first pass, very interesting!




### Replies



#### Reply 1

author: [github.com/atfurman](https://github.com/atfurman)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/15#discussioncomment-12770163](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/15#discussioncomment-12770163)

created: 2025-04-08T21:05:54Z

id: DC_kwDOOK0ax84Awttz

If asked to sketch out a solution right now, I'd begin with what I view as the largest and most achievable parts: what I'll call for the sake of convenience the `infrastructure inventory`. 

BLUF: **The things we want to know about and what specifically we want to know about them should be source controlled and unambiguous.** 

1. For each of the major clouds (AWS, Azure, GCP, maybe Oracle), define the scope for the inventory. For example, if an `AWS account|GCP Project|Azure Subscription|OCI Tenant` hosts any functional component of  the system, then it is considered in scope. This scope is the answer to `Are the accounts I am querying against the full set of accounts for the system?` and should be relatively easy for a human to validate as frequently as required.
2. For each of the major clouds, explicitly and unambiguously define the resource types that **must be inventoried**. For example, you MUST inventory all EC2 instances, S3 buckets, Lambda functions, RDS, DynamoDB tables, ALBs, NLBs, EFS file systems, ECR repositires, etc etc. This is going to be more complex than it initially might sound as A) there are a lot of different resource types and B) the ways in which they contribute to the systems function and store, process or transmit data vary widely. 
3. For each resource type, explicitly define the attributes which must be queried. I'd express these as collections of steampipe queries, as that is the most concise, usable, maintainable, and understandable way I'm aware of to ask these questions. I'll freely admit to being a little biased here; as we have already gone some ways down this path. For instance, what do we want to know about an AWS Network Load balancer? I think the answer looks something vaguely like this:
```sql
select
    arn as inv_asset_id,
    'TRUE' as inv_is_virtual,
    scheme as inv_is_public,
    dns_name as inv_dns_name,
    tags['Function'] as inv_asset_type_and_function,
    'AWS NLB' as inv_hardware_make_model,
    'No - Inherited from AWS' as inv_in_latest_scan,
    case
      when tags['DiagramLabel'] is not null then tags['DiagramLabel']
      else '"NLB"'
    end as inv_diagram_label,
    vpc_id as inv_network_id,
    tags['SystemAdministrator'] as system_administrator,
    tags['Function'] as inv_function,
    tags['EndOfLife'] as inv_end_of_life,
    'securityhub' as inv_scanner
from 
    aws_ec2_network_load_balancer;
```
Note that this example is heavily bound by the conventions of the current FedRAMP inventory; if asked to write this from first principles, I'd probably be structuring it a bit differently, but the overall approach would be the same. 
4. Raw infrastructure inventory would thus be expressed as a query set to be run against infrastructure:
![image](https://github.com/user-attachments/assets/463fd867-21f6-4c5a-8de9-66af087c2de4)
Every CSP runs the same query set and expresses the output as JSON. The CSP is responsible for ensuring that appropriate least privilege permissions are in place to facilitate this, and for ensuring that the entire scope is queried. 

This is only part of a solution, as it wouldn't address:
- OS/Software (that is an entire topic unto itself, possibly better approached from the scanner side), 
- Container image (I don't think based on my experience that one can safely assume that the image repositories within the boundary give a full picture of what can run or is running)
- External services/ SaaS representation (but that isn't consistently addressed anyway; this approach could be extended to encompass at least some of these cases; [steampipe plugins are many and varied](https://hub.steampipe.io/?q=turbot))

However, it would provide a consistently defined, testable, repeatable baseline for CSP inventory reporting, and something of a foundation to build upon. 

I think it would be better than what we currently have, at least, and should be sufficiently complete & correct with respect to actual state that associated KSIs could be meaningful. 




#### Reply 2

author: [github.com/sam-aydlette](https://github.com/sam-aydlette)

url: [https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/15#discussioncomment-12778345](https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/15#discussioncomment-12778345)

created: 2025-04-09T13:12:15Z

id: DC_kwDOOK0ax84Awvtp

Thanks @atfurman for your detailed and thoughtful answer!

