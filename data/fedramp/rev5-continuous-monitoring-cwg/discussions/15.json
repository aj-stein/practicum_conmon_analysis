{
  "id": "D_kwDOOK0ax84AfF_R",
  "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/15",
  "title": "What, specifically, is in scope for component inventory, and what is the intended mechanism to validate against actual state?",
  "body": "# Overview\r\n\r\nThe draft guidance in https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/blob/main/conmon_ksi_report.md#inventory-data states:\r\n```\r\nInventory entries reflect each component within the authorization boundary, encompassing the data plane, management plane, and control plane. \r\n```\r\n\r\nThis is a grand assertion, but does not accurately describe the FedRAMP inventory as I have experienced it during my career thus far. \r\n\r\n# The Perceived Problems\r\n## Problem 1\r\nThe draft guidance does not address _what actually is in scope for inventory_.\r\n\r\nTraditionally this has been considered to be VMs (e.g. GCP compute instances, AWS EC2 instances, etc), managed databases (AWS RDS, GCP Cloud SQL, etc), persistent object stores (S3 and GCS buckets, etc). Based on my experience, this may or may not include components such as managed load balancers, managed filestores, or other infrastructure components.\r\n\r\nHowever, this view is somewhat myopic, as modern systems include many components which appear to be blind spots from the perspective of the system inventory as it stands today, and the inventory does not really appear to handle ephemeral resources well at all.\r\n\r\nFor example, the current inventory does not include serverless compute such as lambda functions or cloud functions- we have included them in the past and were directly instructed to remove them as not relevant, despite the fact that many systems utilize serverless compute, and some utilize little _but_ serverless compute. We viewed this at the time as an astonishingly bad call, and still view it as such, but a directive is a directive.\r\n\r\nIt appears at current time that substantially more robust guidance regarding what specific resource types need to be reflected within the inventory is required, and serious reconsideration may need to be given to what is considered to be a valid identifier for each type. For example, using an IP address as an identifier is not particularly useful if one is scanning container hosts or VMs in an ASG- VM lifetimes may be measured in minutes to hours instead of days, weeks, or months. \r\n\r\n## Problem 2\r\nAssuming problem 1 gets addressed and consistently structured and identified inventories can be generated for arbitrary systems hosted in AWS, Azure, or GCP, there is still a considerable (I'd possibly even say fundamental) problem- what confidence level is there that the inventory _actually reflects system state_?\r\n\r\nHow can a ConMon reviewer have a reasonable level of confidence that the state of the system as reported by the inventory is actually accurate? \r\n\r\nWhile there are scans, the general implementation of scans is `Authenticated scanning for monthly continuous monitoring should consists of targeted scans rather than simply directing a scan tool at subnets`. In many cases agent based scans will be used instead of direct authentication. \r\n\r\nRegardless of whether direct authentication or agent based scans are used. How does one have a sufficient degree of confidence that all resources which should have been scanned by a given scan were, in fact, scanned? \r\n\r\nOr to put it another way, _what confidence can a reviewer have that there is not an arbitrary set of resources which are not reflected on scans **and** not reflected on the inventory_?\r\n\r\nIn fact, if KSIs are being used to score systems, there is what I view as a perverse incentive to keep the population of scanned and inventoried resources as small as possible, which runs directly counter to the intentions of this approach as I understand them. \r\n\r\n# Context\r\n\r\nThese aren't new problems, but I believe that the push to standardize and automate ConMon throws them into sharp contrast, and I am not really sure that this approach can work without controlling for them.\r\n\r\n# Proposal\r\nI believe that a serious reconsideration of the inventory is in order. From my perspective, an inventory which cannot be validated to accurately represent system state **as it is** cannot be used to meaningfully assess system risk, and is of limited usefulness when comparing against scans.\r\n\r\nThe inventory needs to accurately reflect system infrastructure state.\r\nThere are means to accomplish this in a relatively direct fashion- tools such as [steampipe](https://steampipe.io/) are useful abstractions on cloud infrastructure, and allow inventories to be expressed as sets of queries targeted at specific resource types. An example query for dynamoDB which we use to generate data for inventory records:\r\n\r\n```sql\r\nselect \r\n    arn as inv_asset_id,\r\n    'TRUE' as inv_is_virtual,\r\n    'Internally authenticated access only' as inv_is_public,\r\n    'AWS' as inv_software_database_vendor,\r\n    'DynamoDB' as inv_software_database_version,\r\n    'No - Inherited from AWS' as inv_in_latest_scan,\r\n    case\r\n      when tags['DiagramLabel'] is not null then tags['DiagramLabel']\r\n      else '\"DynamoDB\"'\r\n    end as inv_diagram_label,\r\n    tags['InformationImpactLevel'] as inv_comments,\r\n    tags['SystemAdministrator'] as inv_system_administrator,\r\n    tags['Function'] as inv_function,\r\n    tags['EndOfLife'] as inv_end_of_life,\r\n    'securityhub' as inv_scanner\r\nfrom aws_dynamodb_table;\r\n```\r\n\r\nTo trust the answer to the above query however one must first ask additional questions:\r\n\r\n1. What AWS accounts am I querying against? (same general logic applies for GCP projects/Azure subscriptions)\r\n2. Did I have sufficient permissions to query against each account?\r\n3. Are the accounts I am querying against the full set of accounts for the system?\r\n\r\nIf we can prove the answer to 1 and answer `yes` to questions 2 and 3, then I believe we can assert with a sufficient degree of confidence that we are accurately representing **this specific resource type** in the system inventory. \r\n\r\nIf we then skip forward a few (hundred) steps and specify the following, I think that we could have a relatively sound foundation upon which to build the inventory and meaningfully compare against scan results:\r\n1. What cloud resources types should be considered in scope for each of the major clouds\r\n2. The rules for uniquely identifying them\r\n3. The metadata to collect, how to represent in inventory, and how to reconcile with different scan types (this will vary by resource type and scanner/scanner config)\r\n\r\n\r\n\r\n",
  "author": "atfurman",
  "created_at": "2025-03-31T19:14:48Z",
  "comments": [
    {
      "id": "DC_kwDOOK0ax84Awehf",
      "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/15#discussioncomment-12707935",
      "body": "@atfurman\r\n\r\n### **Response: What, specifically, is in scope for component inventory, and what is the intended mechanism to validate against actual state?**\r\n\r\nYou\u2019ve raised some critical points that highlight the need for clarity and consistency in inventory reporting. I\u2019d like to build upon your observations and propose a framework for defining scope, validating inventories, and ensuring consistency across scans and reports.\r\n\r\nAdditionally, I have been developing an open-source project called [**RampScout**](https://github.com/Elevated-Standards/RampScout), which aims to provide a standardized, automated, and scalable solution for inventory collection, validation, and reporting across multi-cloud environments. This tool can be directly applied to the problems you've identified.\r\n\r\n---\r\n\r\n#### **1. Defining Scope: What Should Be Included in Inventory?**\r\nThe current guidance lacks specificity on which resources must be inventoried, which results in inconsistent reporting and scanning coverage. I propose the following categories for inclusion:  \r\n\r\n##### **Core Categories for Inventory Reporting:**  \r\n1. **Compute Resources:**  \r\n   - VMs (EC2, GCP Compute Instances, Azure VMs)  \r\n   - Containers (Kubernetes Pods, ECS Tasks, Azure Containers)  \r\n   - Serverless Compute (AWS Lambda, Azure Functions, GCP Cloud Functions) - *Should be included, especially when they are integral to CSPs' operational architecture.*  \r\n   - Autoscaling Groups - Track the instance IDs within these groups.  \r\n\r\n2. **Data Storage & Management:**  \r\n   - Persistent Object Stores (S3, GCS, Azure Blob Storage)  \r\n   - Managed Databases (RDS, Cloud SQL, Azure SQL)  \r\n   - Caches (Elasticache, Redis, Memcached)  \r\n   - Data Pipelines (AWS Glue, GCP Dataflow, Azure Data Factory)  \r\n\r\n3. **Network Infrastructure:**  \r\n   - Load Balancers (ALBs, NLBs, GCP LBs)  \r\n   - API Gateways (AWS API Gateway, Azure API Management, GCP API Gateway)  \r\n   - VPCs, Subnets, Security Groups, Network ACLs  \r\n\r\n4. **Infrastructure as Code (IaC) Components:**  \r\n   - Terraform, CloudFormation, ARM Templates - These define infrastructure state and can be used to validate what exists vs. what is intended to exist.  \r\n\r\n5. **Control Plane Resources:**  \r\n   - Identity Providers, Authentication Configurations (e.g., AWS IAM, Azure AD)  \r\n   - Service Meshes (Istio, AWS App Mesh)  \r\n   - CI/CD Pipelines - To validate deployments and code integration practices.  \r\n\r\n---\r\n\r\n#### **2. Mechanism for Validating Against Actual State**\r\nAchieving high confidence in inventory accuracy requires ensuring that all resources intended to be scanned are captured within the inventory. I propose a multi-step approach:  \r\n\r\n##### **a. Automated Inventory Generation**  \r\n- Utilize tools like Steampipe, AWS Config, Azure Resource Graph, and GCP Asset Inventory to generate inventories programmatically.  \r\n- Enforce metadata tagging policies (e.g., `Inventory: True`) to mark resources intended for inventory.  \r\n- Leverage IaC definitions to ensure infrastructure matches the intended state.  \r\n\r\nMy project, [**RampScout**](https://github.com/Elevated-Standards/RampScout), is designed to automate inventory generation by querying cloud APIs and validating resource states across AWS, Azure, and GCP. It aims to standardize inventory collection through predefined templates and schemas, providing a consistent, auditable source of truth.\r\n\r\n##### **b. Validation through Continuous Monitoring APIs**  \r\n- Provide CSPs with a structured API endpoint (e.g., `/inventory/validate`) to expose real-time inventory data.  \r\n- Require CSPs to submit inventory signatures (hashes) along with reports to validate accuracy.  \r\n\r\n##### **c. Reconciliation Against Scan Data**  \r\n- Compare inventory data against scan outputs. Identify gaps where resources are missing from scans or scans are incomplete.  \r\n- Implement rules for reconciliation:  \r\n  - **\u201cPresent in Inventory but Missing in Scans\u201d** \u2013 Trigger alerts and require investigation.  \r\n  - **\u201cPresent in Scans but Missing in Inventory\u201d** \u2013 Potentially unauthorized resources requiring immediate attention.  \r\n\r\n---\r\n\r\n#### **3. Mechanism for Establishing Confidence in Inventory Accuracy**\r\nFedRAMP's approach to ConMon needs to directly address how confidence is established. I propose the following framework:  \r\n\r\n##### **a. Inventory Validation Schema (IVS)**  \r\n- Define a JSON/OSCAL schema for inventory submissions that includes:  \r\n  - **Resource Type** (e.g., VM, Lambda Function, Container)  \r\n  - **Unique Identifier** (ARN, Instance ID, etc.)  \r\n  - **Metadata Tags** (e.g., Project, Owner, Environment, Criticality)  \r\n  - **Source of Truth** (IaC, API Query, Manual Entry)  \r\n\r\n##### **b. Multi-Cloud Inventory Reconciliation**  \r\n- Establish guidelines for inventorying resources across AWS, Azure, GCP, and other platforms.  \r\n- Require CSPs to provide proof of completeness by generating inventory records for each account, subscription, or project.  \r\n\r\n##### **c. Periodic Revalidation**  \r\n- Implement periodic revalidation checks to ensure that CSPs are maintaining accurate inventory.  \r\n- These checks can be automated via API calls or batch submissions, but should be verifiable against raw scan outputs when required.  \r\n\r\n---\r\n\r\n#### **4. Avoiding Perverse Incentives**\r\nYou raise a valid point about the risk of CSPs underreporting resources to maintain higher Key Security Indicator (KSI) scores. To address this:  \r\n\r\n- **Standardized Definitions:** Clearly define which resources must be included in the inventory.  \r\n- **Cross-Referencing:** Require inventories to be validated against independent sources (e.g., CloudTrail logs, Azure Monitor logs).  \r\n- **Incentivize Accuracy:** Provide positive scoring for complete inventories and transparent reporting rather than focusing only on vulnerability counts.  \r\n\r\n---\r\n\r\n#### **5. Recommendations**\r\n- **Create a Consistent Inventory Framework:** Adopt a standardized approach for inventory generation and submission across CSPs.  \r\n- **Enable API-Based Validations:** Ensure CSPs can expose real-time inventory data through structured APIs.  \r\n- **Establish Cross-Cloud Standards:** Define rules for inventorying resources across all major cloud providers.  \r\n- **Incorporate IaC Definitions:** Treat IaC files as an authoritative source of truth for inventory validation.  \r\n- **Integrate Open-Source Tools:** Continue enhancing projects like [**RampScout**](https://github.com/Elevated-Standards/RampScout) to provide streamlined, automated, and auditable inventory generation and validation.  ",
      "author": "austinsonger",
      "created_at": "2025-04-03T01:45:45Z",
      "replies": [
        {
          "id": "DC_kwDOOK0ax84AwtRr",
          "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/15#discussioncomment-12768363",
          "body": "A small point, I think the Data Storage & Management section should also include inventory of non-managed databases. While the managed DBs are the likely the vast majority, the current listing leaves space for me to build a DB-on-a-VM and not mention the DB itself as an inventory component.",
          "author": "kamamanh",
          "created_at": "2025-04-08T17:57:43Z"
        }
      ]
    },
    {
      "id": "DC_kwDOOK0ax84AwtkV",
      "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/15#discussioncomment-12769557",
      "body": " > To trust the answer to the above query however one must first ask additional questions:\r\n> \r\n> 1. What AWS accounts am I querying against? (same general logic applies for GCP projects/Azure subscriptions)\r\n> 2. Did I have sufficient permissions to query against each account?\r\n> 3. Are the accounts I am querying against the full set of accounts for the system?\r\n> \r\n> If we can prove the answer to 1 and answer `yes` to questions 2 and 3, then I believe we can assert with a sufficient degree of confidence that we are accurately representing **this specific resource type** in the system inventory.\r\n> \r\n> If we then skip forward a few (hundred) steps and specify the following, I think that we could have a relatively sound foundation upon which to build the inventory and meaningfully compare against scan results:\r\n> \r\n> 1. What cloud resources types should be considered in scope for each of the major clouds\r\n> 2. The rules for uniquely identifying them\r\n> 3. The metadata to collect, how to represent in inventory, and how to reconcile with different scan types (this will vary by resource type and scanner/scanner config)\r\n\r\n@atfurman or others what overall approach do you think would be most effective in defining inventory scope? Examples:\r\n1. First principles approach, i.e., \"components storing or transmitting federal data, or components with privileged access into those components.\" Something like this is straightforward, but subject to interpretation, which gets very squishy.\r\n2. Use case examples approach, i.e., \"this stack is built in AWS/Azure/GCP using these services and these third party tools configured like this.\" This is very concrete, but limited because it would be impossible to cover every use case.\r\n3. Data-centric approach, i.e., \"these types of metadata are considered sensitive, and any components storing or processing them must be tracked as inventory components.\" This gets challenging because metadata is very context specific. Are helm charts inherently \"in the boundary\" because they store metadata policy? The scope can sprawl to ridiculous proportions and a lot of metadata can be sussed out via OSINT methods pretty easily.\r\n\r\nAre there any other approaches that might work better, or tweaks to the above approaches that may make them more effective?\r\n\r\nEDIT: I want to address your specific comments to add context to my question. \r\n\r\n> Based on my experience, this may or may not include components such as managed load balancers, managed filestores, or other infrastructure components.\r\n\r\n...\r\n\r\n> the current inventory does not include serverless compute such as lambda functions or cloud functions- we have included them in the past and were directly instructed to remove them as not relevant, despite the fact that many systems utilize serverless compute, and some utilize little but serverless compute. We viewed this at the time as an astonishingly bad call, and still view it as such, but a directive is a directive.\r\n\r\nand also ...\r\n\r\n> While there are scans, the general implementation of scans is Authenticated scanning for monthly continuous monitoring should consists of targeted scans rather than simply directing a scan tool at subnets. In many cases agent based scans will be used instead of direct authentication.\r\n\r\nFirst off, thank you for sharing your experiences candidly. To your point, I wanted to note that the [Vulnerability Scanning KBA](https://help.fedramp.gov/hc/en-us/articles/29975368259867-Vulnerability-Scanning), while solely a set of best practices and not explicit requirements, specifically advocates for the inclusion of network components, web interfaces, etc. So I am surprised to hear that you received the guidance to exclude networking and serverless compute resources from the inventory. The KBA also specifically recommends performing discovery scans on entire subnet ranges on top of agent-based or targeted scans as a best practice. \r\n\r\nBased on that context, what do you (or others) think is the best way to go about defining inventory requirements in such a way that it ensures the full scope of what *ought* to be in the inventory without being too broad or narrow. \r\n\r\nFWIW, your recommendations on core \"types\" of inventory components is noted, and thank you for that first pass, very interesting!\r\n\r\n\r\n",
      "author": "sam-aydlette",
      "created_at": "2025-04-08T19:51:32Z",
      "replies": [
        {
          "id": "DC_kwDOOK0ax84Awttz",
          "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/15#discussioncomment-12770163",
          "body": "If asked to sketch out a solution right now, I'd begin with what I view as the largest and most achievable parts: what I'll call for the sake of convenience the `infrastructure inventory`. \r\n\r\nBLUF: **The things we want to know about and what specifically we want to know about them should be source controlled and unambiguous.** \r\n\r\n1. For each of the major clouds (AWS, Azure, GCP, maybe Oracle), define the scope for the inventory. For example, if an `AWS account|GCP Project|Azure Subscription|OCI Tenant` hosts any functional component of  the system, then it is considered in scope. This scope is the answer to `Are the accounts I am querying against the full set of accounts for the system?` and should be relatively easy for a human to validate as frequently as required.\r\n2. For each of the major clouds, explicitly and unambiguously define the resource types that **must be inventoried**. For example, you MUST inventory all EC2 instances, S3 buckets, Lambda functions, RDS, DynamoDB tables, ALBs, NLBs, EFS file systems, ECR repositires, etc etc. This is going to be more complex than it initially might sound as A) there are a lot of different resource types and B) the ways in which they contribute to the systems function and store, process or transmit data vary widely. \r\n3. For each resource type, explicitly define the attributes which must be queried. I'd express these as collections of steampipe queries, as that is the most concise, usable, maintainable, and understandable way I'm aware of to ask these questions. I'll freely admit to being a little biased here; as we have already gone some ways down this path. For instance, what do we want to know about an AWS Network Load balancer? I think the answer looks something vaguely like this:\r\n```sql\r\nselect\r\n    arn as inv_asset_id,\r\n    'TRUE' as inv_is_virtual,\r\n    scheme as inv_is_public,\r\n    dns_name as inv_dns_name,\r\n    tags['Function'] as inv_asset_type_and_function,\r\n    'AWS NLB' as inv_hardware_make_model,\r\n    'No - Inherited from AWS' as inv_in_latest_scan,\r\n    case\r\n      when tags['DiagramLabel'] is not null then tags['DiagramLabel']\r\n      else '\"NLB\"'\r\n    end as inv_diagram_label,\r\n    vpc_id as inv_network_id,\r\n    tags['SystemAdministrator'] as system_administrator,\r\n    tags['Function'] as inv_function,\r\n    tags['EndOfLife'] as inv_end_of_life,\r\n    'securityhub' as inv_scanner\r\nfrom \r\n    aws_ec2_network_load_balancer;\r\n```\r\nNote that this example is heavily bound by the conventions of the current FedRAMP inventory; if asked to write this from first principles, I'd probably be structuring it a bit differently, but the overall approach would be the same. \r\n4. Raw infrastructure inventory would thus be expressed as a query set to be run against infrastructure:\r\n![image](https://github.com/user-attachments/assets/463fd867-21f6-4c5a-8de9-66af087c2de4)\r\nEvery CSP runs the same query set and expresses the output as JSON. The CSP is responsible for ensuring that appropriate least privilege permissions are in place to facilitate this, and for ensuring that the entire scope is queried. \r\n\r\nThis is only part of a solution, as it wouldn't address:\r\n- OS/Software (that is an entire topic unto itself, possibly better approached from the scanner side), \r\n- Container image (I don't think based on my experience that one can safely assume that the image repositories within the boundary give a full picture of what can run or is running)\r\n- External services/ SaaS representation (but that isn't consistently addressed anyway; this approach could be extended to encompass at least some of these cases; [steampipe plugins are many and varied](https://hub.steampipe.io/?q=turbot))\r\n\r\nHowever, it would provide a consistently defined, testable, repeatable baseline for CSP inventory reporting, and something of a foundation to build upon. \r\n\r\nI think it would be better than what we currently have, at least, and should be sufficiently complete & correct with respect to actual state that associated KSIs could be meaningful. \r\n",
          "author": "atfurman",
          "created_at": "2025-04-08T21:05:54Z"
        },
        {
          "id": "DC_kwDOOK0ax84Awvtp",
          "url": "https://github.com/FedRAMP/rev5-continuous-monitoring-cwg/discussions/15#discussioncomment-12778345",
          "body": "Thanks @atfurman for your detailed and thoughtful answer!",
          "author": "sam-aydlette",
          "created_at": "2025-04-09T13:12:15Z"
        }
      ]
    }
  ]
}